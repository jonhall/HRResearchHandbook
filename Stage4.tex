\part{The Data}\label{part:data}

%\chapter{Stage 4: Generating and analysing data}\label{ch:Stage4}


You've now reached Stage 4, which means you are half way from the completion of your project. In this stage you will be in the midst of your data generation and analysis, which is possibly the most exciting, yet demanding, part of your research: this is where you get your opportunity to make that contribution to knowledge.

This stage assumes that you have worked out most of your research design details and are now in a position to begin your data generation and analysis\footnote{If that's not the case then you should go back to Stage 3. You should also discuss your progress with your supervisor, revisiting your project timescale and risk.}.


\chapter{Stage 4 Activities and Outcomes}\label{c:Stage4outcomes}

In Stage 4 you will focus on developing your research methodology further and then apply it to generate and analyse the data you need in your project to make your original contribution to knowledge.

For this stage too, we provide a Research Activity table and a Writing Outcomes table to structure and guide your work.

\section{Your Research Activities for this stage}

The research activities which are in focus in Stage 4 are shown in~\Cref{stage4ResearchActivities}, which also provides prompts for your interaction with your supervisor during this stage. 

Generating and analysing data will constitute by far your major effort in this stage (35\% of total effort for this stage). However, before you do that you will need to put some significant effort (20\% of total effort for this stage) into refining your methodology by adding detail to the methods you will apply and, particularly, the procedures you will follow to do so. Related to this, you should ensure that your methods execution is consistent with your objectives (5\% of total effort for this stage) and reflected in the tasks you will need to complete, which should be captured in your work plan (3\% of total effort for this stage).

\begin{SimpleNColTable}{stage4ResearchActivities}{4}{\RActivitiesTableCaption{4}}[X[4]X[1]X[8]X[8]|]
Research activity & Effort & Description &  Supervisor Interaction Focus\\
Identifying the research problem&2\%&Adjust, if needed&\\
Reviewing the literature&2\%&Adjust, if needed&\\
Setting research aim and objectives&5\%&Ensure that appropriate methods are associated with each objective, and break down tasks further in line with your method procedures &Suitability of of association of methods to objectives, and tasks to method procedures\\
Developing the research design&20\%&{Augment your research methodology with detail of your research methods and the procedures to apply them, and how to deal with their potential weaknesses}&Suitability of procedures and mitigation approaches\\
Generating and analysing evidence&35\%&Apply your chosen methods to start generating and analysing your data&Initial application of methods of choice and any improvements required \\
Interpreting and evaluating findings&0\%&n/a&\\
Writing up&20\%&Achieve the writing outcomes of~\Cref{stage4WritingOutcomes} & Demonstration of good academic writing and any improvements required\\
Reflection and reflexivity &10\% & Apply to Stage 4 work and experience as you go along & Reflection on research weaknesses and how to address them\\
Planning work &3\% &{Refine your project plan by detailing tasks, milestones and deliverables for this stage\\ Review progress} & Appropriateness of work plan and progress\\
Managing risk &3\% &Review and adjust project risk, particularly in relation to the application of your methodology &Any major adjustment required\\	
\end{SimpleNColTable}


\section{Your Writing Outcomes for this stage} 

\Cref{stage4WritingOutcomes} gives you the writing outcomes for this stage: the activities in this part of the book are designed to help you reach them.

Remember that the first column of the table gives you the expected full structure of the dissertation\footnote{If your course assumes a different structure, then use that instead, mapping the writing outcomes accordingly.}. Within that column, the greyed out parts are yet to be written and will be the focus of later stages, while those highlighted in red are to be written from scratch during this stage. The remaining parts are those you wrote in previous stages: depending on your work in this stage, you may need to revise or adjust them, with substantial updates highlighted in orange.

\input{WritingOutcomes/Stage4}


\section{Planning your work for this stage}\label{sect:stage4WorkPlan}

Before going further, you should refine your project work plan to include more detail on your work for Stage 4.


%For this, you will need to:
%\begin{itemize}
%	\item make sure you have completed all the work for Stage 1 or make the necessary adjustments to your plan
%	\item identify the main tasks under each activity for this stage, allocate them time and include them in your plan. For complex tasks, you may also include some sub-tasks, etc., but you should avoid making your plan too complicated
%	\item establish main milestones and deliverables and include them in your plan
%	\item optimise your plan by considering dependencies and tasks which may overlap. 
%\end{itemize}


\begin{question}[subtitle={Activity: Revising your work plan}] 
Consider the activities in~\Cref{stage4ResearchActivities} and the writing outcomes in~\Cref{stage4WritingOutcomes}: 

\begin{itemize}
	\item for each activity, identify a number of tasks which capture the work needed, decide how much time to spend on each, and include them in your work plan, also taking into consideration their possible dependencies
	\item for each writing outcome, identify corresponding deliverables and set related milestones in your work plan.
\end{itemize}

At the end, review your overall plan, also considering the progress you made in the previous stages, and make all necessary adjustments. 
\begin{guidance}
Make sure you:
\begin{itemize}
	\item focus on a small number of key tasks for each activity, so to keep your plan light
	\item when allocating time to tasks, ensure that tasks fit within the overall time for their corresponding activity 	
	\item consider task dependencies and things you can progress in parallel, so to optimise your project time 
	\item break down new content you will need to write into deliverables, setting appropriate milestones in your plan.
\end{itemize} 
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

If after reviewing your progress you find that you are well behind, then talk to your supervisor who will be able to advise you on how to bring your project back on track and improve your planning.


%\section{Managing raw data}\label{sect:rawdata}
%Your \textit{raw data} are the data you generate\footnote{\enquote{Data you generate} includes data \emph{gathering} – if the data already exists, for instance, as might be the case with evidence. We use the more active term generate to cover all cases.} as part of your research. Which data you generate and how is determined by the choices you have made in your research design, informed by your research aim and objectives. In this section, we touch on key topics in data generating which are relevant to many projects, although they may not all apply to yours. This section is only meant as an introduction to those topics, to raise your awareness and point you towards specialised literature, should you need it, to deepen your understanding.
%By the end of Stage 4 your data generation, analysis and interpretation should be on a solid ground, and consistent with your aim and objectives. Your research design description should also be close to its final form. Given the criticality of this stage, it is essential that you work very closely with your supervisor throughout.

\chapter{Raw data}\label{ch:RawData}

Your \gloss{raw data} represent any data you generate and analyse as part of your research, and upon which your evidence and contribution to knowledge are based. All research deals with data, irrespective of the specific methodology, so that there are general practices for dealing with raw data which are common to most research. We review them in this chapter.

\section{Sampling: what, who (and how) to choose}\label{sect:sampling}

\gloss{Sampling} is the process of selecting a subset %\footnote{We could have said \enquote{sample} but that would have been circular.} 
for further analysis from a population of interest. You should use it when you wish to study on such population, but this is infeasibly large or inaccessible for you to be able to study every single member of it. Instead, you should choose a sample which is somewhat representative of the population characteristics, hoping that by studying the sample you can establish some properties or patterns of interest which can be assumed true of the population as a whole. 

Sampling assumes that there is a \gloss{sampling frame} as data source: a sub-set of the collection of the population of interest from which your sample is taken. In some sense, you have already experienced sampling as part of your literature review\footnote{You might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. Unless you had infinite amounts of time – which you didn't – and infinite patience – which you might have – you could never be 100\% certain that your literature search collected \emph{all} relevant papers:  the search space is infeasibly large (and not indexed particularly well). But you were systematic and achieved a practically good\footnote{By \emph{practically good}, we mean you found the most of the most important papers, some other papers, and didn't have to read \emph{every single paper}. I.e., you found a \emph{representative sample}.} coverage because of that.

Broadly speaking, sampling can either be random or non-random. 

In \gloss{random sampling}\footnote{Random sampling is also called \gloss{probability sampling}.} you must establish upfront some unbiased way of choosing the subset members from the population to inform your sample collection, which is usually completed prior to any analysis. This is used particularly in quantitative research, and when generalisation of the results to the population is of primary importance, something enabled by the lack of bias in the sample selection process. 

Random sampling techniques include:
\begin{description}
	\item [Simple random sampling] where each member of the population has exactly the same chance to be selected. It has the advantage that it is easy to implement, and given the complete randomness of the sample, generalisation is fairly reliable. However, it can be time consuming if the population if very large, and may not lead to a representative sample if the population has large sub-groups, which may be over-represented in the sample, with minority groups being under-represented
	
	\item [Stratified random sampling] where sub-groups of the population are identified based on common characteristics, the \textit{strata}, and sampling is random across those strata. The strata are not mutually exclusive: for instance, the population may have sub-groups defined by gender, ethnicity and level of education, which may overlap. This approach overcomes the over/under representation problem of simple random sampling; however, deciding on the strata may be difficult and will also complicate data analysis 
	
	\item [Cluster sampling] where the population is divided up in naturally occurring separate clusters, and the sample is obtained by randomly selecting some clusters and then randomly selecting members of those clusters. It is more cost-efficient than the other two approaches, but can introduce bias if the selected clusters are not representative of the whole population, so that the over/under representation problem remains.
\end{description}

In \emph{non-random sampling}\footnote{Non-random sampling is also called \emph{non-probability sampling}.}, you choose your sample based on your own judgement and discretion as a researcher, so that some element of bias may exist. You can also add members to the sample as your research progresses, interleaving data collection and analysis, until no more collection is possible or \gloss{saturation} is reached, that is collecting more data would not bring extra relevant information. This kind of sampling is used particularly in qualitative research, where depth and richness of results are more important than the ability to generalise. 


Non-random sampling techniques include:
\begin{description}
	\item [Purposive sampling] in which participants are selected by the researcher based on particular characteristics, knowledge, or expertise they have. It is often used for small, rare or unique populations, and is particularly suited to studies which intend to be deep and narrow, and for which generalisation to the population is not the main concern. As the sample choice is made by the researcher, it is prone to bias. However, it also allows the researcher to involve participants who are likely to provide insights into such rare or unique groups

	\item [Convenience sampling] where participants are selected based on their availability or accessibility. This is quick and easy, but unlikely to produce a representative sample, so, once again, bias is an issue
	
	\item [Snowball sampling] which relies on referral from previous participants to recruit new ones. This is an effective approach when a population is difficult to access or when the topic is sensitive or tabu. This too is unlikely to generate a representative sample, and is prone to bias. However, it is a way to gain access to members of a population which may be otherwise inaccessible.
\end{description}

In summary, when choosing a sample, you need to consider various factors, including the aim of your study, the kind of methods you are applying, and the level of access you may have. Trade-offs are likely involved and you may not be able to obtain an ideal sample. Nevertheless, your sample will still be useful to your research, as long as you clearly explain and justify how it was obtained and what its limitations are.

\begin{question}[subtitle={Activity: Deep reading on sampling}]
Go back to your choice of research strategy and methods from Stage 3. If you've chosen one which may require sampling, then you should go deeper into this topic to ensure you select the right kind of sampling for your study. We recommend you start by reading the following: \cites{???}
\begin{guidance}
The suggested reading is only a starting point. You should go deeper into the specific kind of sampling you are most likely to apply.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\begin{question}[subtitle={Activity: Your chosen sampling approach}]
Assuming your study requires you to perform some sampling, write down the sampling approach you are going to apply, with its justification in terms of your aim and objectives, and any trade-offs due to the practicality of accessing the sample. Record any possible weakness or limitation of your chosen approach, and how you will address them in your project.
\begin{guidance}
You can skip this activity if sampling is not required by your choice of research strategy.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}



\section{Sharing and anonymising data}\label{sect:sharingAnonymising}

Modern standards of research often require that your data be made available to other researchers so that your research can be verified or even rerun. In fact, it is increasingly the case that data sets are published and shared by entire research communities, often used as testbeds or benchmarks for new knowledge contributions. For instance, in medical applications of Machine Learning, in which new knowledge can be the fractional improvement of the performance of an AI algorithm to, say, diagnose a medical condition from images, not being able to share the data set you have used in your research can negate your knowledge contribution. Therefore, you should consider whether your data (or a sample of it) should appear as an appendix to your dissertation, or whether they should be made available in their entirety to your examiners, or even to the wider research community, and how.

Modern standards of research also require you to comply with regulations on data privacy and protection. These put many constraints on the use of personal data as they are designed to protect the identity of the people they refer to\footnote{We discussed GDPR in~\Cref{sect:personalData}.}. 

Sometimes this can be an hindrance, particularly in reporting and sharing your research where there may be a need to also share the data used in your study -- like in your dissertation. As a result, techniques have been developed to allow the use of such data without comprising their protection. These generally anonymise the data, i.e., the data is processed so that any link, direct or indirect, to a living person is removed.

You should therefore consider the need to anonymise data in your project and familiarise yourself with techniques you can apply to do so.

\begin{question}[subtitle={Activity: Anonymising personal data}] Do a web search to identify techniques to anonymise personal data. List and summarise the main techniques you have found.

\begin{solution}Among others, you may have encountered the following common approaches to anonymising personal data:

\begin{itemize}
\item Hiding, which refers to removing personal data from a data set, for instance, the name and address of participants in a study. Those categories are completely removed from the data set

\item Masking, which refers to obfuscating personal data by replacing values with certain characters, for instance replacing all names and addresses with asterisks. As a result, the specific values are not visible, but their categories are retained in the data set

\item Pseudonymisation, which refers to replacing identifying data with made-up identification data, for instance replacing names or addresses with fake ones

\item Generalisation, which refers to replacing certain data with more general equivalent, for instance, replacing an exact address with an area code.

\end{itemize}
\end{solution}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

Choosing a particular way of anonymising personal data will depend on how the data will be used and the level of information that needs preserving\footnote{A supervisor that has conducted research in the area of your project may have used data anonymising techniques before. It's always worth checking with them what level of anonymisation is needed, and which techniques should be used to achieve this.}.

Among the techniques mentioned in the activity, hiding is the most destructive: by removing personal data from the data set you won't be able track a participant in data collection over time. While this is good for anonymisation, it may be inappropriate for your research. In a clinical study, for instance, you might need to identify the outcomes of a series of tests on a particular individual. If you have removed all identifying information, that isn't possible.

If you need to track participants through their data over time, pseudonymisation -- in which, say,  \enquote{Cruella Deville} is replaced by the made up identifier \enquote{Mario Rossi} is better, as it allows you to track a named individual without giving any personal data away.

Generalisation, on the other hand, can be used when more specific data can be replaced by more general one without loss of accuracy. For instance, you may replace an exact address with an area code in a study which focuses on geographical areas.

It is therefore important that you consider carefully how personal data are to be used in your project when choosing an anonymisation technique. 

Commercially sensitive information also needs protecting from disclosure, so that anonymisation may also apply in this case and some of the techniques we have reviewed still apply.

\begin{question}[subtitle={Activity: Your anonymisation approach}]
Assuming your study requires you to anonymise personal data, write down which technique(s) you may apply, justifying it in relation to the aim and objectives of your research. 
\begin{guidance}
You can skip this activity if you don't need to anonymise personal data in your research.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}


\section{Managing raw data}\label{sect:managingRawData}

%If, for instance, you conduct experimental research, you will have data about your subjects, perhaps collected through questionnaires, and variables of interest, with their measurements. If you use interviews or focus groups, you may have audio or video recordings and their transcripts, or notes you have taken. For survey research, you will have a large number of responses to the set questions. If you use existing secondary evidence, for instance as part of case study research, then you will have all sort of documents, from reports to images, diagrams, etc.: from such documents, you will need to extract relevant raw data for your analysis.

Before proceeding with your data analysis, you must ensure your raw data are properly organised and stored, so that you don't loose track of important information, and you can easily locate and refer back to appropriate data during your analysis and while writing up your research.

It is highly likely that your raw data will be in some digital form. Although techniques for doing so are outside of the scope of this book, your digital data storage should be secured against data loss either due to technical issues, such as computer failure, or due to a data breach, such as through cyber security attacks, at least to the standards required by law, any additional requirements made by your organisation, those of any participants, their organisations, and any other stakeholders\footnote{Once upon a time, in a galaxy far, far away, data generation and storage used to be a \emph{laissez-faire} thing. Today, your university or employer can be fined vast amounts of money for any data misuse, so they tend to take it more seriously. If data loss were to happen, amongst other things, it'd probably mean you'll fail your degree.}.

%is regularly backed up, not to risk loosing it, and, if you collect any personal information, your data, whether physical or digital, must be stored securely to comply with data protection\footnote{See Cref{sect:personalData}.} regulations.
%
It is also important that you put your raw data in a form which is useable for analysis. Spreadsheets are particularly useful for this purpose, especially if your data is quantitative, so that this is a common way to organise and store raw data. In fact, most publicly available data sets used in research and beyond are stored as spreadsheet files: if you are going to use one such data set, then your raw data are likely already organised for you!  

Spreadsheets organise data in rows and columns, so that you can easily enter your raw data using rows for your observations/measurements and columns for your variables. As we will see later on\footnote{See~\Cref{sect:UsingTables}.}, spreadsheets come a wide range of functionalities for data manipulation and for some level of data analysis. They are also easily extensible, so that you can grow your data sets incrementally.

\begin{question}[subtitle={Activity: Managing your raw data}]
Consider the data you will need for your project. List the actions you will take in relation to:
\begin{itemize}
	\item Organising your raw data
	\item Storing and backing up your data
	\item Protecting personal data.
\end{itemize}
Make sure you complete those actions as you generate your data, and before performing any data analysis.
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

%\endinput

\chapter{Data generation methods}\label{ch:DataGenerationMethods}

All research needs data and in this chapter we step through the most used data generation methods. Most of them concern {empirical data}, that is data that is obtained through our five senses or from experience, yours or that of your study participants. 

When we say \enquote{data generation}, we don't necessarily mean that you will create a new-to-the-world \enquote{data}\footnote{Although this might indeed be the outcome of your data generation.}. We simply mean new-to-your-project data, which covers a multitude of sins, including:

\begin{itemize}
\item The creation of a brand new data set, which did not exist before your research project. This may be the result of data collected through new observations or measurements, a new survey, questionnaire or focus group, through selecting passages from documents, etc.
\item The extension of a previously collected data set with new elements, derived from those that already exist, for instance adding the mean value of a collection of numerical data, or grouping together specific distinct data into new categories that you have created
\item The collection of previous data for re-interpretation, for instance if you are re-running a previous experiment in order to confirm its results, or doing a meta-analysis of the literature in a particular area.
\end{itemize}

Of course, the data you generate as part of your research must allow you to make a contribution to knowledge, that is to conclude something new, even if you use an existing data set.

Related to data generation is the concept of \gloss{data source}, which is the location from which your data originates. If you are re-using existing data sets, this may well be an archive or a digital repository. For new data sets you generate, this may be the experimental or real-world setting of your own observations and measurements, or a population of interest from which you will derive a sample for further analysis. 

For each data generation method in this chapter\footnote{And also for each modelling and analysis method in the next two chapters.}, we will provide:
%
\begin{itemize}
\item A brief description of the method
\item Key procedural considerations you should take into account
\item Other important issues, particularly in relation to potential research weaknesses or feasibility within your project
\item further sources to consult for more detail.
\end{itemize}

You concluded Stage 3 with an initial draft of your methodology which included both your chosen research strategy and possible research methods within. Now it's the time to consider those methods in detail to ensure they are the right ones for your project, to plan how to apply them, and to start generating your data. 

The next two activities will help you do that for your chosen data generation methods. These are very substantial activities which will allow you to take a significant step in your research.

\begin{question}[subtitle={Activity: Finalising your data generation methods}]
 Consider your chosen data generation methods. For each, read through the related section in this chapter (see~\Cref{tab:generationMethodsChoice}), and write a summary including the following points:
 \begin{itemize}
 	\item explain why it is an appropriate method for your project, in relation to your aim and objectives, your chosen research strategy and the data sources at your disposal
 	\item if there are variants of the method, indicate the one you will apply and why 
 	\item if sampling is needed, indicate the kind of sampling you will perform and why
 	\item if data anonymisation is needed, indicate which approach you will take
 	\item detail your procedures in applying the method within your project
 	\item indicate how you will guard against potential research weakness intrinsic in the method
 	\item discuss your choices with your supervisor to ensure they are appropriate for your project.   
 \end{itemize}
\begin{guidance}
This activity assumes that you have completed a draft of your methodology which includes your chosen research strategy and possible research methods within. If that's not the case, then you should return to Stage 3 and complete the activity in~\Cref{ch:yourResearchMethodology}.

For each method, conduct a first pass at addressing each of the points based on the content of this chapter, then follow some of the references provided to read more about the method and improve your summary. Your supervisor should also be able to point to relevant literature or provide expert advice on the application of the method.

By procedure we mean the specific steps you will take to ensure the method is applied correctly and you have guarded against potential weaknesses. In your dissertation, your procedures should be sufficiently detailed for other research to follow what you have done or even replicate your work independently. 

You may have to iterate with your supervisor to refine your choices and procedures.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

%%%Intentionally \ref, not~\Cref
%\newcommand{\tick}{$\Box$}
\begin{SimpleNColTable}{tab:generationMethodsChoice}{2}{Data generation methods in this chapter}[X[2]X[4]|]
	Method & Section\\
	Observations&\Cref{sect:observations}\\
	Questionnaires&\Cref{sect:questionnaire}\\
	Interviews&\Cref{sect:interviews}\\
	Focus groups&\Cref{sect:focusGroups}\\
	Delphi&\Cref{sect:Delphi}\\
	Journaling&\Cref{sect:journaling}\\
	Fieldwork &\Cref{sect:fieldwork}\\
	Documents&\Cref{sect:documents}\\
\end{SimpleNColTable}

At the end of this activity you should be ready to start generating your data. 

\begin{question}[subtitle={Activity: Applying your data generation methods}]
 Apply your data generation methods by following the procedures you have outlined and agreed with your supervisor. You should:  
  \begin{itemize}
 	\item test your procedures before their wider application, if possible
 	\item document any deviation or adjustment you may have to make in executing your methods
 	\item ensure you manage your collected data appropriately
 	\item establish regular checkpoints with your supervisor to review your data generation process and outcomes, and to agree any required adjustment. 
 \end{itemize}
\begin{guidance}
The kind of testing you can do will depend on the method you will apply. For instance, you may test a questionnaire with a family member to ensure its design is appropriate, before using it with your research participants.

Regular monitoring and adjustments are essential: it is highly unlikely that things will go exactly as you originally planned them!
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}


\section{Observations}\label{sect:observations}

 Observations constitute one of the main ways in which empirical data are generated\footnote{Whole books have been written on \emph{observations} as a research method; we can only give a shallow introduction. Further sources you can use are included at the end of this section.}. In fact, according to \cite{marvasti2014analysing}, \enquote{Observation is the foundation of science}. 
 
  This method requires the researcher to make their observations\footnote{Hence the name...} of phenomena of interest. What you will observe are core characteristics of the phenomena that you have identified as part of defining your research problem. 
  
  %\ResGenTechnique{observations}
 
 Observations can be made directly, through your naked senses, or through instruments which enhance your sensory capabilities, such as a telescope, a microscope or the \enquote{myriad of other ingenious inventions designed to make the invisible visible, the evanescent permanent, and the abstract concrete} \cite{daston2011introduction}. Quantitative observations, say, the size or weight of an object, are usually referred to as measurements.
 
 
   
 %\blockcquote{daston2011introduction}{Observation[s...] instruments include not only the naked senses, but also tools such as the telescope and the microscope, the questionnaire, the photographic plate, the glassed-in beehive, the Geiger counter, and a myriad of other ingenious inventions designed to make the invisible visible, the evanescent permanent, and the abstract concrete. Where is society? How blue is the sky? Which ways do X-rays scatter? Over the course of centuries, scientific observers have devised ways to answer these and many other riddles.}

 %\todo{Ensure that\footcite{driscoll2011introduction} \emph{Voluntary participation}, \emph{Confidentiality and anonymity}, and \emph{Researcher bias} are covered elsewhere, if not here.}

%\paragraph{What to observe} What you will observe are core characteristics of phenomena of interest that you have identified as part of your research problem, whether they are interactions between atoms, between school children, or even your own actions, thoughts, and – perhaps even – biases. It may be that, in the course of your research, you will observe related or proxy phenomena, as needs must. Part of your observation skills will be to identify those related to and proxies for, to record those observations and to iterate those records into structures that capture the characteristics that are necessary to do the research on their back. 

\paragraph{What to observe} Observations are versatile tools for almost any research domain, and your own domain will determine what sort of observations you will make. Observations range across natural phenomena – such as the different proportions of plant species that populate a wilderness garden – through to artificial phenomena – the way that buses drop off and pick up their passengers at a train station – and to social phenomena – the different ways in which a train station is used by commuters in the morning and the evening – as well as more complex combinations of each. Each will use different observations techniques and tools, and each with different constraints. 

\paragraph{Observation types} Observations can be \emph{naturalistic}, when phenomena are observed as they happen in their natural setting -- for instance, observing the behaviour of animal species in their habitat, or \emph{structured}, when phenomena are observed in a somewhat artificial environment, such as during an experiment  -- for instance, giving people a specific task to perform and observing how they carry it out. In this case, often the aim is to collect quantitative data, say the speed at which the people can complete the task. 


\paragraph{More on social observations} As an observer of people, you can act as either a \emph{participant} or a \emph{non-participant} observer. The former is a researcher that interacts as a member of a community under observation, becoming an active participant in the group or situation under study. In effect, as a participant observer, you would be \enquote{living} alongside those you observe – you might be a commuter that uses the train station and so share the experience of the other commuters you observe. Instead, in non-participant observation, you would remain separate from the group or situation being observed -- you may observe commuters using the train station, but not actively become one of them. 

Depending on whether people are or not aware of being observed, observations can be \textit{covert} or \textit{overt}\footnote{The terms `disguised' and `undisguised' are also used in the literature.}. Covert observations have the advantage that people's behaviour is not affected by their awareness of being observed, but, of course, they raise some important ethical and legal issues in relation to informed consent, and privacy and anonymity. If the judgement is that the phenomena observed do require privacy – perhaps you wish to observe commuters' use of restrooms in the train station or customers in a betting shop – then you must explicitly ask for permission – or change your research problem! Otherwise, in a public space, there may be no overriding expectation of privacy and observations can be done without explicit consent. Your university is likely to have strict regulations on the matter, or even prevent you from conducting covert observations as part of your research. 
%Alternatively, you may be an \emph{unobtrusive observer}, a researcher that works outside of the \enquote{frame of reference}\footnote{The frame of reference is the relation between the observer and what is under observation.} for the observations you will make, perhaps standing at the entrance/exit to the train station counting how many commuters pass.

\subsection{Procedural considerations}\label{ssect:DG:observationsProceduralConsiderations}

In order to apply this method, some preparation is needed for you to decide what you will observe as how. Specifically:

\paragraph{Phenomena}  You will need to decide which phenomena to observe, whether natural, artificial, or social: this choice will depend on your research problem, and aim and objectives. 

\paragraph{Kind of observations} Depending on the phenomena, you will need to decide whether you will perform naturalistic or structured observations. In addition, for social phenomena, you will need to decide which mode, whether participant, non participant, overt or covert. For the latter, you must also identify the steps you will take you ensure compliance with ethical and legal guidelines.

\paragraph{Time and place} For all kinds of observation, you must determine the time and place at which those observations will be made. For participant observations, this choice will be determined by your participation in the group or activity being observed, which may or may not be under your control. For instance, if you are a participant observer of train station usage, then you can determine when to use the station and make your observations. However, if you are a participant observer in a change project within your organisation, then the timeline of the project will determine when your observations can take place. In all cases, you should draw a schedule which establishes the timing and frequency of your observations, and which provides an efficient way for you to conduct your observations. For instance, it may be that you make exaggerated use of the train station\footnote{You could eat there, for instance, or use any shops that are colocated.} to condense many months of participant observation into weeks or days – after all, your research project is time bounded – perhaps visiting ten times per day rather than just two. 

\paragraph{Use of instruments} You may be able to make your observations using only your senses. However, many phenomena do not permit observation through the senses unassisted – for instance, the search for exoplanets\footnote{For instance, \textcite{jones2008exoplanets}. But don't let this exciting mission to explore strange new worlds; to seek out new life and new civilizations; to boldly go where no one has gone before distract you. Too much.} requires complex and delicate instruments which will be located on mountain tops. In this case, the availability of the equipment you will use will determine when and how you make your assisted observations  --- you will also need to gain access to the equipment, and this will constrain your schedule and may alter your research plans\footnote{Remember, plans never survive first contact with reality, so also plan to have a backup plan that you can use should your first plan to make your observations fail!}.

\paragraph{How to record observations} It is important your record what you directly observe, separate by any added interpretation\footnote{That should happen later on, as part of your data analysis.} to avoid possible bias affecting recorded observations. To this end, observations are typically recorded in notebooks with a double entry, which separates pure observations from possible value judgements made by the observer – for instance, observing someone \enquote{waiting impatiently for the train door to open} is ascribing feelings to the person observed which, by their nature, are hidden from the observer, but may be inferred from the observed's body language. By separating them out, another researcher reading your notes can clearly differentiate direct observations from such inferences. In some cases, you may be able to use audio and video recording, say using your smart phone, to capture your observations for follow-up analysis. In this case, ethical issues in relation to privacy and informed consent also apply.

\subsection{Other things to think about}\label{ssect:DG:observationsOtherThingsTo}

Observations are by no means an easy way of generating research data, and there are many issues that can arise, including:
%
\paragraph{Hawthorne effect} Overt observations can lead to the so-called Hawthorne effect\footnote{This term was coined in the 1950s in relation to a productivity study carried out at the Hawthorne Works, an electric plant in Chicago.}, which consists of people changing their behaviour due to their awareness of being observed. This can be mitigated by building a rapport, including  spending more time with the people being observed, observing them for longer periods of time, and, in case of structured observations, by ensuring that the tasks participants are asked to do come natural to them.
	
\paragraph{Observer bias} All observations can be influenced by the observer's own bias, whether implicit or explicit, or the result of overfamiliarity with the phenomena of interest. To guard against it, triangulation should apply, including using different data sources and collection methods, or having multiple observers all following a standardised procedure. The use of double-entry notebooks, as described above, can also help, as they separate pure observations from interpretation and inferences made by the observer, with the latter being the subject of scrutiny for potential bias.

\paragraph{Volume of observations} Observations can lead to vast amount of data to analyse. Different analysts, or different stages of analysis as your research progresses, may focus on different aspects of the same data. This can be a good thing should your analysis deepen due to understanding more about your observations, but may also lead to analysis drift or even \enquote{paralysis through analysis} in which no progress is made due to too much depth. To avoid this, keep a clear eye on the prize: your research goal, and set regular times at which you can reflect on progress.

%\item The analysis of observations depends on the researcher's chosen focus and philosophical and analytical framework. This is a natural dependency and can give great richness to observations, even those that are taken from the record. However, they can also lead to overthinking and, like the previous item, paralysis, as well as to prose that is obtuse and disengaging for the reader\footnote{And examiner! Consider, also, that the examiner might not share your focus and that this difference might be sufficient for them to discount your work as without value. Not likely, but care is needed.}.


\subsection{Further reading}\label{ssect:DG:observationsFurtherReading}

\ResGenExtras{observations}{{daston2011introduction}{marvasti2014analysing}{simpson2003using}{driscoll2011introduction}{angrosino2003observations}{sapsford1996data}}

\section{Questionnaires}\label{sect:questionnaire}

Questionnaires\footnote{Questionnaires are just one in a rich collection of \emph{survey tools}, others of which are described below.} are versatile tools for generating data from participants by asking questions\footnote{There's a hint in the name – \emph{question}naire – although why two \enquote{n}s; does no millionaire, billionaire, or debonaire use them?}. They allow a researcher to collect participants' answers about their attitudes, preferences, opinions, behaviours, etc. You might use a questionnaire as a way of collecting statistically significant responses from a population sample, but there are other uses as well, for instance as the basis of interviews\footnote{Which we cover in the next section.}.

%\ResGenTechnique{questionnaires}

If you do use a questionnaire, its thoughtful design\footnote{\emph{Questionnaire design} may conjure up glossy format and whizzy web-pages, which is of secondary importance. Unless your questionnaire is about the design of questionnaires, of course.} is of critical importance. Otherwise, you might be asking your (willing) respondents to spend a considerable amount of their valuable time answering questions the content of which is not helpful for your research. As they might not be so willing to help a second time, getting the questions right the first time is important. 

Administering questionnaires is nowhere near as difficult as it used to be as the number of online resources for doing so continues to increase. Because of this, there are plenty of resources to help you design your questions. Their descriptions can be a little technical, however, so the following definitions might help you engage with them better.

\paragraph{Essential questions} %You should identify 
This the smallest possible set of questions you absolutely need to ask to address your research aim and objectives. While using several questions will give you richer data sets, long questionnaires tend to put people off, so that fewer people may be willing to participate. 

\paragraph{Profiling questions} %These are 
These questions ensure that your respondents match specific characteristics you are interested in: say, you are studying the usability of a new product, then you will need to know the extent your respondents have engaged with that product. This is particularly the case if you are running a large survey and don't know who is going to respond.  

\paragraph{Demographic questions} %These are 
These are often used so that you can then compare answers across different sub-groups, say, based on gender, age or ethnicity, etc.

\paragraph{Response options} Questions are broadly divided into \emph{closed} and \emph{open}-ended. Close questions restrict the possible responses to a set of given choices, while open questions allow respondents to use their own words freely to answer the question. 

\subsection{Procedural considerations}\label{ssect:questionnaireProceduralConsiderations} 

In applying questionnaires you should consider:

\paragraph{Using tools} While you can design your questionnaires from scratch using your word processor, there are plenty of specialised digital tools, many of which are free, that can make it a lot easier\footnote{Such as GoogleForms or SurveyMonkey, but many more are available at the time or writing.}. They usually come with: templates and pre-defined question types that you can customise for your study; statistical analysis and data visualisation features that you can apply to the data you have collected; export functions that allow you to save the data to a spreadsheet for further analysis. Overall, if you need to develop questionnaires for your research, they can really help you speed up the process, so that it's well-worth the investment of time in climbing their learning curve. 

\paragraph{Drafting, testing and piloting} Unless you have many years of experience in questionnaire design, your first questionnaire draft will be far from suitable. Indeed, releasing your first draft without further thought may lead to you not generating useful data from it, and also putting off your audience sufficiently that they may not be willing even to look at your second version. So, once you have a first draft of your questionnaire, you should test it and refine it. 

Early testing can be done by asking a friend, a family member\footnote{Probably, but not always a friend:)}, or a colleague to work through the questions, provide their answers and any other feedback they might have. This will give you early indications of problems with your questionnaire\footnote{Although it's sometimes difficult, you'll make more progress and more quickly if you think of the questionnaire as imperfect, rather than you. You can then apply comments – even if they are negative – to the questionnaire rather than having a personal emotional reaction to them. For each comment, make sure you understand how it can be addressed in your questionnaire. This last tip also means that you can welcome (but ignore) comments that can't be addressed.}, which you can spot, for instance, if the respondents are confused – which may point to a lack of clarity in the questions – or hesitant – which may point to a poor choice of response options or to inappropriate scales – or disengage before completion – which may point to too many questions being asked. Be sure to loop back to those that have helped you to check that you have addressed their comments. 

Later in the process of designing your questionnaire, however, you should take expert advice including, of course, that of your supervisor, to get to the final agreed form. In addition, you could pilot your questionnaire on a small number of respondents first, then revise it as necessary before using it more widely.  

\subsection{Other things to think about}\label{ssect:questionnaireOtherThingsTo}

In designing your questionnaire you should pay particular attention to the following:

\paragraph{Plain language} Your questions should be clear and plain, and you should avoid jargon and idioms, to ensure your participants understand what you are asking, particularly if not native speakers. 

\paragraph{Unbiased language} Your questions should also be objectives, that is you should avoid any judgemental term or tone which may reveal your own opinions or believes, or influence participants to answer in a particular way. You should also avoid questions which make assumptions about your respondents' habits or behaviours: for instance, asking participants what they eat for breakfast, assumes they all take breakfast, which may not be the case.

\paragraph{Double-barrelled questions} Also termed \enquote{compound}, these are questions that ask more than one thing, while only allowing one answer. These should be avoided as it would be difficult, if not impossible, to establish in your analysis which part of the question each participant has answered. Instead, you should split the question into separate questions each addressing a specific thing.

\paragraph{Closed and open questions} For your closed questions you should ensure that the possible answers provided cover all possible options\footnote{Or, at least those you're interested in.} and do not overlap, that is they are mutually exclusive. Instead, for your open questions you must ensure they are sufficiently constrained so that your participant's answers don't end up being too vague or off topic, hence not providing much value to your research.

\paragraph{Scales} If your questions require participants to estimate or measure something, you need to worry about both validity and reliability when setting up the scales for possible answers. In this context, validity means that the chosen scale should allow respondents to measure something accurately; while reliability means that, under the same conditions, respondents will be able to come up consistently with the same (or very close) measurements.

\paragraph{Question grouping, ordering and flow} You should group related questions\footnote{For instance, those intended to establish a demographic of respondents.} together, and establish a logical flow in sequencing groups of questions, so that topics follow naturally from one another. Question order in each group also matters: as a rule of thumb, simpler questions should precede more complex ones.

\subsection{Further reading}\label{ssect:questionnaireFurtherReading}

\ResGenExtras{questionnaires}{[\nopp C14]{oates2008researching}[p250]{hays2003case}{burns2009action,mcclure2002common}{najafi2016observation}{robertson2002automated}[C6]{kielmann2012introduction}}

\section{Interviews}\label{sect:interviews}

Interviews are a method for generating data from participants by asking questions and recording detailed answers. They are a form of conversation between the researcher and one or more interviewees, designed by the researcher to gain insights and opinions on a specific topic. The researcher guides and controls the conversation and asks the questions.

%\ResGenTechnique{interviews}

The personal approach that is a characteristics of interviews means that they are a great way of accessing a (group of) individuals' feelings, thoughts, ideas, and/or experiences, data that can be difficult to generate in other ways. Interviews can help you obtain detailed information on a specific issue or topic, asking open-ended questions which may be tackled or interpreted differently by different interviewees. They are also an effective way to investigate sensitive issues or privileged information that interviewees may not be willing to commit to writing.

Interviews can also provide direction for new research by giving expert indications of where problems lie in a particular domain. As such, interviews can often be used as a way into an emerging topic or field of study, filling in useful background through personal experiences, and providing access to otherwise difficult to access information. 

There are three main kinds of research interviews:

\paragraph{The structured interview} serves as a repeatable protocol by which each participant is asked the same questions in the same way. There is no scope for deviation from the structure, so that auxiliary questions and follow-ups are not used.

Structured interviews are the closest to being time bounded and predictable; if you only have 8 hours to conduct 24 interviews for instance, a structured interview would be the best way to achieve this. 

Your skills as an interviewer will be tested by structured interviews: it is often difficult not to stray outside of the structure when an interesting answer is given, and you may have to cut a participant short if their answers overrun or diverge from the structure\footnote{In our experience, this is a perennial problem, so don't underestimate the difficulties you will face as an interviewer.}.

\paragraph{The semi-structured interview} serves to identify areas of interest to the researcher, with interesting responses being welcomed and followed up if appropriate. Interviewing a domain expert on your chosen topic would be well-served by a semi-structured interview as their expert knowledge could be probed with follow up questions.

The semi-structured interview does not naturally time-bound the interaction, and so – if you don't have unbounded amounts of time – you will have to balance the breadth of questions with the depth of responses.


\paragraph{The unstructured interview} has no structure to constrain the route through the data that the interviewee wishes to take, although the interview may begin with the same question each time. As the direction may wholly be decided by the participant, you challenge may be retaining forward motion and focus during the interview.

\subsection{Procedural considerations}\label{ssect:InterviewsProceduralConsiderations}

Procedural factors to consider in interviews include:

\paragraph{Interview type} In being standardised, structured interviews make it easier to compare your interviewees' answers objectively. However, interviewees are limited to the set questions, so there is no scope for digging deeper into their answers. If you need deep insights, you should use the less structured interview forms which allow you to probe your participants responses.

If you have a good level of domain knowledge, you can use the less structured interview models, as you will be able to follow your participants' answers more easily and direct their comments towards your research interests\footnote{Of course, you can always use structured interviews even if you do have domain knowledge – there's nothing to stop you.}. If you don't already have a good level of domain knowledge, then you will be putting more effort into the design of the interview, so that you can simply capture your participants' responses to your – well-designed – questions. 
%
%\endinput
\paragraph{Whom to interview} You will need to choose your interviewees carefully. In the perfect case, you should interview until the responses you are receiving are \enquote{guessable}\footnote{I.e., you no longer get novel answers to your questions, indicating that the topic has been covered.}. Practically, you will have limited time and resources, and limited access to interviewees, so that sampling may be required: in such case, you should follow the advice on sampling in~\Cref{sect:sampling}. 
%
\paragraph{Ethical and legal matters}  Your university will have strict guidelines on how to approach and work with human participants, which you should investigate before you contact your potential interviewees. At a minimum, those guidelines will cover informed consent, handling personal data, and health and safely, but they may also prevent you from interviewing certain groups of people, for instance minors or vulnerable adults. You should go back to the advice in~\Cref{ch:EthicsAndRegulations} to refresh your understanding of ethical and legal issues in relation to human research participants.

\paragraph{Testing and reviewing} You can apply some of the advice in~\Cref{sect:questionnaire} to help you design your interview questions. Once you've drafted your interview questions, you should do a dummy run of your interview with a willing friend, family member or colleague, and use their feedback to improve your questions\footnote{Repeat this with as many willing participants as you can until you're happy with the interview format or until you run out of willing participants, or time! Make sure that you do not dip into your target population for these preliminaries.}. In particular, you should consider:
%
\begin{itemize}
\item whether you were able to put the participant at ease during the interview. If not their nervousness might influence their ability to contribute, and you should consider what to do differently
\item which questions worked well and led to useful responses, and which were confusing or led to unhelpful answers. For the latter, you should consider how to reword them – perhaps with the help of your participant\footnote{\enquote{I would have asked it this way}...}, by having alternative versions of the questions, or by removing or replacing the questions
\item (if time constrained) which questions overran, and whether you can rephrase them to be less \enquote{open}
\item (if structured) whether were you able to keep to your \enquote{script}. You should reflect on how will you resist the temptation to probe more deeply, or whether you should consider moving to a semi-structured or unstructured form
\item whether the questions were in a logical order, ideally grouped by topic. If not, consider re-arranging them to build responses in the most productive way
\item whether you have sufficient questions to elicit the data you need, or there are other questions you should ask.
\end{itemize}
Once you are satisfied with your questions, you should run them past your supervisor – they will have comments for sure.

\paragraph{Recording answers} You need to decide how you will capture your interviewees's answers. If you are planning to use audio or video recordings, you will need to make your participants aware and elicit their explicit consent. If not, you will need to take notes manually. In this case, you should also test your note taking, to check that you are able to capture everything of interest\footnote{Longhand notes can be taken at 35 words per minute; spoken text is often as fast as 120 words per minute.}.

\paragraph{Where to hold the interview} With the advances in video conferencing technology, interviews can be conducted effectively online, with the added bonus that they can be easily recorded, often with transcripts automatically generated. However, interviews in a physical space where you are colocated with your interviewee, remain common. For these, you will need to ensure that you have an appropriately comfortable venue for your interview, including access to comfort facilities. Public spaces – where you could share a coffee, for instance – may create a more immediate feeling of intimacy, and so deeper responses, but they may not be suitable for discussing sensitive issues or if background noise might interfere with your record keeping. Therefore, make sure to check the venue out at the right time of day to ensure it is appropriate for the interview and your recording device can handle any difficulties.
%
\paragraph{Opening and closing interviews} As part of giving their inform consent, interviewees should be fully aware of what you are trying to achieve in your research and what the purpose of the interview is within it. They will also be interested in how you will use their answers, and should be reassured as to any use of confidential information or personal data. It is therefore good practice to provide this information at the start of your interview, or even as part of inviting them to participate: perhaps share a sheet which includes this information and describes the research you are doing. At the end of the interview you should also thank them and explain what will happen next, including how they can get in touch if they have any further concerns and follow up questions.

\subsection{Other things to think about}\label{ssect:InterviewsOtherThingsTo}

To be successful at interviews you should also consider:

\paragraph{Making a checklist} There is lots to think about when preparing and conducting interviews. Have you made all necessary arrangements to conduct the interviews? Did you obtain all necessary permissions, including informed consent? Do you know how you will record the answers? What would happen if your audio recording device went wrong? Would you have a backup for the interview? What if you forgot to turn it on?\footnote{Oh so easy to do...} Write a checklist of instructions for yourself to follow before and after each interview, so that you can be sure not to miss anything important. 

\paragraph{Being a good interviewer} Try, to the extent possible, given the format, to allow your participant to govern the speed and direction of the interview. Allow them to talk in complete sentences without interruption, or have a good reason to interrupt. If you need to interrupt, apologise for doing so and tell them the reason why you have done so\footnote{\enquote{I'm sorry to have to interrupt, but we only have 5 minutes left and ...}.}. Be polite and encouraging, as your participant might be nervous.


\subsection{Further reading}\label{ssect:InterviewsFurtherReading}

\ResGenExtras{interviews}{[C13]{oates2008researching}[p43]{johannesson2014research}[p194]{secor2010social}[p250]{hays2003case}{mcclure2002common}[p52]{peoples2020write}[6397]{jorgensen2001grounded}[]{hycner1985some,englander2012interview,ramsook2018methodological}{robertson2002automated}[C4]{kielmann2012introduction}}

%\endinput

\section{Focus groups}\label{sect:focusGroups}

Focus groups engage participants in interactive discussions to develop an understanding of complex phenomena and generate new hypotheses for further research or practice. They are effective at surfacing a full range of perspectives held by the participants and, through their interaction, expand on their individual contributions. They are particularly useful to uncover data and ideas that may not come up in one-on-one interviews, and are generally a more efficient way of collecting data than multiple interviews.

%\ResGenTechnique{focus groups}

Focus groups include participants who share some common characteristics or interest. They are moderated, often by the researcher, so that they combine elements of interviews and observations alongside the group discussion. The moderator plays a crucial role in facilitating group processes, maintaining focus, and controlling participant interactions. Depending on your research aim, it might be necessary for you to run a series of focus groups so that you can identify trends across different groups.

There are different flavours of focus group. For instance, there may be two moderators with separate roles, say one looking after the procedures, the other focusing on the discussion, or both contributing to the discussion, but taking opposite sides or one playing devil's advocate\footnote{The term `duelling moderators' is used in this case.}. You could have a two-way focus group, in which there are actually two moderated groups each listening to each other's discussion, with a view to stimulate richer insights through rebuttal or further elaboration of ideas. You may also reduce the number of participants to create a more intimate `mini' focus group.

\subsection{Procedural considerations}\label{ssect:FocusGroupsProceduralConsiderations}

To optimise your focus groups, you should pay careful attention to the following:


\paragraph{Group type} Depending on your research aim, you should decide which kind of focus groups you will need, including whether more than one moderator is required, or if a series of focus groups would be desirable.

\paragraph{Group size} The number of participants in a focus group is usually between 8 and 12\footnote{Is a 12-person jury simply a focus group?}, although other sizes work too; the smallest useful size is considered to be between 4 and 8 for `mini' focus groups. Anticipating subject loss, you should over-recruit participants by approximately 25\%.

\paragraph{Participants} The purpose of a focus group is to obtain data regarding ideas, attitudes, understanding, and perceptions on a specific topic, and choosing participants that can contribute to this purpose is an important part of identifying the right participants. You should therefore select participants based on their experience and interest in the topic, rather than through random selection. Although the potential range of participants might be limited by context – say, they come from a small organisational group – you should aim for as a diverse range of backgrounds, views, and experiences as possible.

\paragraph{Moderation} You will need a skilled moderator to guide the discussion. Moderators' key qualities include empathy, positive regard\footnote{This denotes a general affirming caring, and supportive attitude.}, being able to use pauses and probes effectively in the group discussion, and exercising control in an unobtrusive manner. If you do not have access to a skilled moderator, then accessing moderator training for yourself might be desirable\footnote{There are videos purporting to guide moderators on youtube.}.

\paragraph{Location} Focus groups can be run online or participants can be physically co-located. For the latter, placing participants within an uncomfortable environment is likely to lead to negative outcomes. Given that a focus group might last for an extended period, appropriate timing should also be considered, with access to comfort facilities, etc., and an explicit timetable which includes breaks.

\paragraph{Choice of questions} Focus groups are sometime referred to as group interviews, in the sense that the moderator seeds and controls the discussion by asking questions. It is important therefore that you consider which questions to ask, including opening questions to get the discussion going, or questions to probe further and to ensure all participants get involved. Open-ended questions are the norm in focus groups as the intention is to elicit insights, attitudes, opinions and perceptions. 

\paragraph{Discussion etiquette} You will need to establish an etiquette for the group discussion, including expected participants' behaviour, for instance in addressing each other, taking turns when speaking, whether mobile devices should be switched off, etc. 

\paragraph{Recording the discussion} Usually video or audio recordings are used to record the group discussion, so you will need explicit consent from the participants. Note taking is possible but only if there are separate moderators and recorders.

\subsection{Other things to think about}\label{ssect:FocusGroupsOtherThingsTo}

To conduct successful focus groups you must also be aware of:

\paragraph{Groupthink} This a tendency to conform to majority opinion to maintain unanimity and avoid confrontations. Groupthink may inhibit discussion and the expression of diverging views, which rather defeats the point of a focus groups where you aim to elicit diverse views from participants. As a moderator you can mitigate against groupthink by asking probing questions, ensuring that a plurality of views are expressed, or playing devil's advocate in relation to prevailing ideas.

\paragraph{Social desirability bias} This is the tendency of participants to express opinions which they think are more likeable or acceptable by the group, even if they are not honest accounts of their views or experiences. As a moderator, you can mitigate against this bias by framing a question in an hypothetical or indirect manner, to distance it from the participant's personal experience, the latter being something they may be reluctant to share. Establishing an atmosphere of trust, anonymity and confidentiality can also help participants be more open and honest.

\paragraph{Group dynamics} Group culture and power relations, and participants' personality may also introduce bias and affect the end result. For instance, shy participants or introverts may feel overpowered and intimidated by assertive participants, whose views may then become prevalent. You, as a moderator, have the task to ensure that all voices are heard, possibly by calling out shy participants individually, or time-limiting contributions to prevent the most talkative participants from taking over. Larger groups may be more difficult to manage and control, so choose the size of your focus groups wisely.


\subsection{Further reading}\label{ssect:FocusGroupsFurtherReading}

\ResGenExtras{focus groups}{{powell1996focus}{smithson2000using}{plummer-damato2008focus}}

%https://www.eiu.edu/ihec/Krueger-FocusGroupInterviews.pdf

\section{Delphi}\label{sect:Delphi}

With the {Delphi} method\footnote{Also called Delphi technique in the literature. Its name is a reference to the ancient Greek temple that hosted the Oracle of Delphi, famous for her prophecies.}, a group of experts are consulted individually by the researcher with a view of obtaining a consensus on a particular issue, problem or topic. 

This method is based on the assumption that a group of experts are more likely to arrive at an informed and valid position than an individual, due to their diversity of knowledge and experience. It involves an iterative process of collecting, synthesising and circulating anonymous judgements among those experts to arrive eventually at a consensual view. At each iteration the experts can revise their opinion in light of what has emerged in the previous iteration. Anonymity is used to ensure that no individual expert exercises undue influence on the other experts, hence  mitigating against groupthink, and that all participants feel free to express their opinions without any fear of judgement or criticism, hence mitigating against social desirability bias. 

%\ResGenTechnique{the Delphi method}

The Delphi method is suited to situations where it important to access collective expertise due to paucity of relevant published knowledge, particularly to inform decision making, policy creation, risk management or forecasting.

\subsection{Operational considerations}\label{ssect:DelphiOperationalConsiderations}

To apply this method you need to consider:

\paragraph{Selecting experts} You should select participants based on their knowledge and experience in relation to the issue, topic or problem under study --- this is purposive rather than random sampling. You should also ensure a diversity of experts to capture the breadth of expertise, hence to generate valid outcomes. Between 10 and 50 experts are usually selected to participate in a Delphi study, although both smaller and bigger numbers have been used in studies reported in the literature. The more participants, the more resource-intensive the process of collecting, analysing and combining feedback is going to be.

\paragraph{Process} Maintaining anonymity is essential throughout the process. Initially, you should consult each expert separately, then anonymises and aggregates the group responses and circulate them to the same group of experts to seed the next round of consultation. Providing feedback at each round is the essential mechanism to foster convergence of opinions, as such feedback is used by each expert to review and refine their own opinions or judgements. In theory, you should repeat this process over multiple rounds until a consensus is reached. Practically, there will only be a limited research time over which you can iterate the process, so you must decide how many iterations you can realistically have. For this, you should also take the experts' availability into account, and their possible fatigue resulting from too many iterations.

\paragraph{Consensus criteria} You must establish explicit criteria to decide when consensus is reached. This may be as simple as establishing a threshold, say when a certain percentage of the experts agree\footnote{A 75\% threshold is often used in the literature.}.

\paragraph{Location} The method is usually executed remotely as there is no direct interaction between the experts.

\subsection{Other things to think about}\label{ssect:DelphiOtherThingsTo}

To be successful, you also need to consider:

\paragraph{Participants' commitment} This method is resource intensive and you must ensure your participants' commitment for the whole duration of your study. If this is not possible, then a focus group may be a better option.

\paragraph{Lack of discussion} There is no direct interaction or discussion among the experts, and you, as the researcher, controls and mediates the feedback at each iteration. If your research requires a deeper investigation of ideas, then you should consider alternative methods, like interviews or focus groups.

\paragraph{Difficulty in reaching consensus} Consensus may be difficult to reach, particularly, if you are investigating a particularly complex or contentious issue, or you are hoping for predictions concerning highly uncertain or volatile contexts. In such cases, you should reflect of the extent consensus is needed in your research and, if not, then consider alternative methods which may allow you to explore alternative or contrasting views and positions.

\subsection{Further reading}\label{ssect:DelphiFurtherReading}


\ResGenExtras{focus groups}{{skulmoski2007delphi}{skinner2015delphi}}



\section{Journaling}\label{sect:journaling}

Journaling is a method requiring participants in a research study to keep regular written personal records in the form of a diary\footnote{Or journal, hence the name.} of their experiences and observations during the study. Participants are encouraged to engage in self-reflection and reflexivity in order to surface their inner thoughts, feelings, motivations and perceptions.

%\ResGenTechnique{journaling}

This method generates rich and detailed qualitative data on the participants' subjective experience. It allows you to collect data on everyday experience in naturalistic settings and can provide deep insights into complex phenomena, including how things change over time Because of these characteristics, it is often applied in ethnographic and grounded theory research.

\subsection{Procedural considerations}\label{ssect:journalingProceduralConsiderations}

%The two uses of journaling lead to two related but different workflows.
%
%\paragraph{For research participants}
%
In applying this method you should consider:

\paragraph{Diary form} Journaling can make use of either hand-written or digital diaries\footnote{Of course, accessing hand-written notes will be more labour intensive than electronic ones.}. One or more diaries can be used for different aspects of the journaling process. 

\paragraph{Prompts and guidance} As a researcher, you should establish the goal of the self-reflection at the beginning and explain it clearly to the participants. This is because a lack of guidance or of clear instructions are likely to lead to irrelevant, inconsistent or incomplete data. You can use journaling prompts to ensure that diary entries align with your research objectives, guiding participants towards diary entries that will be useful to the research. Prompts can take the form of questions or comments on such entries. 

\paragraph{Participants} Journalling is demanding for participants as maintaining regular diary entries over lengthy periods can be challenging. Therefore, it is essential that you recruit participants willing to commit to journaling for the duration of the study. In addition, you should monitor their engagement with journaling, and perhaps re-stating research goals and prompts from time to time to help them refocus their effort as necessary.

\paragraph{Managing data} Journaling can generate large volumes of data from multiple participants, which must be managed carefully and also raise issues of confidentiality, privacy and more generally data protection. As a result it is essential that you establish a systematic approach to storing and backing up the data, whether physical or digital. 


\subsection{Other things to think about}\label{ssect:journalingOtherThingsTo}

For a successful execution of the methods you should also be aware of:

\paragraph{Subjectivity and bias} Participants are in control of their diary entries, which, as a result are influenced by their emotions, beliefs, preconceptions and cognitive limitations. These, in turn, lead to a number of well recognised biases such as confirmation bias -- focusing on evidence in support of prior beliefs, memory and recall biases -- difficulties in remembering or reporting accurately past events, or social desirability bias -- only making entries deemed socially acceptable or desirable. Awareness of such biases and the use of triangulation may help guard against those weaknesses.

\paragraph{Limited generalisability} Diary entries are personal, subjective and usually specific to a particular context or setting. As a results, there may be limited scope for generalising findings based on journaling. If generalisation is an important goal of your research, then you should consider different data generation methods, like questionnaires involving random sampling.

\subsection{Further reading}\label{ssect:journalingFurtherReading}

\newcommand{\ed}[0]{Ed}

\ResGenExtras{journalling}{[\ed]{kadarisman2017classroom}{burns2009action}{james2005journaling}[p55]{peoples2020write}[]{feinblum2016journaling}[]{hayman2012journaling}{mcgrath2021journalling}{taylor2006research}[\ed]{ovens2020weaving}{giguere2012self-reflective}{bacon2014journaling}}

%\endinput

\section{Fieldwork}\label{sect:fieldwork}

Fieldwork is a data generation method which requires the researcher to collect data directly in a natural setting\footnote{The `field', hence the name.}. The goal is to gain firsthand knowledge of the phenomena under study, and the method is widely applied across many disciplines, including anthropology, sociology, archaeology, geography or environmental science. 

Wolcott \cite{wolcott2005fieldwork} offers this salutary advice about fieldwork: 
%
\blockquote{There may be discomfort and hardship aplenty connected with the experience, ranging from the distractions of diarrhoea or lost luggage to the despair of personal failure or lost hope, but the extent of one's suffering and sacrifice are not factored into judgments about the worth of the fieldwork as fieldwork.}


That said, fieldwork is not confined to exotic, distant locations\footnote{Although fieldwork may have this characteristic for some lucky researchers.}! Instead, you can apply it in all natural settings, including, say, your own university or workplace.
%\ResGenTechnique{fieldwork}

Through fieldwork you can generate rich, contextualised data to provide deep insights into the phenomena under study. It is particularly suited to situations in which such data cannot be obtained in any other way, and may also lead to unexpected discoveries. 

The way such data is generated will depend on the nature and context of the phenomena under study, so that many choices are possible. For instance, you may collect samples and specimens, or make observations and measurements, or provide detailed descriptions of your direct experience in the field, including those from participant observations of social phenomena\footnote{This also means that fieldwork may rely on other data generation methods.}.

\subsection{Operational considerations}\label{ssect:FieldworkOperationalConsiderations}

Particularly for distant or exotic location, you will need to consider:

\paragraph{Logistics, equipment and budget} Depending on where the field is located, fieldwork may require some detailed planning addressing travel arrangements and accommodation, as well as access to the research site. If in a foreign country, all sort of factors must be considered, including the local transport networks, administrative processes you may need to go through, the climate, etc. You may also need specialised equipment on site, say field equipment and tools for data collection, alongside your personal protection. This can all be quite expensive, so that careful budgeting and securing the required funding in advance is essential.

\paragraph{Permissions and ethical issues} If access to the field of interest is restricted, then you will need to gain appropriate permissions to proceed from the relevant authorities. This covers anything from obtaining permits and licences to access, say, an archeological site, to permission from your employer to perform participant observations in your workplace. The time and effort to obtain such permissions must be considered upfront, and all ethical and legal implications factored in. In addition, your study must be conducted in full respect of local culture and norms.

\paragraph{Health and Safety} In working in the field, you, and anybody else participating in the research, may be exposed to all sort of hazards, so that assessing and mitigating health and safety risk is paramount. This may involve the introduction of safety protocols, of suitable training, and appropriate contingencies in the case of an emergency.

\paragraph{Managing data} Fieldwork can generate large volumes of data, and may also include precious samples and specimens. All that is collected must be managed carefully, so that alongside issues of confidentiality, privacy and more generally data protection, you may also have to worry about the physical security of those samples and specimens. For this, you will need a systematic approach to storing, protecting and backing up your data, whether physical or digital. 

\subsection{Other things to think about}\label{ssect:FieldworkOtherThingsTo}

To be successful with fieldwork, you should also consider:

\paragraph{Quality of results} The quality of results obtained from fieldwork depends on the data generated in the field, which, in turn, depends upon your skills as a field worker in relation to the specific data generation methods you applied. For instance: using standardised measuring tools will increase the reliability and accuracy of measurements; a reflexive approach will help mitigate against your own personal bias, including confirmation bias; triangulation may guard against observer and social desirability bias in participant observations, etc. Whichever method you choose to apply in your fieldwork, you should ensure you are aware of their potential weaknesses and adopt appropriate strategies to mitigate their effect on the outcomes of your research.

\paragraph{Logistical challenges} The logistical challenges to organise fieldwork may well be beyond what you can address in the limited time of your research project, unless you are able to contribute to a wider research effort, perhaps led by your supervisor, where all logistical issues have already been dealt with.

\paragraph{Time and cost} Fieldwork can be time consuming both for data collection and analysis, and expensive if travel is required. If time or cost are an issue in your project, then you should consider more time efficient or cheaper alternatives.

\subsection{Further reading}\label{ssect:FieldworkFurtherReading}

\ResGenExtras{field work}{{wolcott2005fieldwork}{randall2007fieldwork}}

\citeauthor{wolcott2005fieldwork}'s book is both detailed and entertaining. Reading it gives on a feeling that spending time in fieldwork with \enquote{Harry} would have been an education in itself. The book includes the importance of laundry to fieldwork, for instance, with experiences of fieldwork in a Canadian Indian reserve to illustrate.
According to \textcite{wolcott2005fieldwork}\footnote{\citeauthor{wolcott2005fieldwork}'s book is both detailed and entertaining. Reading it gives on a feeling that spending time in fieldwork with \enquote{Harry} would have been an education in itself. The book includes the importance of laundry to fieldwork, for instance, with experiences of fieldwork in a Canadian Indian reserve to illustrate.}, 
\ResGenExtras{field work}{{wolcott2005fieldwork}{randall2007fieldwork}}

\section{Documents}\label{sect:documents}

Existing documents can be used as data sources in order to develop new insights or answer research questions.

%\ResGenTechnique{documents}

The term `document' is used here in a broad sense to refer to all text-based documents, but also audio-visual materials -- such paintings, maps or photographs, video and audio recordings, and any digitally stored information. As a researcher, documents – in the form of academic articles – will already occupy a large proportion of your time/brain/computer. Your collection of academic papers could currently be as many as 50 or more. You will, therefore, already have good experience of interacting with documents and those interactions may well have already helped you gain valuable insights for your project. 

Researchers examine and interpret documents systematically to extract meaningful information. The documents may be of interest because of their content, or their relation to other documents, or could be studied to discover what they may reveal about their authors, or the historical or cultural context in which they were created. Therefore, a researcher's may have a direct interest in the factual content of a document, or be interested in what that content may indirectly say about some other phenomena of interest. An example may help clarify the difference between these two modes. 


\begin{example}{Extracting different meanings from documents}
This is a copy of a passage from \textcite{fynes1873miners}:
%
\quotation{Miner :– I believe you have something like 150 collieries to inspect?

Mr.~Dunn :– Yes.

Miner :– Twenty-eight in Cumberland?

Mr.~Dunn :– Yes.

Miner :– Do you think you are able to inspect all these? 

Mr.~Dunn :– Well, the Government thinks I am able, you know.

Another Miner :– Were you satisfied with the one shaft at this colliery, if so there is an end to the matter; if not, what steps did you take to remedy the defect? Did you apply to the Secretary of State, showing him that it was defective?

Mr.~Dunn :– At this very moment there are three of the largest collieries in Northumberland – Seaton Delaval, North Seaton, and Newsham – managed by the most talented men in Northumberland, all with single shafts. Now, what would you have me to do? Do you think it is my duty to call in question the management of these pits?

Miner :– Am I to understand this is an answer to my question?

Mr.~Dunn :– Well, I am not so well satisfied as if they had two, but I have not the power to alter it.}
\\

Such a passage could be considered in two ways. A direct reading could be to identify collieries in which a single shaft existed at that time. An indirect reading could be to explore social relationships within a mining community in 18th century England.
\end{example}

Document-based research provides the researcher with evidence of historical events or social phenomena, including nuanced details and perspectives that may not be available through other means. In particular, documents allow you to access data pertaining to different time periods, locations and cultural contexts. 

\subsection{Procedural considerations}\label{ssect:DocumentsProceduralConsiderations}

To apply this method you should consider:

\paragraph{Accessing documents} You need to ensure you have access to the documents you need for your research. While documents are increasingly digitised and easily accessible online, it is also the case that access for many may be restricted by either policies or physical restrictions -- say you wish to study restricted confidential documents in an organisation, or access rare or ancient manuscripts kept in a museum. Ensuring you have the right access at the right time in your project is essential, but can be time consuming, particularly if there are bureaucratic processes you need to go through. Related to access are issues of translation if the documents are in a language you are not familiar with, or transcription, if your sources are audio or video recordings. As well as being time consuming, these processes may introduce errors which may be difficult to spot. Lastly, it is essential you ensure that your documents are authentic: only using trusted sources is a way to do so.

\paragraph{Selection criteria} You must develop clear and explicit selection criteria to decide which documents to include in your study, based on your research problem, and aim and objectives. Such criteria should help you collect an appropriate and representative selection of documents for your research, guiding you in what to include and what to leave you. 

\paragraph{Data management} Alongside generic issues of data storage, protection and privacy, you also need to ensure that your source documents remain easily accessible and that their integrity is maintained: this is both to allow you to revisit those documents repeatedly during your study, and  to allow other researchers to check your sources to verify and validate your findings. Whenever possible, you should digitise your source documents to enhance their accessibility and preservation.

%LR -- the rest is commented out as it is about analysis, which is covered more generally in under analysis methods

%Analytical Framework: Developing an appropriate analytical framework is essential for guiding the analysis of documents. Researchers may use thematic coding, content analysis, discourse analysis, or other methods to identify patterns, themes, and relationships within the documents and generate meaningful insights.
%
%In more detail, indirect and direct reading use the following techniques to classify and conceptualise documents for qualitative research:
%\begin{itemize}
%\item Studying the form, content, and function of documents
%\item Analysing the ways in which documents justify decisions, display hierarchies, and exercise agency
%\item Distinguishing between primary sources (documents providing raw data) and secondary sources (documents providing information about primary sources)
%\end{itemize}
%

%As we have already mentioned, direct interaction with documents is already something with which you are\footnote{Or, should be!} familiar. However, according to \textcite[p.~370]{coffey2014analysing}\footnote{Freely available from \citeurl{coffey2014analysing}.}, a good place to start in analysing documents is with the realisation that documents are \enquote{socially defined, produced, and consumed} so that, alongside the content, the processes by which a document is produced and is intended to be consumed, i.e., by which it becomes an \enquote{accomplishment} for some individual or organisation, often contain useful data.
%
%In this case, there are many approaches possible from the simplest – counting instances, for instance, of words, phrases, or other elements\footnote{\textcite{mckenzie1959shakespearian}, for instance, counts commas – as well as other punctuation – in Shakespear's \emph{first Folio} to help identify which compositors were responsible for which parts of it.} – and indexing and coding document elements to identify thematic content and identify patterns, ala \textcite{schreier2014qualitative}. 
%
%\citeauthor{schreier2014qualitative}'s approach, a type of the more formal \emph{qualitative content analysis}, involves the selection of material from a wide range of source with adequate coverage for the topic of interest. As such it can result ing large amounts of material to analyse and so an element of formal in the process is mandated. An important step in this is the building of a \emph{coding frame}, i.e., a structure consisting of \emph{main category} and two \emph{sub-categories}~\parencite{schreier2014qualitative}:
%%
%\begin{itemize}
%\item a main category\footnote{Coding frames with more than 40 main categories are known to be difficult for one person to handle at one time.} being those aspects of the material that interest the researcher, 
%\item a subcategory being what is said in the material with respect to a main categories.
%\end{itemize}

%\paragraph{Coding for keeps} once you're convinced that your coding frame is stable, you then apply it to \emph{all} documents. This will involve:
%%
%\begin{itemize}
%\item  paying attention to how documents are constructed as distinctive artefacts, their structure, vocabulary, level of formality, etc. \parencite[p.~5]{coffey2014analysing}
%\item analysing their form and content, considering how they were produced and how they were – and how they were intended to be – consumed
%\item considering the relationships \emph{between} documents, highlighting dimensions of similarity, comparison, contrast, and difference by tracing how texts refer to other texts, sharing conventional formats, and constructing a uniform style\footnote{This scaled \emph{Intertextuality} in the literature~\parencite[p.~8]{coffey2014analysing}; it's akin to how you went about analysing the academic literature as part of your literature survey.}
%\item exploring the ways in which they function and are used in everyday life and social context
%\item examine their formal properties, including their linguistic registers, and rhetorical features.
%\end{itemize}

%\paragraph{Presenting your findings} can be as simple as delivering the statistics that you have collected as the basis for further analysis. Alternatively, a completed coding frame  with an accompanying narrative and example quotes as needed could be the output. Like other data, your coding frame can also be the starting point of further data generation and analysis, \textcquote{schreier2014qualitative}{examining the results [...] for patterns and co-occurrences of selected categories.}

\subsection{Other things to think about}\label{ssect:DocumentsOtherThingsTo}

To be successful in document-based research you must also consider:

\paragraph{Bias in documents} Documents are created by people, who necessarily inject their own personal bias into their content\footnote{So called `creator' bias.}, which in turn is the result of their historical, cultural and social contexts\footnote{Another bias, called `contextual' bias.}. In addition, particularly in the case of ancient manuscripts, the documents that have survived may only provide a partial historical account\footnote{You'll have guessed there is a name for this too, which is `survivorship' bias.}. Therefore, you must choose your selection criteria wisely to ensure a diversity of sources and guard against selection bias, which may lead to certain positions, perspectives, or types of documents to be either overrepresented or underrepresented. Being aware of all these biases is essential to the interpretation of documents content and how they may skew or limit your research results. 

\paragraph{Interpretation challenges} Documents are unlikely to provide a complete picture of the phenomena under study, partially due to their inherent biases, but also because they may be incomplete or lack crucial details or contextual information may not be available to you. Also certain phenomena may be more documented than others, so that the availability and quality of documents can vary widely across topics, history or geography. All these factors affect your ability as a researcher to interpret their content and draw robust conclusions.

\paragraph{Time and effort} Document-based research may require large volumes of materials to be selected, collected and analysed, so that it can be very time-consuming. If time is an issue in your project, then you should consider alternative data generation methods.

\subsection{Further reading}\label{ssect:DocumentsFurtherReading}

\ResGenExtras{documents based research}{{coffey2014analysing}{schreier2014qualitative}}

\chapter{Modelling methods}\label{ch:ModellingMethods}

So far we have discussed methods which can help you generate data from either direct observations or experience (whether yours or of other research participants'), or from secondary sources. Once generated, you can organise and analyse such data are organised by applying data analysis methods, which we will consider in the next chapter.

Somewhat in between data generation and analysis are modelling methods, whose aim is to help you build models of natural, social or artificial phenomena, that you can then use for analysis, prediction or decision making, including informing the design and engineering of new artefacts. Such models need data to inform their development and, in turn, generate new data for analysis. Modelling methods support a variety of research strategies including simulation and design science research, but also case studies in which models of socio-technical systems may be useful for investigation.

At its essence, a \gloss{model} is a representation of something, be that a system, a structure, a process or a behaviour. Possibly the most important thing to remember about modelling is expressed by the following oft-cited aphorism\footnote{Box, George E. P. (1976), \enquote{Science and statistics} (PDF), Journal of the American Statistical Association, 71 (356): 791--799.}:

\begin{quotation}
	\textit{All models are wrong, some are useful} (Box, 1976)
\end{quotation}

which makes clear that a model should not be regarded as a faithful replication of some  reality, but as a tool to investigate some aspects of that reality.

At the core of modelling is a process of \emph{abstraction} which starts from an understanding of what is to be modelled and ends with the definition of the desired model. The nature of both determines the kind of thinking required in the abstraction process. 

In this chapter, we focus on the modelling methods summarised in~\Cref{tab:modellingMethodsChoice}  and provide similar descriptions as we did for the data generation methods of~\Cref{ch:DataGenerationMethods}.

If your chosen research methodology does not include modelling methods, then you can skip this chapter and move on to the analysis methods in~\Cref{ch:AnalysisMethods}.

Otherwise it's the time to consider your modelling methods in detail to ensure they are the right ones for your project, and to apply them to your research. The next two activities will help you do that: they very substantial activities which will allow you to take a significant step in your research.

\begin{question}[subtitle={Activity: Finalising your modelling methods}]
 Consider your chosen modelling methods. For each, read through the related section in this chapter (see~\Cref{tab:modellingMethodsChoice}), and write a summary including the following points:
 \begin{itemize}
 	\item explain why it is an appropriate method for your project, in relation to your aim and objectives, your chosen research strategy, the data sources at your disposal, and your relevant technical skills 
 	\item if there are variants of the method, indicate the one you will apply and why 
 	\item detail your procedures in applying the method within your project
 	\item indicate how you will guard against potential research weakness intrinsic in the method
 	\item discuss your choices with your supervisor to ensure they are appropriate for your project.   
 \end{itemize}
\begin{guidance}
This activity assumes that you have completed a draft of your methodology which includes your chosen research strategy and possible research methods within. If that's not the case, then you should return to Stage 3 and complete the activity in~\Cref{ch:yourResearchMethodology}.

For each method, conduct a first pass at addressing each of the points based on the content of this chapter, then follow some of the references provided to read more about the method and improve your summary. Your supervisor should also be able to point to relevant literature or provide expert advice on the application of the method.

By procedure we mean the specific steps you will take to ensure the method is applied correctly and you have guarded against potential weaknesses. In your dissertation, your procedures should be sufficiently detailed for other research to follow what you have done or even replicate your work independently. 

You may have to iterate with your supervisor to refine your choices and procedures.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

%%%Intentionally \ref, not~\Cref
%\newcommand{\tick}{$\Box$}
\begin{SimpleNColTable}{tab:modellingMethodsChoice}{2}{Modelling methods in this chapter}[X[1]X[1]|]
	Method & Section\\
	Computational thinking&\Cref{sect:ComputationalThinking}\\
	Mathematical thinking&\Cref{sect:MathematicalThinking}\\
	Statistical thinking&\Cref{sect:StatisticalThinking}\\
	Systemic thinking&\Cref{sect:SystemicThinking}\\
\end{SimpleNColTable}

At the end of this activity you should be ready to start modelling. 

\begin{question}[subtitle={Activity: Applying your modelling methods}]
 Apply your modelling methods by following the procedures you have outlined and agreed with your supervisor. You should:  
  \begin{itemize}
 	\item proceed incrementally, checking at each increment that your modelling choices are still appropriate
 	\item document any deviation or adjustment you may have to make in executing your methods
 	\item ensure you manage different model increments and versions appropriately
 	\item establish regular checkpoints with your supervisor to review your modelling process and outcomes, and to agree any required adjustment. 
 \end{itemize}
\begin{guidance}
The kind of incremental process you can follow will depend on the method you will apply. For instance, you may be able to split a computation model into different functionalities, which you can then code and integrate in subsequent increments.

Regular monitoring and adjustments are essential: it is highly unlikely that things will go exactly as you originally planned them!
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}



\section{Computational thinking}\label{sect:ComputationalThinking}

Computational thinking is needed when the end point is a model in the form of a computational artefact, that is something that a digital computer can execute\footnote{Computational thinking has a much broader scope than what is reported here. For instance, it underpins learning and curriculum in Computing-related disciplines, as well as professional skills in related industries.}. 

%\ResModTechnique{computation thinking}

Computational thinking is a problem solving approach in which problems are explored with a view to identify and implement computational solutions in the form of computer programmes and systems. In addition to writing code that a computer can execute, computational thinking involves a wide range of cognitive processes such as being able to think at different levels of abstractions, to decompose problems into sub-problems, to identify useful patterns and structures in data, to conceptualise logical steps the computer should take alongside how people may interact with those programmes and systems.  

Computational artefacts are becoming more and more prominent in academic research, which both makes use of existing ones and develops new, bespoke ones to advance knowledge. 



%The techniques generally associated with computational thinking are:
%%
%\begin{itemize}
%\item Decomposition: breaking a problem into parts that are easier to solve;
%\item Pattern recognition \& Generalisation: seeking significance from repeated structures within data
%\item Abstraction: building higher level representations of things
%\item Algorithms: associating behaviours with computational structures
%\item Evaluation: called testing for software, but also has wider applicability when an algorithm is socialised, i.e., used within its final social context.
%\end{itemize}


%Clearly, part of computation thinking is programming a computer to achieve a goal. 
%
%However, \citeauthor{wing2006computational}\footnote{\citeauthor{wing2006computational} is American, and so uses American spelling – -i\textit{z}i-, art\textit{i}fact, etc.}, in her \citeyear{wing2006computational} article that popularised Computational Thinking~\cite{wing2006computational} as a candidate curriculum entry, places programming in the broader context of computational thinking. If you are aiming at computational thinking as a way of focussing on your programming skills, it may be that you have misjudged this wider context. 
%
%\citeauthor{wing2006computational} says:
%
%\noindent\emph{Computational thinking} [...] has the following characteristics\footnote{\citeauthor{wing2006computational} includes other characteristics, of relevance to curricula but not so much to research.}:
%
%\begin{description}
%\item [conceptualising] Computer science is not [just] computer programming. Thinking like a computer scientist means more than being able to program a computer. It requires thinking at multiple levels of abstraction; 
%%
%%\item[Fundamental, not rote skill.] A fundamental skill is something every human being must know to function in modern society. Rote means a mechanical routine. Ironically, not until computer science solves the AI Grand Challenge of making computers think like humans will thinking be rote; 
%%
%\item [A way that humans, not computers, think.] Computational thinking is a way humans solve problems; it is not trying to get humans to think like computers. %Computers are dull and boring; humans are clever and imaginative. We humans make computers exciting. Equipped with computing devices, we use our cleverness to tackle problems we would not dare take on before the age of computing and build systems with functionality limited only by our imaginations; 
%%
%\item [Complements and combines mathematical and engineering thinking.] Computer science inherently draws on mathematical thinking, given that, like all sciences, its formal foundations rest on mathematics. Computer science inherently draws on engineering thinking, given that we build systems that interact with the real world.% The constraints of the underlying computing device force computer scientists to think computationally, not just mathematically. Being free to build virtual worlds enables us to engineer systems beyond the physical world; 
%%
%\item [Ideas, not artifacts.] It's not just the software and hardware artifacts we produce that will be physically present everywhere and touch our lives all the time, it will be the computational concepts we use to approach and solve problems, manage our daily lives, and communicate and interact with other people.%; and
%%
%%\item [For everyone, everywhere.] Computational thinking will be a reality when it is so integral to human endeavors it disappears as an explicit philosophy.
%\end{description}
%
%Recognising the social context of computational thinking is, thus, critical to research in the area.

\subsection{Procedural considerations}\label{ssect:ComputationalThinkingProceduralConsiderations}

Given the explosive growth in the use of computers over the past half century, you may not be surprised to hear that there are thousands of useful\footnote{As well as some that are less than useful!} tools to support computational thinking. They vary in many of their characteristics, so that you will need to make some judicious choices for your project. In particular you will need to consider:

\paragraph{Programming language and paradigm} This concerns the language you will use to express your code, and its underlying philosophy\footnote{You may have heard of Phyton, C or Java. These are just few of the many choices of programming language available! Each language embodies some ontological assumptions as to the building blocks of code -- yes, philosophy comes into play into coding too!}.

\paragraph{Computational mode} This refers to the way computations take place in the implemented artefact, one of sequential, concurrent, distributed or agent-based. The latter is particularly suited to the simulation of complex systems made of many interacting, independent agents. While all programming languages allow you to develop sequential computations, specialised languages\footnote{You can look, for instance, at Petri Nets or NetLogo to get some ideas.} exist for the other modes. 

\paragraph{Delivery platform} This refers to where your computational artefact will be made available for use, be that the web, a mobile device, or some other bespoke hardware.

\paragraph{Integrated Development Environment (IDE)} This the combination of tools to help you develop and keep track of your code, including how it changes over time, and to perform tests to check its intended behaviour and to correct errors and mistakes. 	

\paragraph{Stakeholders and participants} These are all the people you may have to involve to tease out requirements\footnote{Which need will your artefact meet? Which characteristics should it have?}, validate your artefact or generate data by interacting with it.

\paragraph{Development process} This is the process\footnote{Several schools of thought exist as to what constitute a good process to develop computational artefacts. You can look up Agile and Plan-driven development processes to get some ideas.} you will follow to determine what your code should do, and to design, implement, test and release it for use.

%The main idea behind computational thinking is to link a wished-for behaviour to a computational structure. Here, we're thinking of the wished for behaviours of a client in context being translated to an algorithm, data model, or other computational element. 
%
%The ways in which the wished-for behaviour of a client in context are understood is through the discipline of requirements analysis. Although naive requirements analysis is possible for simple projects – asking a client what functional behaviours they need – it is more often driven by the explicit or implicit management or developmental risk, the risks being those of 
%

\subsection{Other things to think about}\label{ssect:ComputationalThinkingOtherThingsTo}

Some key considerations include:

\paragraph{Foundational knowledge} If you don't have any experience of computational thinking or writing code, then you can learn, but the learning curve is going to be very steep. Unless you have direct access to experts to guide you, you will need to consider very carefully whether you will be able to achieve the proficiency you will need within the timeline of your project. 

%\footnote{This video will give you some idea of what will be required: \url{https://www.youtube.com/watch?v=fLMZAHyrpyo}. Stephen Wolfram is a particularly interesting, if restless, speaker and a leader in this area.}\todo{But this isn't a great video, nor is any other that I've looked at, as they're created by computer scientists... They're also heavily advertise laden.}. 

\paragraph{Model validity} You need to worry about two key aspects of validity when developing computational models. One is internal, and concerns the issue of whether you have made mistakes in your code: appropriate code review and testing techniques can help you take care of this. The other is external, and concerns the relation between the model itself and the reality it means to model. In order to establish this, you will need to address several issues including:
		\begin{itemize}
			\item how well it fits the context in which it is eventually installed	
			\item how well it addresses the problem(s) it is meant to solve, and
			\item how well it meets stakeholder's expectations, including existing professional quality standards.
		\end{itemize}

\paragraph{Timing issues} Developing computational model can be very time consuming, particularly when you need to interact with many stakeholders as part of the development, which may then require you to iterate between coding and validation several times. If you are not confident you can accommodate such a development effort within your project, then you should consider other methods or reduce the scope of your model. 

\subsection{Further reading}\label{ssect:ComputationalThinkingFurtherReading}

\ResGenExtras{computation thinking}{{angevine2017computational}{figueiredo2017improve}{lyon2020computational}}

\section{Mathematical thinking}\label{sect:MathematicalThinking}

Mathematical thinking is problem solving with Mathematics. It has had many centuries more than computational thinking to develop and the tools that exist as part of it are very stable. They are also much better explored due to the efforts of many great mathematicians. However, they do require a high level of skills and sophistication in their application to achieve their full potential. 

%\ResModTechnique{mathematical thinking}

Although mathematical techniques can apply to real-world problems, they tend to create \emph{closed form} solutions, that is solutions which can be calculated exactly from mathematical expressions. For instance, systems of differential equations are widely used in Finance to model fluctuations on stock or investment markets. As long as a real-world problem can be captured in this way, then a mathematical model is feasible. However, many real-world problems do not admit such characterisations, so that there are limitations as to what you can treat mathematically. 

Note that there is a strong connection between mathematical and computational thinking in that lots of mathematical models are now implemented as computational algorithms executed by computers. These, however, require some \gloss{numerical approximation} as computers cannot calculate exact values\footnote{Due to such approximations, there may be accumulated errors which also need to be taken into account.}.

%Similarly to computational thinking, mathematical thinking involves various cognitive processes:
%
%\begin{description}
%\item [Specialising] exploring a problem through examples. Each example provides the opportunity for manipulating elements that are concrete, whether they are physical manifestations or ideas.
%\item [Conjecturing] when enough such examples have been examined, you can conjecture about the relationships that connect them. Through conjecturing, underlying patterns are explored, expressed, and then substantiated.
%\item [Generalising] if you are lucky enough to have found a pattern, then you might try to generalise it to creating order and meaning out of a – potentially, overwhelming – amount of data.
%\item [Convincing] a generalisation must be tested until it is convincing to the reader – this is the basis of the knowledge contribution from mathematical thinking.
%\end{description}



%Mathematics has limits of applicability, some of which are extremely subtle, even in relatively simple situations: complete closed form solutions in radicals do not exist for problems as simple as finding the roots to polynomial equations of order 5\footnote{So called \emph{quintic equations}~\parencite{enwiki:1209364767}. A radical is a mathematical expression involving only the coefficients of the equation, and the basic arithmetic operations (addition, subtraction, multiplication, division, and taking the n\fmtord{th}-root).} or above; the general three body problem, for instance, being resistant to differential equation analysis; and others. 

%Alternatively, so called \emph{numerical approximations} can be made to most problems, but these are often related to computational solutions and so might be better approached through computational thinking.
%
%Another alternative that again takes us back to computational thinking, is the use of agent based simulations in which concurrently acting independent agents are used.\todo{More here.}
%
%Differential equations; matrices; algebra; numbers theory; sets; functions; relations; logics\footnote{\emph{Logics} is plural as there are many, depending on which area of mathematics you are using.}; topology; geometry; calculus; algebra; analysis; \todo{More here?}
%
%According to \textcite[, adapted]{burton1984mathematical}, there are four cognitive processes that are central to mathematical thinking: 

\subsection{Operational considerations}\label{ssect:MathematicalThinkingOperationalConsiderations}

To apply mathematical thinking you should consider:

\paragraph{Mathematical tools} This concerns the choice of the kind of Mathematics to apply, including notation, and symbolic and diagrammatic representations appropriate to the problem you are trying to address. 

\paragraph{Computational tools} Should you wish to use a computer to run your mathematical models, then you will also need to make many of the choices related to computational thinking\footnote{See~\Cref{ssect:ComputationalThinkingProceduralConsiderations}.}. Note that many modern programming languages and environments include a wide range of mathematical libraries which you can use directly in your code, so that you don't have to start your code from scratch, reducing substantially the time and effort required. Such libraries are also likely to have been tested extensively, hence their code should be error-free and highly reliable.

\paragraph{Relevant examples} Although you will need to be creative in applying mathematics to your own research problem, there may be relevant examples in the literature which can provide a good starting point. Working from simple examples to more complex ones may help you establish an appropriate mathematical approach.


\subsection{Other things to think about}\label{ssect:MathematicalThinkingOtherThingsTo}
%\endinput
For a successful application of mathematical thinking you must also consider:

\paragraph{Foundational knowledge} Mathematical thinking is arrived at through creative thinking and deep study of mathematical tools and techniques. The sophistication of mathematics often means that, either:
%
\begin{itemize}
\item a particular area of research has already been taken past the abilities of an entry-research-level mathematician;
\item it is not amenable to (current) mathematical tools and techniques, and further creative\footnote{And, most likely, deep and advanced, out of the box, out of this world, and further.} mathematical thinking will be necessary to progress.
\end{itemize}
%
Although neither of these characteristics are insuperable, they make timely contributions to knowledge through the application of mathematical thinking difficult. It's worth moderating your expectations of what can be achieved in your project – discussion with your supervisor of what their expectations are would be very worthwhile\footnote{What is often missing from the mathematical literature – or what isn't always visible to the new entrant – is the often vast timescales over which mathematical progress is made. Bertrand Russell and Alfred Whitehead spent over two decades of their professional lives in the creation of the three volume \emph{Principia Mathematica}. A fourth volume – on geometry – was begun but never completed. In another example, the proof of Fermat's Last Theorem took 358 years to complete.}.

%\begin{question}[subtitle={Activity: Understanding your supervisor's mathematical thinking expectations}] 
%	Schedule some time with your supervisor to discuss what they hope will be achieved through your research project.
%\end{question}
%%Hack to correct tcbox behaviour
%\color{black}


%Mathematics is a very tight community with very high publication standards. The language of mathematics is dense\footnote{A mathematical statement indicative of this complexity is: \enquote{Let q be $x^{5}-x-1$. Let $G$ be its Galois group, which acts faithfully on the set of complex roots of $q$. Numbering the roots lets one identify $G$ with a subgroup of the symmetric group $\mathcal{S}_{5}$. Since $q{\bmod {2}}$ factors as $(x^{2}+x+1)(x^{3}+x^{2}+1)$ in $\mathbb{F}_{2}[x]$...}.}.
%
%Because of this, many mathematical research projects at masters level are designed to provide a way into the mathematical literature. A supervisor will set a mathematical task that may already have been solved. The contribution a research student might make, then, is not a contribution to knowledge in the formal sense of extending mathematics, but the widening of the mathematical community to include another researcher whose skills have expanded to be able to make a novel restatement of a problem, for instance, and research further. 
%
%The study of the development of mathematical thinking, for instance, in schoolchildren is a very fruitful area with much still to be contributed.\todo{More here}
%

\paragraph{Limitations of mathematical abstraction} Mathematics abstracts from real-world complexity: in modelling traffic to improve flow through a complex junction, for instance, one would not necessarily consider the economy of individual cars, or the noise pollution created by a solution. This can reduce a real-world problem to a complexity that is approachable, but may also lead to non-solutions when applied back in the real world, for instance, leading to complaints from local home owners that noise pollution has risen through a solution. Therefore, you need to check you simplifying assumptions carefully against the real-world situation to avoid reaching invalid conclusions.

\subsection{Further reading}\label{ssect:MathematicalThinkingFurtherReading}

\ResGenExtras{mathematical thinking}{{stacey1982thinking}}


\section{Statistical thinking}\label{sect:StatisticalThinking}

Statistical thinking is problem solving with Statistics. You can use it to identify patterns, trends and relationships in data by using probabilistic reasoning, which acknowledges variability and uncertainty inherent in the data. 

%\ResModTechnique{statistical thinking}

Statistical thinking is particularly valuable for prediction and forecasting -- for instance, to predict the spread of a virus in a population or how the average house price may change in a geographical area and over a certain period of time, or to test hypotheses\footnote{We will introduce statistical tests in~\Cref{sect:inferentialStatistics}} -- for instance whether a medical treatment is likely to be effective. Statistical thinking is essential in quantitative analysis, which will cover in~\Cref{sect:statisticalAnalysis}.

%
%Statistical thinking\todo{Source: \textcite{chance2024statistical}.} involves designing a study to collect data, analyse patterns in the data, and draw conclusions that go beyond the observed data. Sampling is key to being able to generalise results, while random assignment is key for cause-and-effect conclusions. Probability models help assess random variation and estimate margin of error.



\subsection{Procedural considerations}\label{ssect:StatisticalThinkingProceduralConsiderations}

To build statistical models you need to consider:

\paragraph{Sampling} Statistical modelling requires relevant data, so that you have to consider how you will obtain such data. Sampling\footnote{See~\Cref{sect:sampling}.} is a standard way to do so, for which you need to worry about both sample size and the extent it is representative of the population of interest.

\paragraph{Data quality} You will need quality data for your models, that is data with no missing, inconsistent or erroneous entries. Typically, you will need to pre-process your data to ensure this is the case before applying any statistical technique. 

\paragraph{Choice of techniques} You will need to decide which statistical techniques to apply in relation to the research problem you are trying to address. Like Mathematics, Statistics too includes a vast repertoire of techniques applicable to different problems. If you do not possess sufficient expertise to be able to choose by yourself, then you will need to take expert advice, as applying inappropriate techniques will lead to invalid or misleading results.

\paragraph{Statistical software} The use of computational tools is the norm to support statistical thinking and many bespoke statistical software applications are available. In addition, many current programming languages and environments\footnote{E.g., R or Python.} come equipped with full libraries of statistical functions ready for use. These allow you to perform most statistical modelling and testing alongside data manipulation and visualisation with graphs and charts.

\subsection{Other things to think about}\label{ssect:StatisticalThinkingOtherThingsTo}

To be successful with statistical modelling you also need to consider:

\paragraph{Foundational knowledge} Statistical techniques can be complex and require specialised knowledge and skills to apply them effectively, particularly for advanced modelling, but also to provide meaningful interpretation of outcomes. As for mathematical thinking, unless you have sufficient foundational knowledge, you need to evaluate carefully whether you will be able to develop the required advanced knowledge and skills within the remit of your project.

\paragraph{Data bias} Even when your data are of good quality, they can still be biased in that they may over- or under-represent certain characteristics of the population of interest, leading to invalid or unreliable generalisations. For instance, if all data in a clinical trial for a new medicinal drug are from male participants, then the effectiveness or otherwise of the drug for female patients cannot be inferred from those data, so that any generalisation to the wider population may be unsound.

\paragraph{Confounding factors} Unfortunately, things can still go wrong even when you have good quality, unbiased data to start with. This may be due to {confounding factors} you may not have considered in your study. For instance, say you are interested in the possible relationship between physical activity and heart health. If you only focus on (some measures for) those two variables, you are likely to miss possible effects of, say, age and gender on heart health in addition to physical activity, and may, once again, infer the wrong conclusions. 

\paragraph{Model assumptions} Statistical models are usually based on specific assumptions made of data characteristics. For instance, many statistical tests assume that the data are normally distributed\footnote{We will cover these topics in~\Cref{sect:inferentialStatistics}}. It is therefore essential for you to check that all required assumptions hold, otherwise your model, and any conclusions you derive from it, may be invalid.

\paragraph{Ethical considerations} As statistical thinking relies on data, then ethical and legal issues arise in relation to how the data are obtained and used in your research, particularly around privacy and data protection. In addition, ethical issues arise in relation to  social implications of applying statistical thinking in decision-making, particularly when decisions are increasingly taken by algorithms. This can lead to inequality and discrimination, as demonstrated by some shocking cases which have been reported widely -- such as the COMPAS system, discriminating against black offenders, or the Amazon's recruitment algorithm, discriminating against women. 

\subsection{Further reading}\label{ssect:StatisticalThinkingFurtherReading}

\ResModExtras{statistical thinking}{{chance2024statistical}}

\section{Systemic thinking}\label{sect:SystemicThinking}

Systemic thinking\footnote{The term `systems thinking' is also used in the literature.} is yet another problem solving approach which focuses on systems and their dynamics. By \gloss{system} we mean a set of elements coming together in a complex whole and whose behaviour stems from the interaction of those elements. Any kind of system is in scope, whether natural, social or artificial, with systemic thinking aimed at understanding how the different elements influence each other and how the system behaviour emerges from their interaction. 

%\ResGenTechnique{systemic thinking}

Systemic thinking takes a holistic approach to understanding a system, encouraging different stakeholders' perspectives and a participative approach to develop a shared understanding. This also means that the enquiry process is iterative, with insights being revisited, reviewed and refined as more knowledge is acquired through ongoing analysis and interaction with stakeholders.

Like mathematical and statistical thinking, systemic thinking may be used in combination with computational thinking, for instance, to develop a better understanding of a system of interest before creating a computational simulation of it, or as an aid to prototyping novel computational artefacts.

Systemic thinking also relies on system models based on diagrammatic notations, of which there are a great variety. Among the most common are\footnote{This is by no means a complete list!}:

\begin{itemize}
	\item \emph{systems maps}, which allow you to sketch the structure of a system by identifying key components and sub-systems
	\item \emph{influence diagrams}, which extend system maps to show how those elements influence each other
	\item \emph{causal loop diagrams}, which are used to capture cause-and-effect relations, and particularly feedback loops in the system dynamics which affect behaviour over time
	\item \emph{stock and flow diagrams}, which augment causal loop diagrams with quantitative information that can be exploited in computational simulations
	\item \emph{UML (Unified Modeling Language) diagrams}, where UML is a standardised engineering modelling language specifically defined to capture and analyse various aspects of a software system\footnote{Although it is also used for other kind of design and engineering, beyond software.}, either in terms of its structure or behaviour.
\end{itemize}

\subsection{Procedural considerations}\label{ssect:SystemThinkingProceduralConsiderations}
When applying statistical thinking you need to consider:

\paragraph{Scope and boundaries} Before you start your investigation you need to define clearly the scope of your system of interest, its boundaries and the purpose of your analysis, to inform your data generation and interaction with stakeholders. Your analysis should encompass different system dimensions, say social, cultural, economical or environmental. 

\paragraph{Stakeholders} You need to decide who you will involve in your research, focusing on stakeholders with an interest and understanding of the system, and ensuring that a plurality of views and perspectives are represented. If you aim for some form of intervention on an existing system, then you must also ensure you involve stakeholders who will champion or support it. In all cases, you should encourage collaboration and communication among stakeholders, including exchanging knowledge and ideas to foster a shared understanding of the system.

\paragraph{Data generation} To generate your data about the system you can apply any relevant method from~\Cref{ch:DataGenerationMethods}. Likely, you will need both qualitative and quantitative data as you are aiming for a comprehensive characterisation and analysis of your system from a plurality of perspectives.

\paragraph{Modelling} You need to decide which notations to use to model key aspects of the system which are relevant to your research. You should also consider whether a computational simulation would be appropriate, in which case, you should review the operational considerations related to computational thinking\footnote{See~\Cref{ssect:ComputationalThinkingProceduralConsiderations}.}. For both, you will need to develop a certain level of expertise to be able to apply them effectively in your enquiry. This will require time, and ideally some expert guidance, which you must ensure are available within the constraints of your project.

\subsection{Other things to think about}\label{ssect:SystemThinkingOtherThingsTo}

For successful systemic modelling you should also consider:

\paragraph{Complexity} Analysing complex systems can be challenging, and taking a systemic thinking approach is time consuming and resource intensive due to the need for large amount of data to gather and protracted interactions with many stakeholders. You need to ensure access to both data and people for your systemic thinking enquiry to be meaningful.

\paragraph{Subjectivity and bias} As a system thinker, you establish the system boundaries, the perspectives to take, who to involve and how to gather and interpret your data. This leaves your research open to your own bias. Reflexive practices, alongside triangulation, say by cross-validating with independent data, are therefore necessary to support the validity of your findings.

\paragraph{Model validity} As for all modelling, your system characterisation will be based on simplifications and assumptions, which you will need to check careful with respect to the system being modelled. To validate both assumptions and resulting models you could apply triangulation, including asking independent experts to review them or compare model behaviour with real-world observations.  


\subsection{Further reading}\label{ssect:SystemThinkingFurtherReading}

\ResGenExtras{systemic thinking}{{simon2014systemic}}


%\endinput
%\section{Statistical thinking}\label{sect:StatisticalThinking}
%
%%\subsection{Statistical thinking tools}\label{ssect:StatisticalThinkingTools}
%
%Like mathematics, statistical thinking is a sophisticated discipline with much to offer the researcher. Statistics provides many tools of general applicability across the research process and some form of statistical thinking will apply to most quantitative research and in some qualitative research projects. To this end, we provide a separate section below on statistical modelling. 
%
%\ResGenTechnique{statistical thinking}
%
%\subsection{Workflow}\label{ssect:Workflow}
%
%\subsection{Other things to think about}\label{ssect:OtherThingsTo}
%
%\ResGenExtras{statistical thinking}{}

%\section{Reflexivity}\label{sect:Reflexivity}
%
%Reflexivity\todo{Sources: \textcites{dodgson2019reflexivity, may2014reflexivity,patnaik2013reflexivity,palaganas2017reflexivity, darawsheh2014reflexivity,macbeth2001reflexivity}.} involves the researcher describing the relationships between themselves and research participants, and is crucial for increasing the credibility of findings and deepening understanding. Researchers should be explicit about their biases and experiences as a means of demonstrating trustworthiness to readers. In addition, however, reflexivity also helps a researcher to recognise and take responsibility for their situatedness within the research, i.e., how they influence data collection and interpretation. The reflexive researcher should focus on self-knowledge, sensitivity, and understanding the role of the self for their knowledge contribution. 
%
%Introducing a **reflexive practice** into qualitative research allows researchers to examine the grounds of claims about the social world and explore the strengths and limitations of knowledge forms. This helps correct an instrumental approach to knowledge that seeks to control rather than understand the social world.
%
%\textcquote{dodgson2019reflexivity}{- **Qualitative research is contextual and occurs between two or more people in a specific time and place.**
%- **Researchers must describe the intersecting relationships between participants and themselves (reflexivity) to increase credibility and deepen understanding of the work.**
%- **Reflexivity is essential in qualitative research as the researcher's identity influences the findings.**
%- **Readers need to understand the researcher's positionality beyond their name and affiliations.**
%- **Researchers should address unconscious biases and continually evaluate their positionality.**
%- **Participator process enhances non-exploitive processes and minimizes power differentials.**
%- **Reflexivity involves self-examination and understanding one's situatedness within the research.**
%- **Researchers must be aware of power differentials inherent in the researcher/participant relationship.**
%- **Describing contextual relationships between participants and researchers increases credibility and understanding of the work.**
%- **Researchers need to focus on self-knowledge, sensitivity, and understanding the role of the self in creating knowledge.**
%- **Researchers' position as an insider or outsider is crucial in considering similarities and differences with participants.**
%
%Reflexivity in qualitative research involves the researcher being conscious of their own biases, positionality, and impact on the research process. It requires continual self-reflection and transparency in addressing these factors throughout the research endeavor.
%
%- Reflexivity is a process that permeates the whole research endeavor.
%- Researchers need to address reflexivity in substantive ways to inform the reader about their processes.
%- The issues surrounding researchers' reflexivity are many and complex.
%- Power differentials between participants and researchers pose challenges related to reflexivity.
%- Researchers must be explicit about reflexivity and continually address trustworthiness criteria.
%- Reflexivity involves a continual internal dialogue and critical self-evaluation of the researcher's positionality.}
%
%\textcquote{may2014reflexivity}{
%- Reflexivity in qualitative research allows for examining the grounds of claims about the social world and exploring the strengths and limitations of knowledge.
%- **Reflexivity involves investigating the relationship between the knower and the known through inquiry itself.**
%- Calls for reflexive social inquiry challenge the separation between subject and object.
%- **Reflexivity enables researchers to correct an instrumental approach to knowledge that aims to control rather than understand the social world.**
%- The document discusses different social scientific approaches to reflexivity and their implications for research practices.
%- **Reflexive spaces are explored through various forms of qualitative work conducted over the years.**
%
%Workflow: - Reflexivity involves turning back on oneself in order that processes of knowledge production become the subject of investigation.
%- It is a way of thinking or critical ethos that aids interpretation, translation, and representation.
%- Reflexivity is not a method but a continuous characteristic of good research practice.
%- It includes endogenous and referential reflexivity, which focus on the actions and understandings of researchers and the meeting of points of view in the production and reception of accounts.
%
%Issues: - Reflexivity involves turning back on oneself in order that processes of knowledge production become the subject of investigation.
%- Endogenous reflexivity and referential reflexivity are two interrelated dimensions of reflexive practice.
%- A reflexive approach to analysis requires navigating between scientism and relativism, and deconstruction and reconstruction.
%- Reflexivity is not a method, but a critical ethos to aid interpretation, translation, and representation.}
%
%\textcquote{patnaik2013reflexivity}{
%
%- The paper explores **reflexivity** in social sciences for meaning making and knowledge claims.
%- **Reflexivity** is important for establishing credibility and richness in research.
%- **Introspective reflexivity** involves understanding how the researcher's experiences influence the research.
%- **Reflexivity** helps in monitoring assumptions, ethical considerations, and research rigour.
%- **Maintaining a reflective journal** helps in capturing the researcher's attitudes and biases.
%- **Bracketing** is used to prevent the researcher's biases from influencing the research process.
%
%Workflow: - Reflexivity is essential in qualitative research to address the subjective nature of data interpretation and researcher bias.
%- It involves introspective reflexivity to understand how the researcher's experiences influence the research process.
%- Epistemological reflexivity examines the knowledge claims being made and the researcher's role in shaping them.
%- Achieving reflexivity requires addressing personal history, values, and biases that may impact the research.
%- Operationalizing reflexivity involves asking questions about the researcher's influence on the topic, research process, and participant interactions.
%
%Issues: - The influence of the researcher's values and attitudes on the choice of topic
%- The exploration of epistemological foundations of knowledge claims
%- The role of the researcher in the process of knowledge construction
%- The presentation of reflexivity in research writing}
%
%\textcquote{palaganas2017reflexivity}{
%The document discusses reflexivity in qualitative research, highlighting the personal changes and influences experienced by researchers during fieldwork. It emphasizes how researchers are shaped by the research process and how their involvement impacts the final study. The authors reflect on their positionality and personal backgrounds, acknowledging the importance of self-awareness in research.
%
%- The document discusses **reflexivity in qualitative research** and how it impacts researchers.
%- The researchers share their **journeys of learning** and how the research process shaped them.
%- The paper focuses on understanding social phenomena like **poverty, development, gender, migration, and ill health** in the Philippines.
%- Reflexivity helps researchers become aware of their contribution to the construction of meanings and lived experiences.
%- **Fieldwork** is described as intensely personal, influenced by researchers' positionality and personal backgrounds.
%
%Workflow: - Reflexivity in research involves reflecting on how the researcher's values, beliefs, and perceptions shape the research process.
%- It is important in feminist research to identify with the research participants and be aware of the power differentials that exist.
%- Reflexivity can take on various forms such as epistemological reflexivity, personal reflexivity, critical reflexivity, and feminist reflexivity.
%- Researchers need to consider how their own background and assumptions affect their research practice.
%- Practicing reflexivity is a significant component of qualitative research.
%
%Issues: - Reflexivity can disrupt the process of discovery
%- Researchers need to suspend the belief that a more personal story reveals a more authentic story
%- Sharing of ideas and experiences can become emotionally driven, leading to ethical issues
%- Researchers need to be aware of personal biases and how they shape the research process
%- Objectivity in research focuses on method rather than content
%- Researchers must maintain academic distance to avoid being influenced by emotions
%- Reflexivity challenges the assumption of studying social reality objectively
%- Researchers need to be critical of power differentials in research
%- Feminist reflexivity emphasizes reciprocity in research}
%
%\textcquote{darawsheh2014reflexivity}{AI: Qualitative research is contextual and occurs between two or more people in a specific time and place. **Reflexivity** in research, which involves the researcher describing the relationships between themselves and the participants, is crucial for increasing the credibility of findings and deepening understanding. Researchers need to be explicit about their positionality, biases, and experiences to ensure trustworthiness. **Reflexivity** helps researchers recognize and take responsibility for their situatedness within the research, influencing data collection and interpretation. It is important for researchers to focus on self-knowledge, sensitivity, and understanding the role of the self in creating knowledge. The balance between personal experiences and universal knowledge must be maintained.
%
%- **Qualitative research is contextual and occurs between two or more people in a specific time and place.**
%- **Researchers must describe the intersecting relationships between participants and themselves (reflexivity) to increase credibility and deepen understanding of the work.**
%- **Reflexivity is essential in qualitative research as the researcher's identity influences the findings.**
%- **Readers need to understand the researcher's positionality beyond their name and affiliations.**
%- **Researchers should address unconscious biases and continually evaluate their positionality.**
%- **Participator process enhances non-exploitive processes and minimizes power differentials.**
%- **Reflexivity involves self-examination and understanding one's situatedness within the research.**
%- **Researchers must be aware of power differentials inherent in the researcher/participant relationship.**
%- **Describing contextual relationships between participants and researchers increases credibility and understanding of the work.**
%- **Researchers need to focus on self-knowledge, sensitivity, and understanding the role of the self in creating knowledge.**
%- **Researchers' position as an insider or outsider is crucial in considering similarities and differences with participants.**
%
%Reflexivity in qualitative research involves the researcher being conscious of their own biases, positionality, and impact on the research process. It requires continual self-reflection and transparency in addressing these factors throughout the research endeavor.
%
%- Reflexivity is a process that permeates the whole research endeavor.
%- Researchers need to address reflexivity in substantive ways to inform the reader about their processes.
%- The issues surrounding researchers' reflexivity are many and complex.
%- Power differentials between participants and researchers pose challenges related to reflexivity.
%- Researchers must be explicit about reflexivity and continually address trustworthiness criteria.
%- Reflexivity involves a continual internal dialogue and critical self-evaluation of the researcher's positionality.
%}
%
%\textcquote{macbeth2001reflexivity}{**Summary:**
%The document discusses the concept of reflexivity in qualitative research, focusing on two main inflections: positional reflexivity and textual reflexivity. It also reintroduces Garfinkel's ethnomethodological "constitutive reflexivity" as an alternative perspective. The text explores the diversity of reflexivity in the literature and its role in deconstructing the intersections of author, other, text, and world. The document includes references to various authors and their works on reflexivity and qualitative research.
%
%- Reflexivity in qualitative research is a significant topic, with two main inflections: positional reflexivity and textual reflexivity.
%- **Positional reflexivity** involves examining the influence of place, biography, self, and others on the analysis.
%- **Textual reflexivity** focuses on disrupting the exercise of textual representation.
%- The article discusses the concept of **constitutive reflexivity** in social science, particularly Garfinkel's ethnomethodological approach.
%- **Reflexivity** is seen as a deconstructive exercise to understand the connections between author, text, and world.
%- The literature on reflexivity is diverse, with various perspectives and interpretations.
%- An example of constitutive reflexivity is analyzed through a videotaped sequence from a fifth-grade classroom.
%- The rush of interest in qualitative research has led to a broad consensus on the importance of reflexivity.
%- **Postmodern attachments** may influence the understanding of reflexivity, but it is suggested that there are commonalities with Enlightenment certainties.
%- **Garfinkel's work** in ethnomethodology is referenced as an alternative perspective on reflexivity.
%
%workflow: Reflexivity in qualitative research involves two main programs: positional reflexivity and textual reflexivity. Positional reflexivity focuses on examining how place, biography, self, and others shape the analytic exercise. Textual reflexivity, on the other hand, involves examining and disrupting the exercise of textual representation. Both programs aim to deconstruct and understand the intersections of author, other, text, and world in the research process.
%
%issues: Reflexivity in qualitative research raises issues related to positional reflexivity and textual reflexivity, which focus on the impact of place, biography, self, and other on the analytic exercise, as well as the disruption of the exercise of textual representation. The discussion also introduces the concept of constitutive reflexivity, which dissolves binaries and representational language games into practical achievements of diverse settings and practices.}
%
%\ResGenTechnique{reflexivity}
%
%\subsection{Reflexivity tools}\label{ssect:ReflexivityTools}
%
%\subsection{Workflow}\label{ssect:Workflow}
%
%\subsection{Other things to think about}\label{ssect:OtherThingsTo}
%
%\ResGenExtras{reflexivity}{}


%\subsection{Sampling: what, who (and how) to choose}\label{sect:DG:sampling}\label{ssect:Sampling}
%\todo{Section referenced, but commented out}
%
%A core prelude to many of the data generating techniques introduced above is to choose the data source. You've already had experience of doing this when you conducted your literature search as part of Stage Cref{stage:?}\footnote{You might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. \todo{More here} 
%
%Unless you had infinite amounts of time – which you don't – and infinite patience – which you might have – you could never be 100\% certain that your literature search collected \emph{all} relevant papers  the search space is infeasibly large (and not indexed particularly well). But you were systematic and achieved a practically good\footnote{By \emph{practically good}, we mean you found the most of the most important papers, some other papers, and didn't have to read \emph{every single paper}. I.e., you found a \emph{representative sample}.} coverage because of that.\todo{More here?}
%
%Sampling is the process of selecting a subset\footnote{We could have said \enquote{sample} but that would have been circular.} of an infeasibly large population of interest, and is used in the research strategies\todo{Update given Stage 3.} that work by estimating or predicting the properties of that population. %, for instance, survey (who will fill in your questionnaire) or experimental (who will take part in your experiment) research. 
%
%Sampling can either be random or non-random. 
%
%In \emph{random sampling}\footnote{Random sampling is also called \emph{probability sampling}.} some unbiased way of choosing, before the fact, subset members from the population, while in \emph{non-random sampling}\footnote{Non-random sampling is also called \emph{non-probability sampling}.}, the choice is based on a researcher's judgement and discretion and can be added to as the research progresses. The lack of bias in the former means that results tend to generalise from the sample to the population. The potential for bias in the latter means that results may not generalise, but things of interest, of depth, and of richness can be followed as they are discovered. As a result, the former is used more in quantitative research, and the latter in qualitative research\todo{Reword to separate the two?}. %Also, in quantitative research the tendency is to choose the sample upfront, before any analysis commences, while in qualitative research, the process is iterative, with more and more sample data collected and analysed until no more collection is possible or \textit{saturation} is reached, that is collecting more data would not bring more relevant information.
%
%Random sampling techniques include:
%\begin{description}
%
%	\item [simple random sampling] where each member of the population has exactly the same chance to be selected. It is easy and efficient to implement, and given the complete randomness of the sample, generalisation is fairly reliable. However, if the population has large sub-groups, these may be over-represented in the sample, with minority groups being under-represented.\todo{Add strengths and weaknesses.}
%	
%	\item [stratified random sampling] where sub-groups of the population are identified based on common characteristics, the \textit{strata}, and sampling is random across those strata. The strata are not mutually exclusive: for instance, the population may have sub-groups defined by gender, ethnicity and level of education, which may overlap. This approach overcomes the over/under representation problem of simple random sampling.\todo{Add strengths and weaknesses.}
%	
%	\item [cluster sampling] where the population is divided up in naturally occurring separate clusters, and the sample is obtained by randomly selecting some clusters and then randomly selecting members of those clusters. It is more cost-efficient than the other two approaches, but can introduce bias if the selected clusters are not representative of the whole population, so that the over/under representation problem remains.\todo{Add strengths and weaknesses.}
%\end{description}
%
%%%Candidate for moving to chapter preload
%
%Non-random sampling techniques include:
%\begin{description}
%	\item [purposive sampling] in which participants are selected by the researcher based on particular characteristics, knowledge, or expertise they have. It is often used for small populations, especially rare populations which may otherwise be difficult to access\todo{Clarify}. Purposive sampling is particularly suited to studies which intend to be deep and narrow, and for which subsequent generalisation back to the parent population is not a concern. As the sample choice is made by the researcher, it is prone to bias.\todo{Add other strengths and weaknesses, or perhaps the weakness is with the class rathe than the instance?}
%
%	\item [convenience sampling] where participants are selected based on their availability or accessibility. This is quick and easy, but unlikely to produce a representative sample, so, once again, bias is an issue.\todo{Add other strengths and weaknesses.}
%	
%	\item [snowball sampling] which relies on referral from previous participants to recruit new ones. This is an effective approach when a population is difficult to access or when the topic is sensitive or tabu. This too is unlikely to generate a representative sample, and is prone to bias.\todo{Add other strengths and weaknesses.}
%\end{description}
%
%\begin{question}[subtitle={Activity: Deep reading on Non-Random Sampling}]
%Check back to your choice of research strategy. If you've chosen one that uses non-random sampling, then you should read the following sources for more details \cites{}	
%\end{question}
%
%In summary, when choosing a sample, you need to consider various factors, including the aim of your study, the kind of methods you are applying, and the level of access you may have. Trade-offs are likely involved and you may not be able to obtain an ideal sample. Nevertheless, your sample will still be useful to your research, as long as you clearly explain and justify how it was obtained and what its limitations are.
%
%\begin{question}[subtitle={Activity: Choosing your sampling approach}]
%Assuming your study requires you to perform some sampling, write down the approach you are going to take, with its justification in terms of what is needed to address your aim and objectives, and any trade-offs due to the practicality of accessing the sample. Record any possible weakness or limitation of your chosen approach.
%\begin{guidance}
%You can skip this activity if sampling is not indicated by your choice of research strategy.
%\end{guidance}
%\end{question}
%
%\todo{Add other core techniques here; which are there?}
%

\chapter{Analysis methods}\label{ch:AnalysisMethods}

%%%
\newcommand{\ResAnTechnique}[1]{\begin{question}[subtitle={Activity: Do I need to know about #1?}]
Check back to your draft methodology from Stage 3. Does it involve data analysis using #1? If so, read through the remainder of this section and complete the activities.
\end{question}}
%%%

All research requires you to analyse data, so that you'll apply one or more data analysis methods in your project. While there is a vast choice of methods for generating data, your choices for analysing them are more limited. Broadly speaking, analysis methods fall into two categories, quantitative and qualitative, depending on the nature of the data to analyse. This chapter introduces some of the most common analysis methods in research: this introduction is neither complete nor very deep\footnote{Entire books have been written on any of them!}, but should give you a solid starting point for your project and references to sources you can access to learn more.

Before we delve into common analysis methods, let's consider techniques to summarise and present data, often a preparatory step for data analysis. In all cases, you will need some of these techniques to summarise and present data in your dissertation, so this will be time well spent.

\section{Summarising and presenting data}\label{sect:pesentingData}


\subsection{Using tables}\label{ssect:UsingTables}

Tables can be used to summarise and present both quantitative and qualitative data, as a starting point for their analysis. The following kinds of tables are used extensively in research and often found in dissertations, hence a good starting point.

\subsubsection{Pivot tables}\label{sssect:pivotTables}

\gloss{Pivot tables} can be used to summarise, sort, filter, re-organise or group data. In a pivot table, data are organised in rows and columns on which you can perform calculations, such as counting, generating totals or averages, and much more. Pivot tables are both powerful and versatile\footnote{In fact, they are so versatile that we'll only be able to provide few illustrative examples. Much, much more can be found online!}, and one of the most widespread tools to facilitate data analysis.

You can generate a pivot table from any data set organised in rows and columns, regardless of whether the values are quantitative or qualitative: all common spreadsheet applications\footnote{From MS Excel to Apple Numbers to Google Sheets.} include this function.

\todo{Jon to change style of pivot tables in example as there should be more than one header row and column}

\begin{example}{US housing market data}
\Cref{tab:exampledata set} gives the first few rows of Kaggle's housing price data set, a data set  related to the US housing market. Kaggle is possibly the largest and best known online community for data science and machine learning, so that its data sets are often used in research and teaching.  

The housing price data set contains over 9,316 entries, each corresponding to a distinct US property, characterised by the following attributes: size in square feet, number of bedrooms and bathrooms, type of neighbourhood, the year it was built and its market price in US dollars. As you can see, the table includes both numerical and categorical variables.
%
%%\begin{figure}[htbp]
%%\centering
%%\includegraphics[width=\textwidth]{figures/exampledata set.pdf}
%%\caption{first few rows of the example data set}
%%\label{fig:exampledata set}
%%\end{figure}
%
\begin{SimpleNColTable}{tab:exampledata set}{7}[\narrowtablewidth]{Example: the US housing market}[X[1]X[3]X[3]X[3]X[3]X[3]X[3]|]
	ID & Square feed & Bedrooms & Bathrooms & Neighbourhood & Year build & Price (US dollars)\\
	1 & 2126 & 4 & 1 & Rural & 1969 & 215,355\\
	2 & 2459 & 3 & 2 & Rural & 1980 & 195,014\\
	3 & 1860 & 2 & 1 & Suburb & 1970 & 306,891\\
	4 & 2294 & 2 & 1 & Urban & 1996 & 206,786\\
	5 & 2130 & 5 & 2 & Suburb & 2001 & 272,436\\
\end{SimpleNColTable}


Pivot tables can be used to summarise data to answer specific questions. For instance, you may ask what is the average house price by neighbourhood and number of bedrooms, which would result in the pivot table in~\Cref{tab:pivot1}, which gives the average price of each combination. From this you can analyse how the average price is affected by each of the factor, for instance you can see how 5-bedroom houses in the suburbs tend to have the highest average price, while 2-bedroom houses in the same neighbourhood are the cheapest.
%
%%\begin{figure}[htbp]
%%\centering
%%\includegraphics[width=\textwidth]{figures/pivot1.pdf}
%%\caption{Pivot table of average property prices by neighbourhood and number of bedrooms}
%%\label{fig:pivot1}
%%\end{figure}
%



\begin{SimpleNColTable}{tab:pivot1}{5}[\narrowtablewidth]{Pivot table of average property prices by neighbourhood and number of bedrooms}[X[2]X[3]X[3]X[3]X[3]|]
	Neighbourhood & Rural & Suburb & Urban & Average \\
	Bedrooms & Price (Average) (US dollar) \\
	2 & 218,323 & 216,300 & 220,050 & 215,355\\
	3 & 219,053 & 220,397 & 223,737 &  218,230\\
	4 & 227,774 & 224,609 & 230,086 & 221,057\\
	5 &  231,112 & 231,776 & 234,894 & 227,473\\
	\hline
	Average & 224,096 & 223,234 & 227,166 & 224,827\\
\end{SimpleNColTable}

Alternatively, you may be interested in how many properties of each kind have been built in each neighbourhood. In this case the resulting pivot table would look like that in~\Cref{tab:pivot2}, which counts the number of house per combination of bedrooms/bathrooms and kind of neighbourhood in the data set.

%\begin{figure}[htbp]
%\centering
%\includegraphics[width=\textwidth]{figures/pivot2.pdf}
%\caption{Pivot table of property counts by neighbourhood and number of bedrooms/bathrooms}
%\label{fig:pivot2}
%\end{figure}

\begin{SimpleNColTable}{tab:pivot2}{6}[\narrowtablewidth]{Pivot table of property counts by neighbourhood and number of bedrooms/bathrooms}[X[3]X[3]X[3]X[3]X[3]X[3]|]
	Neighbourhood & & Rural & Suburb & Urban & Count \\
	Bedrooms & Bathrooms & Count \\
	2 & 1 & 180 & 220 & 261 & 661\\
	  & 2 & 129 & 214 & 283 & 626\\
	  & 3 & 155 & 45 & 75 & 257\\
	2 totals & & 464 &479 & 619 & 1562 \\
	\hline	
	3 & 1 & 96 & 130 & 129 & 355\\
	  & 2 & 397 & 149 & 245 & 791\\
	  & 3 & 127 & 139 & 889 & 1155\\
	3 totals & & 620 & 418 & 1263 & 2301 \\
	\hline	
	4 & 1 & 142 & 306 & 228 & 676\\
	  & 2 & 453 & 379 & 410 & 1242\\
	  & 3 & 315 & 175 & 194 & 684\\
	4 totals & & 910 & 860 & 832 & 2602 \\
\end{SimpleNColTable}
\end{example}

In the example, you have sees just a couple of ways you can use pivot table to address specific questions of your data, out of a vast range of the possibilities. If your data are organised in tables, then it is well worth spending some time becoming familiar with pivot tables.

\begin{question}[subtitle={Activity: Pivot tables in Excel}] Download the housing price data set from Kaggle and re-create the pivot tables in our example. Come up with other questions you could ask of the data and generate related pivot tables.	
\begin{guidance}
Feel free to use your preferred spreadsheet application for this activity, as long as it supports pivot tables -- most do.

You may have to register with Kaggle to gain access to the data set. 

If you use Excel, its help facility and documentation provide all the info you need to create a pivot table. However, you could also browse some of the very many freely available online resources and tutorials on this topic.
\end{guidance}
\end{question}	


\subsubsection{Frequency and contingency tables}\label{sssect:freqAndContTables}

\gloss{Frequency tables} are used to summarise the frequency (or count) of values taken by a categorical variables in a data set, while \gloss{contingency tables}\footnote{Also known as \gloss{cross-tabulation} tables.} extend frequency tables in order to tabulate the value frequencies of two categorical variables. 

\begin{example}{Frequency and contingency tables for degree classifications}
In our university, after studying a degree, a student's outcome is classed as one of distinction, merit, pass or fail. You could use a frequency table to summarise the frequency of each class of outcome for a particular students' cohort, as shown in~\Cref{tab:frequencyTableExample}.
 
\begin{SimpleNColTable}{tab:frequencyTableExample}{5}[\narrowtablewidth]{Classifications frequencies}[X[1]X[3]X[3]X[3]X[3]|]
	& Distinction & Merit & Pass & Fail \\
	Outcome & 12 & 26 & 42 & 5\\
\end{SimpleNColTable}

You could also use a contingency table to tabulate the outcome value frequencies in the cohort against gender, as shown in~\Cref{tab:contingencyTableExample}. 

\begin{SimpleNColTable}{tab:contingencyTableExample}{4}[\narrowtablewidth]{Classifications frequencies by gender} [X[3]X[3]X[3]X[3]|]
	 & Female & Male & Other\\
	Distinction & 7 & 5 & 0\\
	Merit & 12 & 13 & 1\\
	Pass & 21 & 19 & 2\\
	Fail & 2 & 3 & 0\\
\end{SimpleNColTable}

where `Other' is used for students who don't associate with a binary gender or have declined to declare their gender. You can then use the table to investigate if there are significant differences in outcomes by gender.
\end{example}

Contingency tables are often used to summarise and analyse data collected in survey research, and are a key tool in statistical analysis.

Both frequency and contingency tables can be generated as pivot tables in a spreadsheet. In fact,~\Cref{tab:pivot2} is a contingency table. 

\subsubsection{Tabulating your data}\label{sssect:tabulatingData}

This is a good point to consider how you could tabulate your data for follow up analysis and presentation. 

\begin{question}[subtitle={Activity: Creating your own tables}]
Consider how you could use different kinds of table to summarise your data both to help you in your follow-up data analysis and to include in the body of your dissertation.
Apply your choices to your data. 
\begin{guidance}
You can start from the kind of tables we have included in this chapter. Should they not be suitable, you should conduct some web searches to find examples of other kinds of tables you may use.

In your table choices, you should consider:
\begin{itemize}
\item purpose of the table: you should decide what you intend to achieve by tabulating the data. For instance you may want to provide a concise summary or make it easier to analyse trends over time or relationships between data
\item  type of data: as you have seen in this sections, some forms of tabulation may be more appropriate for quantitative rather then qualitative data, so you need to think of the kind of data you want to tabulate
\item table design: you should choose rows and columns carefully to meet the purpose of the table, including providing clear and concise headings which appropriately describe the content of each cell
\item  consistency: for numerical values, ensure you use consistent units of measurement and level of precisions. If the same data are included in several tables ensure you use the same headings
\item highlight significant entries: you can use colours or other visual cues to draw attention to significant entries
\end{itemize}
Your table won't be perfect at this point, but should provide a good starting point to analyse your data.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\subsection{Summarising qualitative data}\label{ssect:summarisingQualitativeData}

Qualitative data are heterogeneous nature and cannot be easily set out in a standard manner. 

Conveying the depth and richness of qualitative data in a succinct way is challenging, so that you will need both selectivity and creativity in presenting your data. 

For textual data, like interview transcripts, \emph{verbatim} quotations are often used to illustrate specific themes or points, or support certain conclusions. However, an excessive use of quotations will result in overlong accounts, which may be difficult to follow or even obscure the main findings. Therefore it is important that you select quotations which are particularly representative or poignant, avoiding verbose details that you can present more succinctly in the narrative surrounding those quotations.

Diagrams, schematics or drawings can also be used effectively and imaginatively to present qualitative data and their analysis. Data visualisation is, in fact, a discipline in its own right\footnote{Edward Tufte is one of the most influential figures in this field. His books provide compelling examples on how to use visualisation to present and analyse highly complex data.}, and some visualisation techniques can be applied to qualitative data.

\begin{question}[subtitle={Activity: Visualisation techniques for qualitative data}] 
Conduct a web search on techniques for visualising qualitative data. List the techniques you have found and what they are used for. Consider whether they may be applicable in your project.
\begin{solution}
You may have encountered some or all of the following:
\begin{itemize}
	\item diagrams and schematics, to convey complex processes or structures
	\item graphic timelines, to summarise key events and their order
	\item word clouds, to summarise emerging themes or concepts from text, and their relative frequencies
	\item mind maps, to visualise how different ideas relate or contribute to a central concept or topic
	\item heat maps, to highlight trends or differences in tabulated data
	\item icons, alongside brief descriptions, to represent and quickly identify specific concepts 
	\item storyboards, to visualise narratives or sequencing of actions or events
	\item bespoke drawings, for data which cannot be easily visualised using other standard techniques
	\item pie charts and bar charts, to summarise proportions and counts – which are actually quantitative, but may be the result of qualitative data analysis – of categorical data.
\end{itemize}
\end{solution}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

If you have concluded that visualisation may be a good way to present your qualitative data, then this is a good time to have a go.

\begin{question}[subtitle={Activity: Creating your own visualistations}]
Apply your chosen visualisation to your qualitative data.
\begin{guidance}
Your visualisations should be:
\begin{itemize}
\item fit-for-purpose in relation to what you intend to convey
\item readable and accessible to a variety of readers with diverse abilities
\item accurate and honest in representing your data, so that your readers are not misled or likely to misinterpret your data.
\end{itemize}
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}



\section{Statistical analysis}\label{sect:statisticalAnalysis}

Statistical analysis in an umbrella term for a set of methods which you can apply to numerical and categorical data. More precisely, in Statistics data are classified as:

\begin{itemize}
	\item scalar, which includes all measurements and counts; with reference to the types in~\Cref{sect:evidenceAndData}, these are all numerical data, continuous, discrete, interval and ratio data; and
	\item categorical, both ordinal and nominal.
	\end{itemize}

There are two broad categories of statistical methods, which we consider next. They are:
\begin{itemize}
	\item descriptive statistics, whose aim is to describe data; and
	\item inferential statistics, whose aim is to make predictions from data.
\end{itemize}


\subsection{Descriptive statistics} %\label{sect:descriptive} -- old
\label{ssect:DescriptiveStatistics}

Descriptive statistics are used to describe various attributes of a data set. 

\ResAnTechnique{descriptive statistics}

They include:
\begin{itemize}
	\item count, to establish how many entries there are in the data set
	\item centrality, to establish the `centre' of the data set. Three measures are commonly used: the \gloss{mean}, which provides the average value of the data set; the \gloss{median}, which provides its mid point\footnote{Remember that quantitative data can be ordered.}; and the \gloss{mode}, which indicates the value that occurs most frequently, if any\footnote{There is no mode if no value is repeated in the data set.} 
	\item dispersion, to establish the spread of the data in the data set. There are two common measures: the \gloss{range}, which is the difference between smallest (minimum) and largest (maximum) values; and the \gloss{standard deviation}, which is derived from the distance of each value in the data set from the mean through a mathematical formula\footnote{It is not essential for you to know such formula, which is automatically computed by spreadsheets and statistical software. Of course, you can always look it up in the literature...}. The larger the standard deviation, the greater the dispersion
	\item skewness, to establish how symmetrically distributed the values in the data set are in relation to the centre. In the case of perfect symmetry, skewness is equal to zero, and mean and median are equal. When asymmetric, mean and median are different and the distribution may be either right (mean smaller than median, and negative skewness) or left (mean greater than median, and positive skewness) skewed. A perfectly symmetric distribution is usually referred to as a \gloss{normal distribution} or \gloss{bell curve}, from the shape of the line that you can obtain by plotting the data on a chart\footnote{This oversimplifies the topic in order to give you some intuition in case you have not come across these concepts before. A lot more could be said about the normal distribution and its pivotal role in Statistics!}.
\end{itemize}

Not all descriptive statistics apply to categorical data. In particular, the mode is used as the main measure of centrality for nominal data, while the median is used for ordinal data which are not numeric.

These are lots of definitions to digest, particularly if you haven't encountered these terms before! The following activity should help.

\begin{question}[subtitle={Activity: Descriptive statistics in Excel}] Assume you have measured the weight in grams of each apple in a basket, obtaining the following numbers: 105, 120, 122, 125, 127, 128, 129, 130, 132, 133, 135, 135, 138, 140, 128. Enter these data in an Excel sheet and use its built-in data analysis function to generate the related descriptive statistics.
\begin{guidance}
In the current version of Excel, you can access this function from the Data tab, by pressing the Data Analysis button. If you find it difficult to locate this function, you should refer to the documentation or to some of the many tutorials on this topic which are freely available online.
\end{guidance}
\begin{solution}

You should have obtained the values in~\Cref{tab:values}.

\begin{SimpleNColTable}{tab:values}{2}{Values}[{rS[table-format=3.2]}]
{{{Attribute}}} & {{{Value}}} \\%%Triple {{{}}} on page 51 of tabularray manual
mean & 128.47 \\
median & 129 \\
mode & 128 \\
standard deviation & 8.55 \\
skewness & -1.4 \\
range & 35 \\
minimum & 105 \\
maximum & 140 \\
count & 15 \\
\end{SimpleNColTable}

There are 15 values in this data set (count), with range 35 (the difference between maximum and minimum values).

In terms of centrality, the mean (128.47) is slightly smaller than the median (129), and Excel reports a mode at 128. In reality, if you look at the data you will see that there are two modes in this data set\footnote{Statisticians call this \textit{bi-modal}.}, 128 and 135, but Excel only returns the first encountered!

In terms of dispersion, the standard deviation is telling us that most apple weights are within 8.55 grams of the mean (below or above), so the apple weights are similar in the apple baskets.

Note that the skewness is negative, which is consistent with the mean being smaller than median, so the data distribution is right skewed. 
\end{solution}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

In your dissertation, you can easily present the descriptive statistics of your data sets as a table, possibly adapting that automatically generated by your spreadsheet.

In addition, you can use standard charts to visualise the data and examine their descriptive statistics. 

\paragraph{Histograms}
With scalar data, like in the previous activity, you can use a \gloss{histogram}. The one in~\Cref{fig:histogramBin1} uses the apple weights from the activity: on the horizontal axis, we have the distinct weights, and on the vertical axis, their frequencies, that is how many times each weight appears in the data set. Given the values you have obtained for the descriptive statistics of the data set, you can easily locate on the chart min and max values, and mean, median and mode. In this case, the two `peaks' correspond to the two modes we mentioned in the activity. You can also check that most of the values are within 8.55 grams from the mean, either way: the only values left out are 105 (to the left) and 138 and 140 (to the right). Skewness is not obviously notable on this chart, so that we will use a different chart for that purpose.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/barchart.pdf}
\caption{Histogram for the apple weights (bin size = 1)}
\label{fig:histogramBin1}
\end{figure}

Before we do that, however, it is worth noticing that given our small data set of discrete values, we have used a histogram with `bin' size equal to one, which allows us to plot each individual apple weight. A \gloss{bin} in a histogram is essentially a way to group a number of values, with bin size establishing the spread of each bin. Frequencies are then calculated by bin. Grouping values in bins is necessary with large data sets and/or with continuous data. ~\Cref{fig:histogramBin5} illustrates a histogram for the apple weights, in which the bin size is five: that is, each bin spans a set of five possible values. 

\begin{figure}[htbp]
\centering
\includegraphics[width=12cm]{figures/histogramBin5.pdf}
\caption{Histogram for the apple weights (bin size = 5)}
\label{fig:histogramBin5}
\end{figure}

\paragraph{Boxplots}
In order to visualise both spread and skewness, you can use a \gloss{boxplot}, illustrated in~\Cref{fig:boxplot} for the apple weights. This is made of a `box' around the median of the data, and some `whiskers' on each side of the box\footnote{Which is why this chart is also called a \gloss{box and whiskers plot}.}. It is obtained by dividing up the data into quartiles, each containing a quarter (or 25\%) of the data, with the median in the centre. The box includes the two quartiles on each side of the median, which, together, account for half of the values in the data set. The whiskers account for the other two quartiles, with a caveat: if there are very extreme values, these are treated as possible outliers and left out of the whiskers. This is, in fact, the case in our example where value 105 is treated as an outlier in the chart: it is a dot on its own, not included in the left whisker. The whisker length provides an indication of spread: the longer the whiskers, the more spread out the data. Instead, the position of the median in relation to the extreme of the box provides an indication of skweness: in our example the median is further away from to the right edge (just!), indicating that the data distribution is slightly right-skewed (consistent with the negative skewness value in the descriptive statistics).

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/boxplot.pdf}
\caption{Boxplot for the apple weights}
\label{fig:boxplot}
\end{figure}

To be more precise, the relation between a boxplot and its underlying statistical features is illustrated in~\Cref{fig:boxplotFeatures}. The two quartiles around the median represent the interquartile range (IQR) of the data set. The whisker lengths, calculated based on the formulae in the figure,  allows the identification of lower and upper bounds beyond which values are seen as extreme and represented separately as outliers. An outlier, therefore, is just a value which is distant from most of the other values in the data set: it may point to an error, which should be corrected, or an anomaly, which may require further investigation, but that's not necessarily the case. However, it's good practice to investigate all outliers to understand why they have occurred. 

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/boxplotFeatures.pdf}
\caption{The features of a boxplot --- LR to redraw as taken from the web}
\label{fig:boxplotFeatures}
\end{figure}


\begin{question}[subtitle={Activity: Charts in Excel}] Go back to your Excel sheet from the previous activities and generate charts similar to those in the figures above.
\begin{guidance}
In the current version of Excel, you can generate these charts from the Insert tab, by choosing from the Statistical charts menu. If you find it difficult to locate this function, you should refer to the documentation or check some of the many tutorials on this topic which are freely available online.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\paragraph{Common charts}
~\Cref{tab:charts} summarises types of charts you can use to visualise your data and their descriptive statistics: it includes charts we have not used in our examples, but which are very common, so that you can find plenty of study materials online should you wish to look them up and use them.

\begin{SimpleNColTable}{tab:charts}{3}{Common charts to visualise data sets and their descriptive statistics}[X[2]X[2]X[4]|]
Chart & Variable(s) & Purpose \\
bar chart & one categorical & to visualise counts/frequencies/proportions/percentages \\
stacked bar chart & two categorical & to compare   counts/frequencies/proportions/percentages between two groups\\
histogram & one scalar & to visualise distribution, including centrality, dispersion and skewness \\
scatter diagram & two scalar & to visualise relationships and possible outliers \\
boxplot & one scalar or one categorical & to visualise spread, skewness, median, IQR and possible outliers \\
line chart & one scalar by time & to visualise change over time \\
\end{SimpleNColTable}


Calculating descriptive statistics and visualising data in appropriate charts, should be the first step in your statistical data analysis, as these provide useful summaries and visualisations of key properties of your data set. And, as you have found out in the activities, you do not need to be a statistician to be able to generate them!

Descriptive statistics may also help you identify errors or anomalies in your data, and can inform possible follow-up analysis, including inferential statistical analysis. Depending on your research aim and objectives, they could also be all you need in your project. 


\subsubsection{Further reading}\label{ssect:descriptiveStatistics}

\ResGenExtras{descriptive statistics}{{cooksey2020descriptive}}

\subsubsection{Descriptive statistics applied to your data}\label{ssect:yourDescriptiveStatistics}

If you have collected scalar or categorical data, it is time for you to have a go at analysing them using descriptive statistics and charts.

\begin{question}[subtitle={Activity: Applying descriptive statistics to your data}] 
If your data set includes scalar or categorical data, calculate descriptive statistics for your data set, and generate appropriate charts.
\begin{guidance}
MS Excel is relatively straightforward to use for this purpose, but feel free to use other tools you may be already familiar with, including statistical or data analytics packages. Whichever tool you use, you should ensure it supports the functionalities we have discussed in this section.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}


\subsection{Inferential statistics}\label{sect:inferentialStatistics}\label{ssect:InferentialStatistics}

Inferential statistics relies on the concepts of population and sample: the \gloss{population} is the entire group you are interested in studying -- say, all UK voters in a general election; while the \gloss{sample} is the portion or subset of that group you have access to in your research. Then the aim of inferential statistics is to establish whether patterns or effects you have observed in the sample can be generalised to, i.e., inferred for, the whole population, or whether they are the result of chance. In inferential statistics this is achieved through statistical tests.

\ResAnTechnique{inferential statistics}

You use a statistical test to find out whether a \gloss{proposition} is likely to be true in the population you are studying. You can think of a proposition as an educated guess you have made based on some observations, but that has yet to be supported by evidence. To test a proposition, you need a representative sample of the population\footnote{We discussed sampling in~\Cref{ssect:sampling}}.

A statistical test is applied to the sample and returns a measure of \gloss{statistical significance}, which is used to provide evidence (or otherwise) that any pattern or effect observed in your sample is also likely to exist in the population, and is not just the effect of chance. Note that contrary to the common language meaning of `significance' as big or important, statistical significance only indicates that the effect is likely to exist in the population, where it may well be small or unimportant. As a corollary, if your sample is very large, almost all effects observed in the sample will be likely present in the population; vice-versa, if your sample is very small, most effects observed in the sample are unlikely to be present in the population, unless they are really very large. 
As a rule of thumb, most tests require a sample size of at least 30 observations, but more precise sample size estimates can be made based on population size and expected significance level\footnote{In the literature, you can easily find formulae for the ideal sample size.}.

You can apply statistical tests to both scalar and categorical data and use them to compare values of specific statistics or to establish statistical relationships between variables, specifically:
\begin{itemize}
	\item an \gloss{association} between variables means that one variable can be used to provide some information about the other
	\item a \gloss{correlation} is a particular type of association such that the two associated variables always change together, for instance they both increase or decrease at the same time, or when one increases the other always decreases. 
\end{itemize}

Statistical tests can be used to estimate the strength of an association (i.e., the extent changes in one correspond to changes in the other) and its direction (whether the variable changes are in the same or opposite way).

Each statistical test comprises the following elements:

\begin{itemize}
	\item \gloss{hypotheses}: there are two, \gloss{null} and \gloss{alternative} hypotheses. Inferential statistics assumes you can't prove something to be true, but you can disprove something by finding an exception. Here is a classic example: you can't prove that all swans are white, but you can disprove they are by finding a black swan! So, you must  set the null hypothesis to what you want to disprove about the population, with the alternative hypothesis being what you are really interested in finding out. So, the null hypothesis is usually a statement of no pattern/effect in the population
	\item \gloss{significance}: this is the level of statistical significance for the test. It's known as the \textit{alpha} ($\alpha$) value from the Greek name of the mathematical variable used to express it. Most tests are run with $\alpha=0.05$, which gives a 5\% probability that we may infer that the null hypothesis is disproved while in actuality it is correct\footnote{This is called a Type I error in Statistics.}
	\item \gloss{sample(s)}: you need to have one or more (representative) samples of the population of interest  on which to perform the test. Multiple samples are used in some tests, typically to compare specific statistics in different groups within the population or changes within a group over time or after an intervention of interest, say treating patients with a new pharmacological drug
	\item \gloss{p-value}: this is the probability calculated for your test by your statistical package, and which is used to decide the outcome of the test
	\item \gloss{decision}: this is based on the p-value in relation to the $\alpha$ value. If the p-value is less than the $\alpha$ value, then the null hypothesis is {rejected}, i.e. disproved, which means your alternative hypothesis that there is an effect in the population is supported by statistical evidence.
\end{itemize}

There are very many statistical tests to choose from, depending on the kind of data you have and their distribution, the purpose of your analysis and the number of samples involved.  We will not detail all possible statistical tests in this introductory section --- once again, entire books have been written about them! Instead, we provide~\Cref{tab:testsForComparison} and~\Cref{tab:testsForAssociation} as summaries of the most common tests that you can then follow up in the literature, should you wish to apply any in your research.

\begin{SimpleNColTable}{tab:testsForComparison}{6}{Common statistical tests for comparison. {Parametric} tests apply to normally distributed data (see Section\Cref{ssect:DescriptiveStatistics}); {non parametric} tests to skewed distributions}[X[4]X[2]X[4]X[2]X[2]X[4]|]
	Purpose & Variables & Example & Parametric & Non parametric & Notes  \\
to compare the sample mean against a specific value & one scalar & to investigate whether AA batteries of a particular brand have the claimed lifespan  & one sample t-test & n/a  & \\
to compare the sample proportion against a specific value & one categorical & to investigate the proportion of people who voted for a particular party in a city against that for the whole country & one sample z-test & n/a  & \\
to compare the means of two independent samples & scalar & to compare the mean scores (dependent) of students studying the same subject with two different teaching approaches (explanatory) & independent t-test & Mann-Whitney test/Wilcoxon rank sum  & two samples are \textit{independent} when there is no reason to believe that observations in one sample are influenced or determined by those in the other\\
to compare the means of three or more independent samples & scalar dependent; nominal explanatory & to compare the mean scores (dependent variable) of students studying the same subject with three or more different teaching approaches (explanatory variable) & one-way ANOVA & Kruskal-Wallis test \\

to compare the average difference between paired samples against a particular value & scalar dependent; time or condition as explanatory & to compare the blood pressure readings (dependent variable) of a group of people before and after exercising (explanatory variable) & paired t-test & Wilcoxon signed
rank test &  in paired samples each data point in one sample is uniquely matched to a data point in the other sample; this happens, for instance, when we measure a factor before and after an intervention, or take different readings for the same group of individuals. Because of this, paired samples are not independent.\\
\end{SimpleNColTable}

\begin{SimpleNColTable}{tab:testsForAssociation}{6}{Common statistical tests for association. \textit{Parametric} tests apply to normally distributed data; \textit{non parametric} tests to skewed distributions}[X[4]X[2]X[4]X[2]X[2]X[4]|]
	Purpose & Variables & Example & Parametric & Non parametric & Notes  \\
to investigate correlation between two continuous variables & scalar dependent and explanatory & to investigate the relation between blood pressure (dependent) and age (explanatory)  & Pearson’s Correlation Coefficient & Spearman’s Correlation Coefficient & \\

to investigate association between two categorical variables & categorical dependent and explanatory & to find out if there are gender (categorical) differences in the choice of modes of transport (categorical) in a city & chi-squared & n/a  &  \\

to investigate association between two categorical variables when the sample is small & categorical dependent and explanatory & to find out if there are gender (categorical) differences in the choice of modes of transport (categorical) in a city  & fisher's Exact test & n/a & the sample size $n$ should be less than 20 \\

to predict the value of one variable from that of one or more other variables & scalar dependent and any kind of explanatory & to predict house prices (dependent) based on location (explanatory, categorical) and number of bedrooms (explanatory, scalar) & linear regression & n/a & linear regression relies on associations between dependent and explanatory variables\\

to predict the value of a binary variable from that of two or more other variables & binary categorical dependent and any kind of explanatory & to predict whether a customer is likely or not to purchase a certain product (dependent) based on previous purchased products (explanatory, categorical) and average annual spent (explanatory, scalar) & logistic regression & n/a & a binary variable has only two possible values, so that logistic regression calculates the probability of each value based on the values of the explanatory variables. Because of this logistic regression can be used as a classification method \\
\end{SimpleNColTable}

Even if these tests are only a sub-set of all statistical tests available, there is a lot to digest. The next activity should help you use these tables to choose an appropriate test. 

\begin{question}[subtitle={Activity: Choosing an appropriate test}] 
Consider each of the following scenarios and use the information in the tables to decide which test to apply and what the null hypothesis should be. For each, write down your reasoning, choice and null hypothesis.

\begin{itemize}
	\item \textit{Scenario 1} to investigate the amount of sugar contained in baby food of a particular brand against a recommended threshold, from a sample of 30 products of that brand.
	\item \textit{Scenario 2} to investigate the number of products per hour of two manufacturing machines in the same plant, by observing the two machines' output over 24 hours. 
	\item \textit{Scenario 3} to investigate the effect of temperature on the consumption of ice cream in a particular city over 12 months.
	\item \textit{Scenario 4} to investigate whether preference in chocolate types, say white vs milk vs dark, is related to gender in a particular country.
	\end{itemize}
\begin{guidance}
To simplify things, always assume normal distributions.
\end{guidance}
\begin{solution}
Assuming normal distributions, for each scenario, we have considered:
\begin{itemize}
	\item the kind of data
	\item number of samples and their size
	\item purpose of the investigation
\end{itemize}
This is what we have concluded:
\begin{itemize}
	\item \textit{Scenario 1} scalar variable (amount of sugar); one sample of 30 products; to compare the sample mean against the recommended threshold. The test to use is a one sample t-test with null hypothesis that the sample mean is above the threshold.
	\item \textit{Scenario 2}  scalar variable (number of products per hour); two samples (one per machine over the time span); to compare the means of products per hours for the two machines; there is no reason to think that the working of one machine may influence that of the other, so the two samples are independent. The test to use is an independent t-test with null hypothesis that the two sample means are different.
	\item \textit{Scenario 3} scalar dependent (level of ice cream consumption) and scalar explanatory (temperature); to investigate any relationship between the two variables from one sample over the period. The test to apply is Pearson's correlation with null hypothesis that there is no association between the two variables.  If, in addition, we wanted to make predictions on ice cream consumption based on temperature, then we could also apply linear regression.
	\item \textit{Scenario 4} both dependent (chocolate type preference) and explanatory (gender) variables are categorical; to investigate association based on one sample from a particular country. The test to use is a Chi-squared with null hypothesis that gender has no association with chocolate taste.
\end{itemize}
\end{solution}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}




\subsubsection{Further reading}\label{ssect:inferentialStatistics}

\ResGenExtras{descriptive statistics}{{casella2024statistical}}

\subsubsection{Inferential statistics applied to your data}\label{ssect:yourDescriptiveStatistics}

It's time to apply inferential statistics in your project.

\begin{question}[subtitle={Activity: Applying inferential statistics to your data}] 
Apply to your data and document any statistical test required by your methodology.
\begin{guidance}
You should make use of a statistical package to perform your test(s). In documenting each test, you should include:
\begin{itemize}
	\item the kind of test performed
	\item how your data met its conditions
	\item the hypotheses, sample(s) and level of significance
	\item the outcome, in terms of p-value and decision
	\item how the outcome relates to your aim and objectives
\end{itemize} 
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}


\section{Qualitative analysis}\label{sect:QualitativeAnalysis}

Qualitative analysis is used to extract meaning and insights from non numerical data, be that text, images, audio or other. The most common types of qualitative analysis are:

\begin{itemize}
	\item \gloss{thematic analysis}, which aims to identify recurring themes, their definition and relationships. It is applied particularly to text, e.g., transcriptions of interviews or answers to questionnaires or existing text documents, for instance to find out something about people's views, opinions, knowledge, etc.
	\item \gloss{content analysis}, which aims to identify patterns used for communication, whether in text, speech, images, videos, or other, for instance, focusing on the use of certain words, themes, or concepts within that content. It has many uses, from discovering and understanding patterns, to looking at intentions behind what is expressed, or to highlighting differences of use in different contexts
	\item \gloss{discourse analysis}, which focuses on the use of language in conversations in a real-world context, including how this is influenced by historic or cultural factors, or power dynamics
	\item \gloss{narrative analysis}, which focuses on stories made and told by people, to investigate their meaning and how people make sense of reality.
\end{itemize}

\ResAnTechnique{any of the above types of qualitative analysis}

While their goal may be different, all these types of analysis apply {coding} as a core method, which we discuss next.


\subsection{Coding qualitative data}\label{ssect:CodingQualitativeData}

A \gloss{code} is a label which describes an extract from a qualitative data set, with \gloss{coding} the process of creating and assigning codes to categorise those extracts. 

Coding is important and it helps you ensure that your analysis is systematic, and the codes will help you explore themes and patterns in the data. However, codes are not themes: they are just labels used to group similar types of data, developed to support your follow-up analysis. 

There are two main approaches to coding. In \gloss{deductive coding}, the codes are decided upfront, before looking at the data, and may be based on your research problem phenomena, or may have emerged from your literature review, including codes possibly used in previous studies. In \gloss{inductive} coding, the codes emerge from the data and are not pre-defined. Deducting and inductive coding can also be combined: you could start with a set of pre-defined codes then add new codes as you review the data.

Whichever your approach, you should follow a multi-pass coding process. The first pass should consist of going through the whole data set in order to establish which codes to use. In the second pass, and any subsequent ones, you should apply the codes to the data bit by bit, say by line by line in a text, or frame by frame in a video, etc. In the second pass and subsequent passes, the initial codes are reviewed and may become more or less detailed.

You can choose your codes in various ways. For instance, \gloss{in vivo} coding uses the exact language which occurs in the data: this is used, in particular, for participants' speech, especially when different languages are used. On the other hand, \gloss{descriptive}\footnote{This is a very common approach, although there are others which you can research in the literature.} coding uses words which encapsulate a general idea, such as `sport' or `running': this is particularly useful for non textual data, like images or videos. 

Whichever codes you end up with, you should ensure they are properly defined, so that their are unambiguous and can be applied consistently. You should use a \gloss{codebook} for this purpose, which lists all the codes and their intended meaning, so that you can revisit and refine them throughout the coding process.

The last step before detailed analysis is \gloss{code categorisation}, which is the process of reviewing what you have coded and organise it into categories. For instance, from codes such as `football', `tennis' and `rugby' you may define a category `sports'. In this way, you both organise your data and establish connections between codes and coded information. 

Both coding and categorisation are iterative processes which carry on until you reach saturation, that is no more is gained from further coding or categorisation. At this point, you can proceed with your chosen analysis method, whether content, thematic, narrative, discourse analysis or other, in order to identify patterns and themes, and provide your own interpretation of the data.

Coding and categorising are time consuming tasks, particularly if you have a large amount of text to code. In most research, coding data by hand is impractical and you should at least make use of a word processor, perhaps using colours and comments to code fragments of your text. Better still, you could  make use of a bespoke qualitative data coding tool: many such tools are now available, some of which can also automate coding and categorisation to some extent.

\begin{question}[subtitle={Activity: Investigating tools for coding qualitative data}] 
Conduct a web search on tools which support qualitative data coding. List up to four which appear most commonly used. For each, indicate which coding features it offers and the extent it is freely available for students' research projects.
\begin{solution}
Qualitative analysis tools are growing and changing rapidly, particularly due to the integration and exploitation of AI capabilities. 

At the time of writing this book, the most used commercial products include NVivo, ATLAS.it and MAXQDE\footnote{You can easily find their home page through a web search.}.
 
They all provide support for coding, with more or less extensive automation, alongside various other features such as data visualisation, statistical analysis, automatic transcripts generation from audio and video files, to name just a few. These commercial products are quite sophisticated with a steep learning curve and are usually quite expensive. They are also geared towards large research efforts, possibly by teams of researchers.

An increasing number of lighter, free products are also available. These include, for instance, Taguette, which supports manual coding and is both open source and free to use, or QDE Miner Lite, which is a free limited version of its full commercial release, and also supports manual coding. Such free products may be sufficient for students' research projects, particularly at Masters level.

You may have found other similar tools in your search.
\end{solution}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\subsection{Further reading}\label{ssect:QualitativeAnalysisFurtherReading}

There is a lot more for you to know on the different kinds of qualitative analysis, so that we strongly advise you read more widely before applying your chosen techniques.
 
\ResGenExtras{qualitative analysis}{{kiger2020thematic}{drisko2016content}{gee2014introduction}{bamberg2012narrative}}


\subsection{Analysing your qualitative data}\label{ssect:yourQualitativeAnalysis}

You should be now in a position to carry out your qualitative analysis.

\begin{question}[subtitle={Activity: Your qualitative analysis}]
Apply your chosen qualitative analysis technique(s) to your data and write up your data analysis. When appropriate, apply visualisation techniques to summarise your data.
\begin{guidance}
In writing up your analysis you should describe:
\begin{itemize}
	\item the techniques and procedures your have used to analyse the data
	\item how you coded the data and the results of that process
	\item which major themes or patterns have emerged from your analysis
	\item how they relate to your aim and objectives
\end{itemize}
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}



%%%LR -- I don't think we need this, which is a T802 thing
%\subsection{The extended abstract}\label{ssect:ExtendedAbstract} 
%
%An {extended abstract} is a summary of academic research intended for a more general audience, so that it should be easily read and understood by someone with only a superficial knowledge of the topic. As with the abstract, it should be a stand-alone item without any reference to your full dissertation. However, it is a lengthier piece of academic writing, structured with headings and sub-headings, including citations and references, and possibly tables, figures and diagrams to help you present and summarise your work.
%
%\begin{question}[subtitle={Activity: Drafting your extended abstract}] Write a draft extended abstract for your project, which should reflect your research progress to date.
%
%\begin{guidance}Your extended abstract should be 4 to 6 pages in length (once complete) and a common structure is as follows:
%
%\begin{itemize}
%\item Title --- the same as your dissertation
%
%\item Introduction and background --- an outline of your research problem in its context, its significance, and the knowledge gap addressed by your research
%
%\item Aim and objectives --- from your dissertation
%
%\item Research design --- an outline of your research design
%
%\item Results --- a summary of the evidence collected and analysed, and your key findings
%
%\item Discussion --- how significant your findings are in relation to research problem and knowledge gap
%
%\item Conclusion and future work --- your overall conclusions and possible follow-up research
%
%\item References --- selected references cited in the body of your extended abstract
%
%\end{itemize}
%
%Your course may have different guidelines which you should check and follow to produce your extended abstract.
%
%\end{guidance}\end{question}
%%%Hack to correct tcbox behaviour
%\color{black}

\chapter{Writing up}\label{ch:writingUpInStage4}

It's time for your end-of-stage report to consolidate your work so far and provide some more content for your dissertation. Its recommended structure and content are indicated in~\Cref{stage4WritingOutcomes}. 

\begin{question}[subtitle={Activity: Writing and assessing your report for Stage 4}] Using your word processor of choice, revise and expand your Stage 3 report by applying the structure and guidance in~\Cref{stage4WritingOutcomes}, making good use of your notes and summaries from all related activities you have carried out.

Assess your report by applying the criteria in~\Cref{tab:criteriaForReport4}. Revise and iterate until you are ready to move on. 
\begin{guidance}
There are substantial additions to your previous report as a result of your work in this stage. In particular:
\begin{itemize}
	\item you should revise and expand your research design chapter substantially, adding details of the procedures you have followed in your data generation and analysis. You should make all necessary adjustments to your methodology which may have resulted from carrying out those activities
	\item in your (new) analysis and interpretation chapter, you should provide appropriate summaries of the data you have generated, using suitable techniques to do so, such as tables, charts, visualisations, etc. You should also provide a succinct account of your data analysis and record its main findings. You should structure your narrative in this chapter to best convey what you have done, striving for clarity and rigour 
	\item if appropriate you may use appendices to include samples of your raw data, or other information in relation to the methods you have applied, such as questionnaires you have used, or code you have written.
\end{itemize} 
In evaluating your report, for each criteria in the table, you should consider the related prompts, write down any further work needed for your next stage, and update your work plan and risk assessment accordingly.
\end{guidance}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\begin{SimpleNColTable}{tab:criteriaForReport4}{2}{Criteria for reviewing your report}[X[2]X[6]|]
Criteria & Prompts \\
Completeness & Are all sections included and their content complete? What is missing?\\
Academic writing & Is your writing clear, concise and precise? Should you improve it further? \\
Logical structure and flow & Have you structured your writing so that your narrative follows a logical flow? Which restructuring may be needed?\\
Supporting evidence & Are all your claims supported by appropriate references or other evidence? Which further evidence do you still need?\\
Citation and reference style & Do all your citations and references comply with the bibliographical style required by your course? \\
Avoiding plagiarism & Have you acknowledged the work of others? Is it clearly distinguished from your own? \\
Grammar and spelling & Have you proof-read your report carefully to remove typos and grammatical errors? \\
\end{SimpleNColTable}
 
 
\chapter*{Stage 4 Takeaways}\label{ch:Stage4Takeaways}

\begin{itemize}
\item Raw data represent any data you generate and analyse as part of your research, and upon which your evidence and contribution to knowledge are based
\item You need to manage your data carefully, ensuring they are properly stored and organised
\item You must consider whether you will need to share your research data, and how to deal with confidential data, particularly personal data
\item Sampling is the process of selecting a sample from the population of interest, and is something used in many research strategies
\item All research needs methods to generate and analyse data and there is a vast choice of methods for you to choose from
\item You can use modelling methods if your research requires you to build models of natural, social or artificial phenomena  
\item Each method requires you to consider procedural and feasibility issues, alongside potential research weaknesses and how to deal with them
\item Tables are common ways to organise and present many kinds of data, and a good starting point for data analysis 
\item Qualitative data are heterogeneous in nature, and you many need bespoke approaches to summarise and present them
\item When your data are numerical or categorical you can use descriptive statistics to capture key features of your data set, and use standard charts to visualise such features
\item You can use inferential statistics to make predictions from data, specifically to establish whether patterns or effects observed in a sample can be inferred for the population from which the sample was taken
\item Qualitative analysis comes in many flavour, depending on your goal in extracting meaning from qualitative data
\item Coding is the first step in all kinds of qualitative analysis. It is the process of assigning labels to extracts from qualitative data to allow a systematic follow-up analysis
\item In writing up your data analysis you must decide how to summarise and present your data, how to report your analysis and its your findings and how to structure your arguments and narrative 
\end{itemize}

%%Sectional bibliography
\printbibliography[segment=\therefsegment,title=Stage 4 \bibname]
