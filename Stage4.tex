\part{The Data}

%%From authoryear.cbx
%% Candidate for moving to header files
\DeclareMultiCiteCommand{\fullcites}{\fullcite}{\multicitedelim\\}

%\chapter{Stage 4: Generating and analysing data}

\todo{this section to be done at the end, once we've decided each stage LOs}

You've now reached Stage 4, which means the end of your project is now in sight. In this stage you will be in the midst of your data generation and analysis, which is possibly the most exciting, yet demanding, part of your research: this is where you get your opportunity to make that contribution to knowledge.

This stage assumes that you have worked out most of your research design details and are now in a position to begin your data generation and analysis\footnote{If that's not the case then you should go back to Stage 3. You should also discuss your progress with your supervisor, revisiting your project timescale and risk.}.

With reference to our 5-stage framework, the activities which are in focus in Stage 4 are summarised in Table~\ref{tab:stage4}, which also provides some guidance for your interaction with your supervisor during this stage.

\input{Tables/ResearchActivities/Stage4}

\begin{question}[subtitle={Activity: Understanding the effort needed in this stage}] Consider Table~\ref{tab:stage4} carefully, paying particular attention to the entries in the `Effort' column. Make a note of the activities which are most prominent in this stage and what their deliverables and learning outcomes are.

\begin{solution}
Generating and analysing evidence will constitute by far your major effort in this stage (50\% of study time): in particular, the framework assumes that you will have worked out the details of your research design in Stage 3, so you can focus on applying your data generation and analysis methods. You will also start to interpret you findings, an activity your will complete in Stage 5. 
\end{solution}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

Note that your data analysis and interpretation may also prompt you to generate more data, including, perhaps, reviewing more academic literature or even re-thinking or adjusting your  aim an objectives better to reflect your improving understanding. Therefore, so you should expect some iteration back to activities you have carried out in previous stages, and revision of things you have written.

%\section{Generating and organising your raw data}
%Your \textit{raw data} are the data you generate\footnote{\enquote{Data you generate} includes data \emph{gathering} – if the data already exists, for instance, as might be the case with evidence. We use the more active term generate to cover all cases.} as part of your research. Which data you generate and how is determined by the choices you have made in your research design, informed by your research aim and objectives. In this section, we touch on key topics in data generating which are relevant to many projects, although they may not all apply to yours. This section is only meant as an introduction to those topics, to raise your awareness and point you towards specialised literature, should you need it, to deepen your understanding.
%By the end of Stage 4 your data generation, analysis and interpretation should be on a solid ground, and consistent with your aim and objectives. Your research design description should also be close to its final form. Given the criticality of this stage, it is essential that you work very closely with your supervisor throughout.

\chapter{Raw data}

Your \textit{raw data} represent any data you generate and analyse as part of your research, which in turn will be determined by the choices you have made in your research design, informed by your research aim and objectives.  In this chapter, we look at methods you can apply to generate and analyse your data. For each method, we provide:
%
\begin{itemize}
\item a brief description of the method;
\item key procedural consideration you should take into account;
\item other important issues, particularly in relation to threats to validity or feasibility within your project;
\item further sources to consult for more detail.
\end{itemize}

When we say \enquote{data generation}, we don't necessarily mean that you will create a new-to-the-world \enquote{data}\footnote{Although this might indeed be the outcome of your data generation.}. We simply mean new-to-your-masters-project data, which covers a multitude of sins, including:

\begin{itemize}
\item the creation of a brand new data set, which did not exist before your research project. This may be the result of data collected through new observations or measurements, a new survey, questionnaire or focus group, through selecting passages from documents, etc.
\item the extension of a previously collected data set with new elements, derived from those that already exist, for instance adding the mean value of a collection of numerical data, or grouping together specific distinct data into new categories that you have created;
\item the collection of previous data for reinterpretation, for instance if you are rerunning a previous experiment in order to confirm its results, or doing a meta-analysis of the literature in a particular area.
\end{itemize}

Our use of the term {data generation} includes all of these. Of course, in making a contribution to knowledge, you're going to have to do it regardless of the data generation method and so the data you generate as part of your research must allow you to conclude something new.

Related to data generation is the concept of ``data source", which is the location from which your data originates. If you are re-using existing data sets, this may well be an archive or a digital repository. For new data sets you generate, this may well be the experimental or real-world setting of your own observations and measurements, or a population of interest from which you will derive a ``sample'' for further analysis. The latter underpins many data generation methods, so that we will consider sampling in some detail next.

%A core element of all data generating methods is the choice of data sources. You've already had experience of doing this when you conducted your literature search as part of Stage~\ref{stage:?}\footnote{You might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. \todo{More here}

\section{Sampling: what, who (and how) to choose}\label{sect:DG:sampling}

Sampling is the process of selecting a subset\footnote{We could have said \enquote{sample} but that would have been circular.} for further analysis from a population of interest. 

Sampling assumes that there is a ``sampling frame'' as data source: a sub-set of the collection of the population of interest from which your sample is taken. In some sense, you have already experienced sampling as part of your literature review\footnote{You might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. Unless you had infinite amounts of time – which you didn't – and infinite patience – which you might have – you could never be 100\% certain that your literature search collected \emph{all} relevant papers:  the search space is infeasibly large (and not indexed particularly well). But you were systematic and achieved a practically good\footnote{By \emph{practically good}, we mean you found the most of the most important papers, some other papers, and didn't have to read \emph{every single paper}. I.e., you found a \emph{representative sample}.} coverage because of that.

More generally, sampling is used when we wish to study a population of interest, but this is infeasibly large or inaccessible for us to be able to study every single member of it. Instead, we choose a sample which is somewhat representative of the population characteristics, hoping that by studying the sample we can establish some properties or patterns of interest which can be assumed true of the population as a whole.

Broadly speaking, sampling can either be random or non-random. 

In \emph{random sampling}\footnote{Random sampling is also called \emph{probability sampling}.} some unbiased way of choosing the subset members from the population must be established upfront to inform sample collection, which is usually completed prior to any analysis. This is used particularly in quantitative research, and when generalisation of the results to the population is of primary importance, something enabled by the lack of bias in the sample selection process. 

Instead, in \emph{non-random sampling}\footnote{Non-random sampling is also called \emph{non-probability sampling}.}, the sample choice is based on the researcher's judgement and discretion, so that some element of bias may exist. Members can be added to the sample as the research progresses, interleaving data collection and analysis, until not more collection is possible or \textit{saturation} is reached, that is collecting more data would not bring extra relevant information. This kind of sampling is used particularly in qualitative research, where depth and richness of results are more important than the ability to generalise. 

Random sampling techniques include:
\begin{description}
	\item [simple random sampling] where each member of the population has exactly the same chance to be selected. It has the advantage that it is easy to implement, and given the complete randomness of the sample, generalisation is fairly reliable. However, it can be time consuming if the population if very large, and may not lead to a representative sample if the population has large sub-groups, which may be over-represented in the sample, with minority groups being under-represented.
	
	\item [stratified random sampling] where sub-groups of the population are identified based on common characteristics, the \textit{strata}, and sampling is random across those strata. The strata are not mutually exclusive: for instance, the population may have sub-groups defined by gender, ethnicity and level of education, which may overlap. This approach overcomes the over/under representation problem of simple random sampling; however, deciding on the strata may be difficult and will also complicate data analysis. 
	
	\item [cluster sampling] where the population is divided up in naturally occurring separate clusters, and the sample is obtained by randomly selecting some clusters and then randomly selecting members of those clusters. It is more cost-efficient than the other two approaches, but can introduce bias if the selected clusters are not representative of the whole population, so that the over/under representation problem remains.
\end{description}

Non-random sampling techniques include:
\begin{description}
	\item [purposive sampling] in which participants are selected by the researcher based on particular characteristics, knowledge, or expertise they have. It is often used for small, rare or unique populations, and is particularly suited to studies which intend to be deep and narrow, and for which generalisation to the population is not the main concern. As the sample choice is made by the researcher, it is prone to bias. However, it also allows the researcher to involve participants who can provide insights into such rare or unique groups.
	\item [convenience sampling] where participants are selected based on their availability or accessibility. This is quick and easy, but unlikely to produce a representative sample, so, once again, bias is an issue.
	
	\item [snowball sampling] which relies on referral from previous participants to recruit new ones. This is an effective approach when a population is difficult to access or when the topic is sensitive or tabu. This too is unlikely to generate a representative sample, and is prone to bias. However, it is a way to gain access to members of a population which may be otherwise inaccessible.
\end{description}

In summary, when choosing a sample, you need to consider various factors, including the aim of your study, the kind of methods you are applying, and the level of access you may have. Trade-offs are likely involved and you may not be able to obtain an ideal sample. Nevertheless, your sample will still be useful to your research, as long as you clearly explain and justify how it was obtained and what its limitations are.

\begin{question}[subtitle={Activity: Deep reading on sampling}]
Check back to your choice of research strategy. If you've chosen one which may require sampling, then you should go deeper into this topic to ensure you select the right kind of sampling for your study. We recommend you start by reading the following: \cites{}	
\begin{guidance}
The suggested reading is only a starting point. You should go deeper into the specific kind of sampling you are most likely to apply.
\end{guidance}
\end{question}

\begin{question}[subtitle={Activity: Your chosen sampling approach}]
Assuming your study requires you to perform some sampling, write down the sampling approach you are going to apply, with its justification in terms of your aim and objectives, and any trade-offs due to the practicality of accessing the sample. Record any possible weakness or limitation of your chosen approach, and how you will address them in your project.
\begin{guidance}
You can skip this activity if sampling is not required by your choice of research strategy.
\end{guidance}
\end{question}

%%%%%%%
\newcommand{\ResGenTechnique}[1]{\begin{question}[subtitle={Activity: Do I need to know about #1?}]
Check back to your chosen research strategy from Stage 3. Does it involve data generation using #1? If so, read through the remainder of this section and complete the activities.
\end{question}}

\newcommand{\ResGenExtras}[2]{\begin{question}[subtitle={Activity: Deep dive into #1}]
To find out more about #1, take a look at these resources:

\fullcites#2

\end{question}}

\section{Modern standards}

Modern standards of research often require that your data be made available to other researchers so that your research can be verified or even rerun. In fact, it is increasingly the case that data sets are published and shared by entire research communities, often used as testbeds or benchmarks for new knowledge contributions. For instance, in medical applications of Machine Learning, in which new knowledge can be the fractional improvement of the performance of an AI algorithm to, say, diagnose a medical condition from images, not being able to share the data set you have used in your research can negate your knowledge contribution. Therefore, you should consider whether your data (or a sample of it) should appear as an appendix to your dissertation, or whether they should be made available in their entirety to your examiners, or even to the wider research community, and how.

Modern standards of research also require you to comply with regulations on data privacy and protection\footnote{We discussed GDPR in Section~\ref{sect:GDPR}.}, so that as part of your data generation process you should also consider the need to anonymise data\footnote{There may be a route to your degree in which your thesis is not published. Should you have any concerns about the release of data, please do find time to discuss this with your supervisor, balancing the needs for total anonymity with those than can be achieved through data anonymisation.} without losing their research value for your project or the need to release commercial in confidence or otherwise sensitive data.  

\section{Managing raw data}

%If, for instance, you conduct experimental research, you will have data about your subjects, perhaps collected through questionnaires, and variables of interest, with their measurements. If you use interviews or focus groups, you may have audio or video recordings and their transcripts, or notes you have taken. For survey research, you will have a large number of responses to the set questions. If you use existing secondary evidence, for instance as part of case study research, then you will have all sort of documents, from reports to images, diagrams, etc.: from such documents, you will need to extract relevant raw data for your analysis.

Before proceeding with your data analysis, you must ensure your raw data are properly organised and stored, so that you don't loose track of important information, and you can easily locate and refer back to appropriate data during your analysis and when writing up your research.

It is highly likely that your raw data will be in some digital form. Although techniques for doing so are outside of the scope of this book, your digital data storage should be secured against data loss either due to technical issues, such as computer failure, or due to a data breach, such as through cyber security attacks, at least to the standards required by law, any additional requirements made by your organisation, those of any participants, their organisations, and any other stakeholders\footnote{Once upon a time, in a galaxy far, far away, data generation and storage used to be a \emph{laissez-faire} thing. Today, your university or employer can be fined vast amounts of money for any data misuse, so they tend to take it more seriously. If data loss were to happen, amongst other things, it'd probably means you'll fail your degree.}.

%is regularly backed up, not to risk loosing it, and, if you collect any personal information, your data, whether physical or digital, must be stored securely to comply with data protection\footnote{See Section~\ref{sect:personalData}.} regulations.
%
It is also important that you put your raw data in a form which is useable for analysis. Spreadsheets are particularly useful for this purpose, especially if your data is quantitative, so that this is a common way to organise and store raw data. In fact, most publicly available data sets used in research and beyond are stored as spreadsheet files: if you are going to use one such data set, then your raw data are likely already organised for you!  

Spreadsheets organise data in rows and columns, so that you can easily enter your raw data using rows for your observations/measurements and columns for your variables. As we will see later on\footnote{See Section ??}, spreadsheets come a wide range of functionalities for data manipulation and for some level of data analysis. They are also easily extensible, so that you can grow your data sets incrementally.

\begin{question}[subtitle={Activity: Organising and storing your raw data}]
Consider the data and evidence you have collected or are planning to collect. List the actions you have taken/will take in relation to:
\begin{itemize}
	\item organising your raw data
	\item storing and backing up your data
	\item protecting personal data
\end{itemize}
Make sure you complete those actions as you generate your data, and before performing any data analysis.
\end{question}

%\endinput

\chapter{Data generation methods}

In this section, we step through the most used data generation methods – those that were mentioned within the research strategies in Stage~\ref{stage3}, i.e., Interviews, Journalling, Observations, Questionnaires, Documents, Focus groups, Field work, Computational thinking, Mathematical thinking, and Statistical thinking. \todo{cross-check with stage 3 if this is the full list}

Most of these methods concern \textit{empirical data}, that is data that is gathered through our five senses or from experience, and then used as the benchmark against which theories and advances in knowledge are made.

\section{Observations}\label{sect:DG:observations}

 Observations constitute one of the main ways in which empirical data are generated\footnote{Whole books have been written on observations as a research method; we can give but a shallow introduction. Further sources you can use are included at the end of this section.}. In fact, according to \cite{marvasti2014analysing}, ``Observation is the foundation of science.'' 
 
  This method requires the researcher to make their observations\footnote{Hence the name...} of phenomena of interest. What you will observe are core characteristics of the phenomena that you have identified as part of defining your research problem. 
  
  \ResGenTechnique{observations}
 
 Observations can be made directly, through our naked senses, or through instruments which enhance our sensory capabilities, such as a telescope, a microscope or the ``a myriad of other ingenious inventions designed to make the invisible visible, the evanescent permanent, and the abstract concrete'' \cite{daston2011introduction}. Quantitative observations, say, the size or weight of an object, are usually referred to as `measurements'.
 
 
   
 %\blockcquote{daston2011introduction}{Observation[s...] instruments include not only the naked senses, but also tools such as the telescope and the microscope, the questionnaire, the photographic plate, the glassed-in beehive, the Geiger counter, and a myriad of other ingenious inventions designed to make the invisible visible, the evanescent permanent, and the abstract concrete. Where is society? How blue is the sky? Which ways do X-rays scatter? Over the course of centuries, scientific observers have devised ways to answer these and many other riddles.}

 %\todo{Ensure that\footcite{driscoll2011introduction} \emph{Voluntary participation}, \emph{Confidentiality and anonymity}, and \emph{Researcher bias} are covered elsewhere, if not here.}

%\paragraph{What to observe} What you will observe are core characteristics of phenomena of interest that you have identified as part of your research problem, whether they are interactions between atoms, between school children, or even your own actions, thoughts, and – perhaps even – biases. It may be that, in the course of your research, you will observe related or proxy phenomena, as needs must. Part of your observation skills will be to identify those related to and proxies for, to record those observations and to iterate those records into structures that capture the characteristics that are necessary to do the research on their back. 

\paragraph{What to observe} Observations are versatile tools for almost any research domain, and your own domain will determine what sort of observations you will make. Observations range across natural phenomena – such as the different proportions of plant species that populate a wilderness garden – through to artificial phenomena – the way that buses drop off and pick up their passengers at a train station – and to social phenomena – the different ways in which a train station is used by commuters in the morning and the evening – as well as more complex combinations of each. Each will use different observations techniques and tools, and each with different constraints. 

\paragraph{Observation types} Observations can be \emph{naturalistic}, when phenomena are observed as they happen in their natural setting -- for instance, observing the behaviour of animal species in their habitat, or \emph{structured}, when phenomena are observed in a somewhat artificial environment, such as during an experiment  -- for instance, giving people a specific task to perform and observing how they carry it out. In this case, often the aim is to collect quantitative data, say the speed at which the people can complete the task. 


\paragraph{More on social observations} As an observer of people, you can act as either a \emph{participant} or a \emph{non-participant} observer. The former is a researcher that interacts as a member of a community under observation, becoming an active participant in the group or situation under study. In effect, as a participant observer, you would be \enquote{living} alongside those you observe – you might be a commuter that uses the train station and so share the experience of the other commuters you observe. Instead, in non-participant observation, you would remain separate from the group or situation being observed -- you may observe commuters using the train station, but not actively become one of them. 

Depending on whether people are or not aware of being observed, observations can be \textit{covert} or \textit{overt}\footnote{The terms disguised and undisguised are also used in the literature.}. Covert observations have the advantage that people's behaviour is not affected by their awareness of being observed, but, of course, they raise some important ethical and legal issues, in relation to informed consent, and privacy and anonymity. If the judgement is that the phenomena observed do require privacy – perhaps you wish to observe commuters' use of restrooms in the train station or customers in a betting shop – then you must explicitly ask for permission – or change your research problem! Otherwise, in a public space, there may be no overriding expectation of privacy and observations can be done without explicit consent. Your university is likely to have strict regulations on the matter, or even prevent you from conducting covert observations as part of your research. 
%Alternatively, you may be an \emph{unobtrusive observer}, a researcher that works outside of the \enquote{frame of reference}\footnote{The frame of reference is the relation between the observer and what is under observation.} for the observations you will make, perhaps standing at the entrance/exit to the train station counting how many commuters pass.

\subsection{Procedural considerations}

In order to apply this method, some preparation is needed for you to decide what you will observe as how. Specifically:

\paragraph{Phenomena}  You will need to decide which phenomena to observe, whether natural, artificial, or social: this choice will depend on your research problem, and aim and objectives. 

\paragraph{Kind of observations} Depending on the phenomena, you will need to decide whether you will perform naturalistic or structured observations. In addition, for social phenomena, you will need to decide which mode, whether participant, non participant, overt or covert. For the latter, you must also identify the steps you will take you ensure compliance with ethical and legal guidelines.

\paragraph{Time and place} For all kinds of observation, you must determine the time and place at which those observations will be made. For participant observations, this choice will be determined by your participation in the group or activity being observed, which may or may not be under your control. For instance, if you are a participant observer of train station usage, then you can determine when to use the station and make your observations. However, if you are a participant observer in a change project within your organisation, then the timeline of the project will determine when your observations can take place. In all cases, you should draw a schedule which establishes the timing and frequency of your observations, and which provides an efficient way for you to conduct your observations. For instance, it may be that you make exaggerated use of the train station\footnote{You could eat there, for instance, or use any shops that are colocated.} to condense many months of participant observation into weeks or days – after all, your research project is time bounded – perhaps visiting ten times per day rather than just two. 

\paragraph{Use of instruments} You may be able to make your observations using only your senses. However, many phenomena do not permit observation through the senses unassisted – for instance, the search for exoplanets\footnote{For instance, \textcite{jones2008exoplanets}. But don't let this exciting mission to explore strange new worlds; to seek out new life and new civilizations; to boldly go where no one has gone before distract you. Too much.} requires complex and delicate instruments which will be located on mountain tops. In this case, the availability of the equipment you will use will determine when and how you make your assisted observations  --- you will also need to gain access to the equipment, and this will constrain your schedule and may alter your research plans\footnote{Remember, plans never survive first contact with reality, so also plan to have a backup plan that you can use should your first plan to make your observations fail!}.

\paragraph{How to record observations} It is important your record what you directly observe, separate by any added interpretation\footnote{That should happen later on, as part of your data analysis.} to avoid possible bias affecting recorded observations. To this end, observations are typically recorded in notebooks with a double entry, which separates pure observations from possible value judgements made by the observer – for instance, observing someone \enquote{waiting impatiently for the train door to open} is ascribing feelings to the person observed which, by their nature, are hidden from the observer, but may be inferred from the observed's body language. By separating them out, another researcher reading your notes can clearly differentiate direct observations from such inferences. In some cases, you may be able to use audio and video recording, say using your smart phone, to capture your observations for follow-up analysis. In this case, ethical issues in relation to privacy and informed consent also apply.

\subsection{Other things to think about}

Observations are by no means an easy way of generating research data, and there are many issues that can arise, including:
%
\paragraph{Hawthorne effect} Overt observations can lead to the so-called Hawthorne effect\footnote{This term was coined in the 1950s in relation to a productivity study carried out at the Hawthorne Works, an electric plant in Chicago.}, which consists of people changing their behaviour due to their awareness of being observed. This can be mitigated by building a rapport, including  spending more time with the people being observed, observing them for longer periods of time, and, in case of structured observations, by ensuring that the tasks participants are asked to do come natural to them.
	
\paragraph{Observer bias} All observations can be influenced by the observer's own bias, whether implicit or explicit, or the result of overfamiliarity with the phenomena of interest. To guard against it, triangulation should apply, including using different data sources and collection methods, or having multiple observers all following a standardised procedure. The use of double-entry notebooks, as described above, can also help, as they separate pure observations from interpretation and inferences made by the observer, with the latter being the subject of scrutiny for potential bias.

\paragraph{Volume of observations} Observations can lead to vast amount of data to analyse. Different analysts, or different stages of analysis as your research progresses, may focus on different aspects of the same data. This can be a good thing should your analysis deepen due to understanding more about your observations, but may also lead to analysis drift or even \enquote{paralysis through analysis} in which no progress is made due to too much depth. To avoid this, keep a clear eye on the prize: your research goal, and set regular times at which you can reflect on progress.

%\item The analysis of observations depends on the researcher's chosen focus and philosophical and analytical framework. This is a natural dependency and can give great richness to observations, even those that are taken from the record. However, they can also lead to overthinking and, like the previous item, paralysis, as well as to prose that is obtuse and disengaging for the reader\footnote{And examiner! Consider, also, that the examiner might not share your focus and that this difference might be sufficient for them to discount your work as without value. Not likely, but care is needed.}.


\subsection{Further reading}

\ResGenExtras{observations}{{daston2011introduction}{marvasti2014analysing}{simpson2003using}{driscoll2011introduction}{angrosino2003observations}{sapsford1996data}}

\section{Questionnaires}\label{sect:questionnaire}

Questionnaires\footnote{Questionnaires are just one in a rich collection of \emph{survey tools}, others of which are described below.} are versatile tools for generating data from participants by asking questions\footnote{There's a hint in the name – \emph{question}naire – although why two \enquote{n}s; does no millionaire, billionaire, or debonaire use them?}. They allow a researcher to collect participants' answers about their attitudes, preferences, opinions, behaviours, etc. You might use a questionnaire as a way of collecting statistically significant responses from a population sample, but there are other uses as well, for instance as the basis of interviews\footnote{Which we cover in the next section.}.

\ResGenTechnique{questionnaires}

If you do use a questionnaire, its thoughtful design is of critical importance. Otherwise, you might be asking your (willing) respondents to spend a considerable amount of their valuable time answering questions the content of which are not helpful for your research. As they might not be so willing to help a second time, getting the questions right\footnote{Often called \emph{questionnaire design}, although this conjures up glossy format and whizzy web-pages which is of secondary importance. Unless, your questionnaire is about the design of questionnaires, of course.} the first time is important. 

Administering questionnaires is nowhere near as difficult as it used to be as the number of online resources for doing so increases. And, probably because of this, there are plenty of resources in the literature and online to help you design your questions. Their descriptions can be a little technical, however, so the following glossary might help you engage with them better.

\paragraph{Essential questions} %You should identify 
This the smallest possible set of questions you absolutely need to ask to address your research aim and objectives. While using several questions will give you richer data sets, long questionnaires tend to put people off, so that fewer people may be willing to participate. 

\paragraph{Profiling questions} %These are 
These questions ensure that your respondents match specific characteristics you are interested in: say, you are studying the usability of a new product, then you will need to know the extent your respondents have engaged with that product. This is particularly the case if you are running a large survey and don't know who is going to respond.  

\paragraph{Demographic questions} %These are 
These are often used so that you can then compare answers across different sub-groups, say, based on gender, age or ethnicity, etc.

\paragraph{Response options} Questions are broadly divided into \emph{closed} and \emph{open}-ended. Close questions restrict the possible responses to a set of given choices, while open questions allow respondents to use their own words freely to answer the question. 

\subsection{Procedural considerations} 

\paragraph{Using tools} While you can design your questionnaires from scratch using your word processor, there are plenty of specialised digital tools, many of which are free, that can make it a lot easier\footnote{Examples include: {\color{red}add list here and URLs.}}. They usually come with: templates and pre-defined question types that you can customise for your study; statistical analysis and data visualisation features that you can apply to the data you have collected; export functions that allow you to save the data to a spreadsheet for further analysis. Overall, if you need to develop questionnaires for your research, they can really help you speed up the process, so that it's well-worth the investment of time in climbing their learning curve. 

\paragraph{Drafting, testing and piloting} Unless you have many years of experience in questionnaire design, your first questionnaire draft will be far from suitable. Indeed, releasing your first draft without further thought may lead to you not only generating no useful data from it, but also putting off your audience sufficiently that they may not be willing even to look at your second version. So, once you have a first draft of your questionnaire, you should test it and refine it. 

Early testing can be done by asking a friend, a family member\footnote{Probably, but not always a friend:)}, or a colleague to work through the questions, provide their answers and any other feedback they might have. This will give you early indications of problems with your questionnaire\footnote{Although it's sometimes difficult, you'll make more progress and more quickly if you think of the questionnaire as imperfect, rather than you. You can then apply comments – even if they are negative – to the questionnaire rather than having a personal emotional reaction to them. For each comment, make sure you understand how it can be addressed in your questionnaire. This last tip also means that you can welcome (but ignore) comments that can't be addressed.}, which you can spot, for instance, if the respondents are confused – which may point to a lack of clarity in the questions – or hesitant – which may point to a poor choice of response options or to inappropriate scales – or disengage before completion – which may point to too many questions being asked. Be sure to loop back to those that have helped you to check that you have addressed their comments. 

Later in the process of designing it, however, you should take expert advice including, of course, that of your supervisor, to get to the final agreed form. In addition, you could pilot your questionnaire on a small number of respondents first, then revise it as necessary before using it more widely.  

\subsection{Other things to think about}

In designing you questionnaire you should pay particular attention to the following:

\paragraph{Plain language} Your questions should be clear and plain, and you should avoid jargon and idioms, to ensure your participants understand what you are asking, particularly if not native speakers. 

\paragraph{Unbiased language} Your questions should also be objectives, that is you should avoid any judgemental term or tone which may reveal your own opinions or believes, or influence participants to answer in a particular way. You should also avoid questions which make assumptions about your respondents' habits or behaviours: for instance, asking participants what they eat for breakfast, assumes they all take breakfast, which may not be the case.

\paragraph{Double-barrelled questions} Also termed \enquote{compound}, these are questions that ask more than one thing, while only allowing one answer. These should be avoided as it would be difficult, if not impossible, to establish in your analysis which part of the question each participant has answered. Instead, you should split the question into separate questions each addressing a specific thing.

\paragraph{Closed and open questions} For your closed questions you should ensure that the possible answers provided cover all possible options\footnote{Or, at least those you're interested in.} and do not overlap, that is they are mutually exclusive. Instead, for your open questions you must ensure they are sufficiently constrained so that your participant's answers don't end up being too vague or off topic, hence not providing much value to your research.

\paragraph{Scales} If your questions require participants to estimate or measure something, you need to worry about both validity and reliability when setting up the scales for possible answers. In this context, validity means that the chosen scale should allow respondents to measure something accurately; while reliability means that, under the same conditions, respondents will be able to come up consistently with the same (or very close) measurements.

\paragraph{Question grouping, ordering and flow} You should group related questions\footnote{For instance, those intended to establish a demographic of respondents.} together, and establish a logical flow in sequencing groups of questions, so that topics follow naturally from one another. Question order in each group also matters: as a rule of thumb, simpler questions should precede more complex ones.

\subsection{Further reading}

\ResGenExtras{questionnaires}{[\nopp C14]{oates2008researching}[p250]{hays2003case}{burns2009action,mcclure2002common}{najafi2016observation}{robertson2002automated}[C6]{kielmann2012introduction}}

\section{Interviews}\label{sect:DG:sampling}

Interviews are a method for generating data from participants by asking questions and recording detailed answers. They are a form of conversation between the researcher and one or more interviewees, designed by the researcher to gain insights and opinions on a specific topic. The researcher guides and controls the conversation and asks the questions.

\ResGenTechnique{interviews}

The personal approach that is a characteristics of interviews means that they are a great way of accessing a (group of) individuals' feelings, thoughts, ideas, and/or experiences, data that can be difficult to generate in other ways. They can help you obtain detailed information on a specific issue or topic, asking open-ended questions which may be tackled or interpreted differently by different interviewees. They are also an effective way to investigate sensitive issues or privileged information that interviewees may not be willing to commit to writing.

Interviews can also provide direction for new research by giving expert indications of where problems lie in a particular domain. As such, interviews can often be used as a way into a discipline, filling in useful background through personal experiences, and having access to otherwise difficult to access information. 

There are three main kinds of research interviews:

\paragraph{The structured interview} serves as a repeatable framework by which each participant is asked the same questions in the same way. There is no scope for deviation from the structure, so that auxiliary questions and follow-ups are not used.

Structured interviews are the closest to being time bounded and predictable; if you only have 8 hours to conduct 24 interviews for instance, a structured interview would be the best way to achieve this. 

Your skills as an interviewer will be tested by structured interviews: it is often difficult not to stray outside of the structure when an interesting answer is given, and you may have to cut a participant short if their answers overrun or diverge from the structure\footnote{In our experience, this is a perennial problem, so don't underestimate the difficulties you will face as an interviewer.}.

\paragraph{The semi-structured interview} serves to identify areas of interest to the researcher, with interesting responses being welcomed and followed up if appropriate. Interviewing a domain expert on your chosen topic would be well-served by a semi-structured interview as their expert knowledge could be probed with follow up questions.

The semi-structured interview does not naturally time-bound the interaction, and so – if you don't have unbounded amounts of time – you will have to balance the breadth of questions with the depth of responses.


\paragraph{The unstructured interview} has no structure to constrain the route through the data that the interviewee wishes to take, although the interview may begin with the same question each time. As the direction may wholly be decided by the participant, you challenge may be retaining forward motion and focus during the interview.

\subsection{Procedural considerations}

Main factors to consider in interviews include:

\paragraph{Interview type} In being standardised, structured interviews make it easier to compare your interviewees' answers objectively. However, interviewees are limited to the set questions, so there is no scope for digging deeper into their answers. If you need deep insights, you should use the less structured interview forms which allow you to probe your participants responses.

If you have a good level of domain knowledge, you can use the less structured interview models, as you will be able to follow your participants' answers more easily and direct their comments towards your research interests\footnote{Of course, you can always use structured interviews even if you do have domain knowledge – there's nothing to stop you.}. If you don't already have a good level of domain knowledge, then you will be putting more effort into the design of the interview, so that you can simply capture your participants' responses to your – well-designed – questions. 
%
%\endinput
\paragraph{Whom to interview} You will need to choose your interviewees carefully. In the perfect case, you should interview until the responses you are receiving are \enquote{guessable}\footnote{I.e., you no longer get novel answers to your questions, indicating that the topic has been covered.}. Practically, you will have limited time and resources, and limited access to interviewees, so that sampling may be required: in such case, you should follow the advice on sampling in Section~\ref{sect:DG:sampling}. 
%
\paragraph{Ethical and legal matters}  Your university will have strict guidelines on how to approach and work with human participants, which you should investigate before you contact your potential interviewees. At a minimum, those guidelines will cover informed consent, handling personal data, and health and safely, but they may also prevent you from interviewing certain groups of people, for instance minors or vulnerable adults. You should go back to the advice in Section~\ref{??} to refresh you understanding of ethical and legal issues in research.

\paragraph{Testing and reviewing} You can apply some of the advice in Section~\ref{sect:questionnaire} in relation to designing your interview questions. Once you've drafted your interview questions, you should do a dummy run of your interview with a willing friend, family member or colleague, and use their feedback to improve your questions\footnote{Repeat this with as many willing participants as you can until you're happy with the interview format or until you run out of willing participants, or time! Make sure that you do not dip into your target population for these preliminaries.}. In particular, you should consider:
%
\begin{itemize}
\item whether you were able to put the participant at ease during the questionnaire. If not their nervousness might influence their ability to contribute, and you should consider what to do differently
\item which questions worked well and led to useful responses, and which were confusing or led to unhelpful answers. For the latter, you should consider how to reword them – perhaps with the help of your participant\footnote{\enquote{I would have asked it this way}...}, by having alternative versions of the questions, or by removing or replacing the questions
\item (if time constrained) which questions overran, and whether you can rephrase them to be less \enquote{open}
\item (if structured) whether were you able to keep to your \enquote{script}. You should reflect on how will you resist the temptation to probe more deeply, or whether you should to consider moving to a semi-structured or unstructured form
\item whether the questions were in a logical order, ideally they grouped by topic. If not, consider re-arranging them to build responses in the most productive way
\item whether you have sufficient questions to elicit the data you need, or there other questions you should ask
\end{itemize}
Once you are satisfied with your questions, you should run them past your supervisor – they will be sure to have comments.

\paragraph{Recording answers} You need to decide how you will capture your interviewees's answers. If you are planning to use audio or video recordings, you will need to ensure your participants are aware and give their explicit consent. If not, you will need to take notes manually. In this case, you should also test your note taking, to ensure you are able to capture everything of interest\footnote{Longhand notes can be taken at 35 words per minute; spoken text is often as fast as 120 words per minute.}.

\paragraph{Where to hold the interview} With the advances in video conferencing technology, interviews can be conducted effectively online, with the added bonus that they can be easily recorded, often with transcripts automatically generated. However, interviews in a physical space where you are colocated with your interviewee, remain common. For these, you will need to ensure that you have an appropriately comfortable venue for your interview, including access to comfort facilities. Public spaces – where you could share a coffee, for instance – may create a more immediate feeling of intimacy, and so deeper responses, but they may not be suitable for discussing sensitive issues or if background noise might interfere with your record keeping. Therefore, make sure to check the venue out at the appropriate time of day to ensure it is appropriate for the interview and a recording device can handle any difficulties.
%
\paragraph{Opening and closing interviews} As part of giving their inform consent, interviewees should be fully aware of what you are trying to achieve in your research and what the purpose of the interview is within it. They will also be interested in how you will use their answers, and should be reassured as to any use of confidential information or personal data. It is therefore good practice to provide this information at the start of your interview, or even as part of inviting them to participate: perhaps share a sheet which includes this information and describes the research you are doing. At the end of the interview you should also thank them and explain what will happen next, including how they can get in touch if they have any further concerns and follow up questions.

\subsection{Other things to think about}

\paragraph{Making a checklist} There is lots to think about when preparing and conducting interviews. Have you made all necessary arrangements to conduct the interviews? Did you obtain all necessary permissions, including informed consent? Do you know how you will record the answers? What would happen if your audio recording device went wrong? Would you have a backup for the interview? What if you forgot to turn it on?\footnote{Oh so easy to do...} Write a checklist of instructions for yourself to follow before and after each interview, so that you can be sure not to miss anything important. 

\paragraph{Being a good interviewer} Try, to the extent possible, given the format, to allow your participant to govern the speed and direction of the interview. Allow them to talk in complete sentences without interruption, or have a good reason to interrupt. If you need to interrupt, apologise for doing so and tell them the reason why you have done so\footnote{\enquote{I'm sorry to have to interrupt, but we only have 5 minutes left and ...}.}. Be polite and encouraging, as your participant might be nervous.


\subsection{Further reading}

\ResGenExtras{interviews}{[C13]{oates2008researching}[p43]{johannesson2014research}[p194]{secor2010social}[p250]{hays2003case}{mcclure2002common}[p52]{peoples2020write}[6397]{jorgensen2001grounded}[]{hycner1985some,englander2012interview,ramsook2018methodological}{robertson2002automated}[C4]{kielmann2012introduction}}

%\endinput

\section{Focus groups}

Focus groups engage participants in interactive discussions to develop an understanding of complex phenomena and generate new hypotheses for further research or practice. They are effective at surfacing a full range of perspectives held by the participants and, through their interaction, expand on their individual contributions. They are particularly useful to uncover data and ideas that may not come up in one-on-one interviews, and are generally a more efficient way of collecting data than multiple interviews.

\ResGenTechnique{focus groups}

Focus groups include participants who share some common characteristics or interest. They are moderated, often by the researcher, so that they combine elements of interviews and observations alongside the group discussion. The moderator plays a crucial role in facilitating group processes, maintaining focus, and controlling participant interactions. Depending on the research aim, it might be necessary to run a series of focus groups so that trends across different groups can be identified.

There are different flavours of focus group. For instance, there may be two moderators with separate roles, say one looking after the procedures, the other focusing on the discussion, or both contributing to the discussion, but taking opposite sides or one playing devil's advocate\footnote{The term `duelling moderators' is used in this case.}. You could have a two-way focus group, in which there are actually two moderated groups each listening to each other's discussion, with a view to stimulate richer insights through rebuttal or further elaboration of ideas. You may also reduce the number of participants to create a more intimate `mini' focus group.

To optimise data collection from focus groups, careful attention must be paid to the composition, size and number of groups, selection and training of the moderator(s), and development of the questions used to guide the group discussion. 

\subsection{Procedural considerations}

\paragraph{Group type} Depending on your research aim, you should decide which kind of focus groups you will need, including whether more than one moderator is required, or if a series of focus groups would be desirable.

\paragraph{Group size} The number of participants in a focus group is usually from between 8 to 12 participants\footnote{Is a 12-person jury simply a focus group?}, although other sizes work too, the smallest useful size being 4 to 8 for `mini' focus groups. Anticipating subject loss, you should over-recruit participants by approximately 25\%.

\paragraph{Participants} The purpose of a focus group is to obtain data regarding ideas, attitudes, understanding, and perceptions on a specific topic, and choosing participants that can contribute to this purpose is an important part of identifying the right participants. Participants should therefore be selected based on their experience and interest in the topic, rather than through random selection. Although the potential range of participants might be limited by context – you may need them to be selected from a small organisational group – the choice should be made so that they come from as diverse range of backgrounds, views, and experiences as possible. Participants should not, however, be chosen to be individuals suggested by fellow group members.

\paragraph{Moderation} A skilled moderator is needed to guide the discussion. Moderators' key qualities include empathy, positive regard\footnote{This denotes a general affirming caring, and supportive attitude.}, being able to use of pauses and probes effectively in the group discussion, and exercising control in an unobtrusive manner. If you do not have access to a skilled moderator, then accessing moderator training for yourself might be desirable\footnote{There are videos purporting to guide moderators on youtube.}.

\paragraph{Location} Focus groups can be run online or participants can be physically co-located. For the latter, placing participants within an uncomfortable environment is likely to lead to negative outcomes. Given that a focus group might last for an extended period, appropriate timing should also be considered, with access to comfort facilities, etc., and an explicit timetable which includes breaks.

\paragraph{Choice of questions} Focus groups are sometime referred to as group interviews, in the sense that the moderator seeds and controls the discussion by asking questions. It is important therefore that you consider which questions to ask, including opening questions to get the discussion going, or questions to probe further and to ensure all participants get involved. Open-ended questions are the norm in focus groups as the intention is to elicit insights, attitudes, opinions and perceptions. 

\paragraph{Discussion etiquette} You will need to establish an etiquette for the group discussion, including expected participants' behaviour, for instance in addressing each other, taking turns when speaking, whether mobile devices should be switched off, etc. 

\paragraph{Recording the discussion} Usually video or audio recordings are used to record the group discussion, so you will need explicit consent from the participants. Note taking is possible but only if there are separate moderators and recorders.

\subsection{Other things to think about}

\paragraph{Groupthink} The point of a focus group is to elicit diverse views from participants, so it is important to be wary of \emph{groupthink}, a tendency to conform to majority opinion to maintain unanimity and avoid confrontations, and which may inhibit discussion and the expression of diverging views. As a moderator you can mitigate against groupthink by asking probing questions, ensuring that a plurality of views are expressed, or playing devil's advocate in relation to prevailing ideas.

\paragraph{Social desirability bias} This is the tendency of participants to express opinions which they think are more likeable or acceptable by the group, even if they are not honest accounts of their views or experiences. The moderator can mitigate against this bias by framing a question in an hypothetical or indirect manner, to distance it from the participant's personal experience, the latter being something they may be reluctant to share. Establishing an atmosphere of trust, anonymity and confidentiality can also help participants being more open and honest.

\paragraph{Group dynamics} Group culture and power relations, and participants' personality may also introduce bias and affect the end result. For instance, shy participants or introverts may feel overpowered and intimidated by assertive participants, whose views may then become prevalent. The moderator has the task to ensure all voices are heard, possibly by calling out shy participants individually, or time-limiting contributions to prevent the most talkative participants from taking over. Larger groups may be more difficult to manage and control, so that group size should be chosen wisely.


\subsection{Further reading}

\ResGenExtras{focus groups}{\cite{powell1996focus}{smithson2000using}{plummer2008focus}}

https://www.eiu.edu/ihec/Krueger-FocusGroupInterviews.pdf

\section{Delphi}

With the {Delphi} method\footnote{Also called Delphi technique in the literature. Its name is a reference to the ancient Greek temple that hosted the Oracle of Delphi, famous for her prophecies.}, a group of experts are consulted individually by the researcher with a view of obtaining a consensus on a particular issue, problem or topic. 

\ResGenTechnique{the Delphi method}

The method involves an iterative process of collecting, synthesising and circulating anonymous judgements among those experts to arrive eventually at a consensual view. At each iteration the experts can revise their opinion in light of what has emerged in the previous iteration. Anonymity is used to ensure that no individual expert exercises undue influence on the other experts, hence  mitigating against groupthink, and that all participants feel free to express their opinions without any fear of judgement or criticism, hence mitigating against social desirability bias. 

This method is based on the assumption that a group of experts are more likely to arrive at an informed and valid position than an individual, due to the diversity of knowledge and experience. The judgements and consensus gathered constitute the generated data that are subsequently analysed by the researcher.

The Delphi technique is suited to situations where it important to access collective expertise due to paucity of relevant published knowledge, particularly to inform decision making, policy creation, risk management or forecasting.

\subsection{Operational considerations}

\paragraph{Selecting experts} Participants are selected based on their knowledge and experience in relation to the issue, topic or problem under study, so this is purposive rather than random sampling. Diversity of experts is important to ensure breadth of expertise, hence to generate valid outcomes. Between 10 and 50 experts are usually selected to participate in a Delphi study, although both smaller and bigger numbers have been used in studies reported in the literature. The more participants, the more resource-intensive the process of collecting, analysing and combining feedback is going to be.

\paragraph{Process} Maintaining anonymity is essential throughout the process. Each expert is initially consulted separately by the researcher, who then anonymises and aggregates the group responses and circulate them to the same group of experts to seed the next round of consultation. Providing feedback at each round is the essential mechanism to foster convergence of opinions, as such feedback is used by each expert to review and refine their own opinions or judgements. In theory, this process is repeated over multiple rounds till a consensus is reached. Practically, there will only be a limited research time over which the process can be iterated. In addition, experts' availability should be taken into account, as well as possible fatigue resulting from too many iterations.

\paragraph{Consensus criteria} It is important to establish explicit criteria to decide when consensus is reached. For instance, the researcher may establish a threshold, say when a certain percentage of the experts agree\footnote{A 75\% threshold is often used in the literature.}.

\paragraph{Location} The method is usually executed remotely as there is no direct interaction between the experts.

\subsection{Other things to think about}

\paragraph{Resources} This method is resource intensive, particular if you need to conduct several rounds, and you must ensure commitment from your participants for the whole duration of the study. If you are short of time, a focus group may be a better option.

\paragraph{Lack of discussion} The feedback at each iteration is mediated and controlled by the researcher and there is no direct interaction or discussion among the experts. If a deeper investigation of ideas is needed, then other methods should be used, for instance interviews or focus groups.

\paragraph{Difficulty in reaching consensus} Consensus may be difficult to reach, particularly, if you are investigating a particularly complex or contentious issue, or you are hoping for predictions concerning highly uncertain or volatile contexts. In such cases, you should reflect of the extent consensus is needed and, if not, then consider alternative methods which may allow you to explore alternative or contrasting views and positions.

\subsection{Further reading}

*** find more/better references

Skulmoski, G.J., Hartman, F.T. and Krahn, J., 2007. The Delphi method for graduate research. Journal of Information Technology Education: Research, 6(1), pp.1-21.


\section{Journaling}\label{sect:DG:journaling}

Journaling is a method requiring participants in a research study to keep regular written personal records in the form of a diary\footnote{Or journal, hence the name.} of their experiences and observations during the study. Participants are encouraged to engage in self-reflection in order to surface their inner thoughts, feelings, motivations and perceptions.

\ResGenTechnique{journaling}

This method generates rich and detailed qualitative data on the participants' subjective experience. It can provide deep insights into complex phenomena, including how things change over time, and allows the collection of data on everyday experience in naturalistic settings. Because of these characteristics, it is often applied in ethnographic and grounded theory research.

\subsection{Procedural considerations}

%The two uses of journaling lead to two related but different workflows.
%
%\paragraph{For research participants}
%

\paragraph{Diary form} Journaling can make use of either hand-written or digital diaries\footnote{Of course, accessing hand-written notes will be more labour intensive than electronic ones.}. One or more diaries can be used for different aspects of the journaling process. 

\paragraph{Prompts and guidance} The goal of the self-reflection should be established at the beginning by the researcher and clearly explained to the participants. Journaling prompts are used to ensure that diary entries align with the objectives of the research, that is to guide participants' focus towards diary entries that will be useful to the research. Prompts can take the form of questions or comments on those diary entries. Lack of guidance or clear instructions is likely to lead to poor data, which are inconsistent or incomplete.

\paragraph{Participants} Journalling is demanding for participants as maintaining regular diary entries over lengthy periods can be challenging. Therefore, recruiting participants willing to commit to journaling for the duration of the study is essential to the successful generation of comprehensive data. In addition, engagement with journaling should be monitored throughout the study, and perhaps research goals and prompts re-stated to help participants refocus their effort as necessary.

\paragraph{Managing data} Journaling can generate large volumes of data from multiple participants, which must be managed carefully, and raises issues of confidentiality, privacy and more generally data protection. As a result it is essential that the researcher establishes a systematic approach to storing and backing up data, whether physical or digital. 


\subsection{Other things to think about}

\paragraph{Subjectivity and bias} Participants are in control of their diary entries, which, as a result are influenced by their emotions, beliefs, preconceptions and cognitive limitations. These, in turn, lead to a number of well recognised biases such as confirmation bias -- focusing on evidence in support of prior beliefs, memory and recall biases -- difficulties in remembering or reporting accurately past events, or social desirability bias -- only making entries deemed socially acceptable or desirable. Awareness of such biases and the use of triangulation may help mitigate resulting weaknesses.

\paragraph{Limited generalisability} Diary entries are personal, subjective and usually specific to a particular context or setting. As a results, there may be limited scope for generalising findings based on journaling. If generalisation is an important goal of your research, then you should consider different data generation methods, like questionnaires involving random sampling.

\subsection{Further reading}

\newcommand{\ed}[0]{Ed}

\ResGenExtras{journalling}{[\ed]{kadarisman2017classroom}{burns2009action}{james2005journaling}[p55]{peoples2020write}[]{feinblum2016journaling}[]{hayman2012journaling}{mcgrath202115}{taylor2006research}[\ed]{ovens2020weaving}{giguere2012self-reflective}{bacon2014journaling}}

%\endinput

\section{Fieldwork}

\citeauthor{wolcott2005art} offers salutary advice: 
%
\blockquote{There may be discomfort and hardship aplenty connected with the experience, ranging from the distractions of diarrhoea or lost luggage to the despair of personal failure or lost hope, but the extent of one's suffering and sacrifice are not factored into judgments about the worth of the fieldwork as fieldwork.}

Fieldwork is a data generation method which requires the researcher to collect data directly in a natural setting\footnote{The `field', hence the name.}. The goal is to gain firsthand knowledge of the phenomena under study, and the method is widely applied across disciplines, including anthropology, sociology, archaeology, geography or environmental science. 

\ResGenTechnique{fieldwork}


Fieldwork encompasses all kinds of data collection performed directly by the researcher in that setting, be that observations and measurements, collection of samples and specimens, detailed descriptions of direct experience, or other. In sociological studies, fieldwork requires personal involvement of the researcher with the social activities under study, so that participant observations are commonly used.

Through fieldwork the researcher can generate rich, contextualised data to provide deep insights into the phenomena under study. It is particularly suited to situations in which such data cannot be obtained in any other way, and may also lead to unexpected discoveries. It is also flexible in that the researcher can pick data collection techniques to match the specific context and situation.

Fieldwork is not confined to exotic, distant locations\footnote{Although fieldwork may have this characteristic for some lucky researchers.}! Instead, it can be used in all natural settings, including, say, the researcher's own university or workplace.



\subsection{Operational considerations}

\paragraph{Logistics, equipment and budget} Depending on where the field is located, fieldwork may require some detailed planning addressing travel arrangements and accommodation, as well as access to the research site. If in a foreign country, all sort of factors must be considered, including the local transport networks, administrative processes you may need to go through, the climate, etc. You may also need specialised equipment on site, say field equipment and tools for data collection, alongside your personal protection. This can all be quite expensive, so that careful budgeting and securing the required funding in advance is essential.

\paragraph{Permissions and ethical issues} If access to the field of interest is restricted, then you will need to gain appropriate permissions to proceed from the relevant authorities. This covers anything from obtaining permits and licences to access, say, an archeological site, to permission from your employer to perform participant observations in your workplace. The time and effort to obtain such permission must be considered upfront, and all ethical and legal implications factored in. In addition, the study must be conducted in full respect of local culture and norms.

\paragraph{Health and Safety} In working in the field, you, and anybody else participating in the research, may be exposed to all sort of hazards, so that assessing and mitigating health and safety risk is paramount. This may involve the introduction of safety protocols, of appropriate training, and appropriate contingencies in the case of an emergency.

\paragraph{Managing data} Fieldwork can generate large volumes of data, and may also include precious samples and specimens. All that is collected must be managed carefully, so that alongside issues of confidentiality, privacy and more generally data protection, you may also have to worry about the physical security of those samples and specimens. For this, you will need a systematic approach to storing, protecting and backing up your data, whether physical or digital. 

\subsection{Other things to think about}

\paragraph{Quality of results} The quality of results obtained from fieldwork depends on the data generated in the field, which, in turn, depends upon the skills of the field worker in relation to the specific techniques applied. For instance, using standardised measuring tools will increase the reliability and accuracy of measurements; a reflexive approach will help mitigate against the researcher's personal bias, including confirmation bias; triangulation may mitigate observer and social desirability bias in participant observations, etc. Whichever techniques you choose to apply in your fieldwork, you should ensure you are aware of their potential weaknesses and adopt  appropriate strategies to mitigate their effect on the outcomes of your research.

\paragraph{Logistic challenges} The logistical challenges to organise fieldwork may well be beyond what can be addressed in the limited time of a Masters project, unless you are able to contribute to a wider research effort, perhaps led by your supervisor, where all logistical issues have already been addressed.

\paragraph{Time and cost} Fieldwork can be time consuming both for data collection and analysis, and expensive if travel is required. If time or cost are an issue in your project, then you should consider more time efficient or cheaper alternatives.

\subsection{Further reading}


enwiki:1211911661\todo{is this good to include? Check!}

According to \textcite{wolcott2005art}\footnote{\citeauthor{wolcott2005art}'s book is both detailed and entertaining. Reading it gives on a feeling that spending time in fieldwork with \enquote{Harry} would have been an education in itself. The book includes the importance of laundry to fieldwork, for instance, with experiences of fieldwork in a Canadian Indian reserve to illustrate.}, 

\ResGenExtras{field work}{{wolcott2005art}{randall2007fieldwork}}

\section{Documents}

Existing documents can be used as data sources in order to develop new insights or answer research questions. Research which takes this approach is called document-based research\footnote{Or documentary research.}

\ResGenTechnique{documents}

As a researcher, documents – in the form of academic articles – will already occupy a large proportion of your time/brain/computer. Your collection of academic papers could currently be as many as 50 or more. You will, therefore, already have good experience of interacting with documents and those interactions may well have already helped you gain valuable insights for your project. 

Other documents can also be used as data sources in document-based research. The term `document' is used here in a broad sense to refer to all text-based documents, but also visual materials -- such paintings, maps or photographs, video and audio recordings, and any digitally stored information. 

Researchers engage in document-based research by systematically examining and interpreting these  documents to extract meaningful information. The documents may be of interest because of their content, or their relation to other documents, or could be studied to discover what they may reveal about their authors, or the historical or cultural context in which they were created. Therefore, a researcher's may have a direct interest in the factual content of a document, or be interested in what that content may indirectly say about some other phenomena of interest. An example may help clarify the difference between these two modes. This is a copy of a passage from \textcite{fynes1873the-miners}:
%
\blockquote{Miner :– I believe you have something like 150 collieries to inspect?

Mr.~Dunn :– Yes.

Miner :– Twenty-eight in Cumberland?

Mr.~Dunn :– Yes.

Miner :– Do you think you are able to inspect all these? 

Mr.~Dunn :– Well, the Government thinks I am able, you know.

Another Miner :– Were you satisfied with the one shaft at this colliery, if so there is an end to the matter; if not, what steps did you take to remedy the defect? Did you apply to the Secretary of State, showing him that it was defective?

Mr.~Dunn :– At this very moment there are three of the largest collieries in Northumberland – Seaton Delaval, North Seaton, and Newsham – managed by the most talented men in Northumberland, all with single shafts. Now, what would you have me to do? Do you think it is my duty to call in question the management of these pits?

Miner :– Am I to understand this is an answer to my question?

Mr.~Dunn :– Well, I am not so well satisfied as if they had two, but I have not the power to alter it.}

Here, a direct reading could be to identify collieries in which a single shaft existed at that time. An indirect reading could be to explore social relationships within a mining community in 18th century England.

Document-based research provides the researcher with evidence of historical events or social phenomena, including nuanced details and perspectives that may not be available through other means. In particular, documents allow the researcher to access data pertaining to different time periods, locations and cultural contexts. It is a flexible method that can be integrated in several research strategies. 

\subsection{Procedural considerations}

\paragraph{Accessing documents} You need to ensure you have access to the documents you need for your research. While documents are increasingly digitised and easily accessible online, it is also the case that access for many may be restricted by either policies or physical restrictions, say you wish to study restricted confidential documents in an organisation, or access rare or ancient manuscripts kept in a museum. Ensuring you have the right access at the right time in your project is essential, but can be time consuming, particularly if there are bureaucratic processes you need to go through. Related to access are issues of translation if the documents are in a language you are not familiar with, or transcription, if you sources are audio or video recordings. As well as being time consuming, these processes may introduce errors which may be difficult to spot. Lastly, it is essential you ensure that your documents are authentic: only using trusted sources is a way to do so.

\paragraph{Selection criteria} You must develop clear and explicit selection criteria to decide which documents to include in your study, based on your research problem or question, and aim and objectives. Such criteria should help you collect an appropriate and representative selection of documents for your research, guiding you in what to include and what to leave you. The criteria should ensure that your data sources are diverse and no selection bias creeps in, which may lead to certain positions, perspectives, or types of documents to be either overrepresented or underrepresented.

\paragraph{Data management} Alongside generic issues of data storage, protection and privacy, you also need to ensure that your source documents remain easily accessible and that their integrity is maintained: this is both to allow you to revisit those documents repeatedly during your study, and  to allow other researchers to check your sources to verify and validate your findings. Whenever possible, you should digitise your source documents to enhance their accessibility and preservation.

%LR -- the rest is commented out as it is about analysis, which is covered more generally in under analysis methods

%Analytical Framework: Developing an appropriate analytical framework is essential for guiding the analysis of documents. Researchers may use thematic coding, content analysis, discourse analysis, or other methods to identify patterns, themes, and relationships within the documents and generate meaningful insights.
%
%In more detail, indirect and direct reading use the following techniques to classify and conceptualise documents for qualitative research:
%\begin{itemize}
%\item Studying the form, content, and function of documents
%\item Analysing the ways in which documents justify decisions, display hierarchies, and exercise agency
%\item Distinguishing between primary sources (documents providing raw data) and secondary sources (documents providing information about primary sources)
%\end{itemize}
%

%As we have already mentioned, direct interaction with documents is already something with which you are\footnote{Or, should be!} familiar. However, according to \textcite[p.~370]{coffey2014analysing}\footnote{Freely available from \citeurl{coffey2014analysing}.}, a good place to start in analysing documents is with the realisation that documents are \enquote{socially defined, produced, and consumed} so that, alongside the content, the processes by which a document is produced and is intended to be consumed, i.e., by which it becomes an \enquote{accomplishment} for some individual or organisation, often contain useful data.
%
%In this case, there are many approaches possible from the simplest – counting instances, for instance, of words, phrases, or other elements\footnote{\textcite{mckenzie1959shakespearian}, for instance, counts commas – as well as other punctuation – in Shakespear's \emph{first Folio} to help identify which compositors were responsible for which parts of it.} – and indexing and coding document elements to identify thematic content and identify patterns, ala \textcite{schreier2014qualitative}. 
%
%\citeauthor{schreier2014qualitative}'s approach, a type of the more formal \emph{qualitative content analysis}, involves the selection of material from a wide range of source with adequate coverage for the topic of interest. As such it can result ing large amounts of material to analyse and so an element of formal in the process is mandated. An important step in this is the building of a \emph{coding frame}, i.e., a structure consisting of \emph{main category} and two \emph{sub-categories}~\parencite{schreier2014qualitative}:
%%
%\begin{itemize}
%\item a main category\footnote{Coding frames with more than 40 main categories are known to be difficult for one person to handle at one time.} being those aspects of the material that interest the researcher, 
%\item a subcategory being what is said in the material with respect to a main categories.
%\end{itemize}

%\paragraph{Coding for keeps} once you're convinced that your coding frame is stable, you then apply it to \emph{all} documents. This will involve:
%%
%\begin{itemize}
%\item  paying attention to how documents are constructed as distinctive artefacts, their structure, vocabulary, level of formality, etc. \parencite[p.~5]{coffey2014analysing}
%\item analysing their form and content, considering how they were produced and how they were – and how they were intended to be – consumed
%\item considering the relationships \emph{between} documents, highlighting dimensions of similarity, comparison, contrast, and difference by tracing how texts refer to other texts, sharing conventional formats, and constructing a uniform style\footnote{This scaled \emph{Intertextuality} in the literature~\parencite[p.~8]{coffey2014analysing}; it's akin to how you went about analysing the academic literature as part of your literature survey.}
%\item exploring the ways in which they function and are used in everyday life and social context
%\item examine their formal properties, including their linguistic registers, and rhetorical features.
%\end{itemize}

%\paragraph{Presenting your findings} can be as simple as delivering the statistics that you have collected as the basis for further analysis. Alternatively, a completed coding frame  with an accompanying narrative and example quotes as needed could be the output. Like other data, your coding frame can also be the starting point of further data generation and analysis, \textcquote{schreier2014qualitative}{examining the results [...] for patterns and co-occurrences of selected categories.}

\subsection{Other things to think about}

\paragraph{Bias in documents} Documents are created by people, who necessarily inject their own personal bias into their content\footnote{So called `creator' bias.}, which in turn is the result of their historical, cultural and social contexts\footnote{Another bias, called `contextual' bias.}. In addition, particularly in the case of ancient manuscripts, the documents that have survived may only provide a partial historical account\footnote{You'll have guessed there is a name for this too, which is `survivorship' bias.}. Being aware of all these biases is essential to the interpretation of documents content and how they may skew or limit the research results.  

\paragraph{Interpretation challenges} Documents are unlikely to provide a complete picture of phenomena under study, partially due to their inherent biases, but also because they may be incomplete or lack crucial details or contextual information may not be available to the researcher. Also certain phenomena may be more documented than others, so that the availability and quality of documents can vary widely across topics, history or geography. All these factors affect your ability as a researcher to interpret their content and draw robust conclusions.

\paragraph{Time and effort} Document-based research may require large volumes of materials to be selected, collected and analysed, so that it can be very time-consuming. If time is an issue in your project, then alternative data generation methods should be considered.

\subsection{Further reading}

\ResGenExtras{documents}{{coffey2014analysing}{schreier2014qualitative}}

\chapter{Modelling methods}

So far we have discussed methods which focus on generating data from either direct observations or experience (whether the researcher's or other research participants'), or from secondary sources. Once gathered, such data are organised and then analysed by applying data analysis methods, which we will consider in the next section.

Somewhat in between data generation and analysis are modelling methods, whose aim is to build models of natural, social or artificial phenomena, that can then be used for analysis, prediction or decision making, including informing the design and engineering of new artefacts. Such models need data to inform their development and, in turn, generate new data for analysis. Modelling methods support a variety of research strategies including simulation and design science research, but also case studies in which models of socio-technical systems may be useful for investigation.

At its essence, a \textit{model} is a representation of something, be that a system, a structure, a process or a behaviour. Possibly the most important thing to remember about modelling is expressed by the following oft-cited aphorism\footnote{Box, George E. P. (1976), ``Science and statistics'' (PDF), Journal of the American Statistical Association, 71 (356): 791--799.}:

\begin{quotation}
	\textit{All models are wrong, some are useful} (Box, 1976)
\end{quotation}

which makes clear that a model should not be regarded as a faithful replication of some  reality, but as a tool to investigate some aspects of that reality.

At the core of modelling is a \emph{process of abstraction} which starts from an understanding of what is to be modelled and ends with the definition of the desired model. The nature of both determines the kind of thinking required in the abstraction process. In this section, we focus on computational, mathematical, statistical and system thinking. 

\section{Computational thinking}

Computational thinking is needed when the end point is a computational artefact, that is something that a digital computer can execute\footnote{Computational thinking has a much broader scope than what is reported here. For instance, it underpins learning and curriculum in Computing-related disciplines, as well as professional skills in related industries.}. 

\ResGenTechnique{computation thinking}

Computational thinking is a problem solving approach in which problems are explored with a view to identify and implement computational solutions in the form of computer programmes and systems. In addition to writing code that a computer can execute, computational thinking involves a wide range of cognitive processes such as being able to think at different levels of abstractions, to decompose problems into sub-problems, to identify useful patterns and structures in data, to conceptualise logical steps the computer should take alongside how people may interact with those programmes and systems.  

Computational artefacts are becoming more and more prominent in academic research, which both makes use of existing ones and develop new, bespoke ones to advance knowledge. 



%The techniques generally associated with computational thinking are:
%%
%\begin{itemize}
%\item Decomposition: breaking a problem into parts that are easier to solve;
%\item Pattern recognition \& Generalisation: seeking significance from repeated structures within data
%\item Abstraction: building higher level representations of things
%\item Algorithms: associating behaviours with computational structures
%\item Evaluation: called testing for software, but also has wider applicability when an algorithm is socialised, i.e., used within its final social context.
%\end{itemize}


%Clearly, part of computation thinking is programming a computer to achieve a goal. 
%
%However, \citeauthor{wing2006computational}\footnote{\citeauthor{wing2006computational} is American, and so uses American spelling – -i\textit{z}i-, art\textit{i}fact, etc.}, in her \citeyear{wing2006computational} article that popularised Computational Thinking~\cite{wing2006computational} as a candidate curriculum entry, places programming in the broader context of computational thinking. If you are aiming at computational thinking as a way of focussing on your programming skills, it may be that you have misjudged this wider context. 
%
%\citeauthor{wing2006computational} says:
%
%\noindent\emph{Computational thinking} [...] has the following characteristics\footnote{\citeauthor{wing2006computational} includes other characteristics, of relevance to curricula but not so much to research.}:
%
%\begin{description}
%\item [conceptualising] Computer science is not [just] computer programming. Thinking like a computer scientist means more than being able to program a computer. It requires thinking at multiple levels of abstraction; 
%%
%%\item[Fundamental, not rote skill.] A fundamental skill is something every human being must know to function in modern society. Rote means a mechanical routine. Ironically, not until computer science solves the AI Grand Challenge of making computers think like humans will thinking be rote; 
%%
%\item [A way that humans, not computers, think.] Computational thinking is a way humans solve problems; it is not trying to get humans to think like computers. %Computers are dull and boring; humans are clever and imaginative. We humans make computers exciting. Equipped with computing devices, we use our cleverness to tackle problems we would not dare take on before the age of computing and build systems with functionality limited only by our imaginations; 
%%
%\item [Complements and combines mathematical and engineering thinking.] Computer science inherently draws on mathematical thinking, given that, like all sciences, its formal foundations rest on mathematics. Computer science inherently draws on engineering thinking, given that we build systems that interact with the real world.% The constraints of the underlying computing device force computer scientists to think computationally, not just mathematically. Being free to build virtual worlds enables us to engineer systems beyond the physical world; 
%%
%\item [Ideas, not artifacts.] It's not just the software and hardware artifacts we produce that will be physically present everywhere and touch our lives all the time, it will be the computational concepts we use to approach and solve problems, manage our daily lives, and communicate and interact with other people.%; and
%%
%%\item [For everyone, everywhere.] Computational thinking will be a reality when it is so integral to human endeavors it disappears as an explicit philosophy.
%\end{description}
%
%Recognising the social context of computational thinking is, thus, critical to research in the area.

\subsection{Procedural considerations}

Given the explosive growth in the use of computers over the past half century, you may not be surprised to hear that there are thousands of useful\footnote{As well as some that are less than useful!} tools to support computational thinking. They vary in many of their characteristics, so that you will need to make some judicious choices for your project. In particular you will need to consider:

\paragraph{Programming language and paradigm} This concerns the language you will use to express your code, and its underlying philosophy\footnote{You may have heard of Phyton, C or Java. These are just few of the many choices of programming language available! Each language embodies some ontological assumptions as to the building blocks of code -- yes, philosophy comes into play into coding too!}.

\paragraph{Computational mode} This refers to the way computations take place in the implemented artefact, one of sequential, concurrent, distributed or agent-based. The latter is particularly suited to the simulation of complex systems made of many interacting, independent agents. While all programming languages allow you to develop sequential computations, specialised languages\footnote{You can look, for instance, at Petri Nets or NetLogo to get some ideas.} exist for the other modes. 

\paragraph{Delivery platform} This refers to where your computational artefact will be made available for use, be that the web, a mobile device, or some other bespoke hardware.

\paragraph{Integrated Development Environment (IDE)} This the combination of tools to help you develop and keep track of your code, including how it changes over time, as well as to perform tests to check its intended behaviour and to correct errors and mistakes. 	

\paragraph{Stakeholders and participants} These are all the people you may have to involve to tease out requirements,\footnote{Which need will your artefact meet? Which characteristics should it have?}, validate your artefact or generate data by interacting with it.

\paragraph{Development process} This is the process\footnote{Several schools of thought exist as to what constitute a good process to develop computational artefacts. You can look up Agile and Plan-driven development processes to get some ideas.} you will follow to determine what your code should do, and to design, implement, test and release it for use.

%The main idea behind computational thinking is to link a wished-for behaviour to a computational structure. Here, we're thinking of the wished for behaviours of a client in context being translated to an algorithm, data model, or other computational element. 
%
%The ways in which the wished-for behaviour of a client in context are understood is through the discipline of requirements analysis. Although naive requirements analysis is possible for simple projects – asking a client what functional behaviours they need – it is more often driven by the explicit or implicit management or developmental risk, the risks being those of 
%

\subsection{Other things to think about}

\paragraph{Foundational knowledge} If you don't have any experience of computational thinking or writing code, then you can learn, but the learning curve is going to be very steep. Unless you have direct access to experts to guide you, it is unlikely you will be able to achieve the proficiency you will need within the timeline of a Masters project. 

%\footnote{This video will give you some idea of what will be required: \url{https://www.youtube.com/watch?v=fLMZAHyrpyo}. Stephen Wolfram is a particularly interesting, if restless, speaker and a leader in this area.}\todo{But this isn't a great video, nor is any other that I've looked at, as they're created by computer scientists... They're also heavily advertise laden.}. 

\paragraph{Model validity} You need to worry about two key aspects of validity when developing computational models. One is internal, and concerns the issue of whether you have made mistakes in your code: appropriate code review and testing techniques can help you take care of this. The other is external, and concerns the relation between the model itself and the reality it means to model. In order to establish this, you may need to consider several factors including:
		\begin{itemize}
			\item how well it fits the context in which it is eventually installed	
			\item how well it addresses the problem(s) it is meant to solve, and
			\item how well it meets stakeholder's expectations, including any professional quality standards
		\end{itemize}

\paragraph{Timing issues} Developing computational model can be very time consuming, particularly when you need to interact with many stakeholders as part of the development, which may then require you to iterate between coding and validation several times. If you are not confident you can accommodate such a development effort within your Masters project, then you should consider other methods or reduce the scope of your model. 

\subsection{Further reading}

\ResGenExtras{computation thinking}{{angevine2017computational}{figueiredo2017improve}{lyon2020computational}}

\section{Mathematical thinking}

Mathematical thinking is problem solving with Mathematics. It has had many centuries more than computational thinking to develop and the tools that exist as part of it are very stable. They are also much better explored due to the efforts of many great mathematicians. However, they do require a high level of skills and sophistication in their application to achieve their full potential. 

\ResGenTechnique{mathematical thinking}

Although mathematical techniques can apply to real-world problems, they tend to create \emph{closed form} solutions, that is solutions which can be calculated exactly from mathematical expressions. For instance, systems of differential equations are widely used in Finance to model fluctuations on stock or investment markets. As long as a real-world problem can be captured in this way, then a mathematical model is feasible. However, many real-world problems do not admit such characterisations, so that there are limitations as to what can be treated mathematically. 

It should also be noted that there is a strong connection between mathematical and computational thinking in that lots of mathematical models are now implemented as computational algorithms executed by computers. These, however, require some \emph{numerical approximations} as computers cannot calculate exact values.

Similarly to computational thinking, mathematical thinking involves various cognitive processes:

\begin{description}
\item [Specialising] exploring a problem through examples. Each example provides the opportunity for manipulating elements that are concrete, whether they are physical manifestations or ideas.
\item [Conjecturing] when enough such examples have been examined, you can conjecture about the relationships that connect them. Through conjecturing, underlying patterns are explored, expressed, and then substantiated.
\item [Generalising] if you are lucky enough to have found a pattern, then you might try to generalise it to creating order and meaning out of a – potentially, overwhelming – amount of data.
\item [Convincing] a generalisation must be tested until it is convincing to the reader – this is the basis of the knowledge contribution from mathematical thinking.
\end{description}



%Mathematics has limits of applicability, some of which are extremely subtle, even in relatively simple situations: complete closed form solutions in radicals do not exist for problems as simple as finding the roots to polynomial equations of order 5\footnote{So called \emph{quintic equations}~\parencite{enwiki:1209364767}. A radical is a mathematical expression involving only the coefficients of the equation, and the basic arithmetic operations (addition, subtraction, multiplication, division, and taking the n\fmtord{th}-root).} or above; the general three body problem, for instance, being resistant to differential equation analysis; and others. 

%Alternatively, so called \emph{numerical approximations} can be made to most problems, but these are often related to computational solutions and so might be better approached through computational thinking.
%
%Another alternative that again takes us back to computational thinking, is the use of agent based simulations in which concurrently acting independent agents are used.\todo{More here.}
%
%Differential equations; matrices; algebra; numbers theory; sets; functions; relations; logics\footnote{\emph{Logics} is plural as there are many, depending on which area of mathematics you are using.}; topology; geometry; calculus; algebra; analysis; \todo{More here?}
%
%According to \textcite[, adapted]{burton1984mathematical}, there are four cognitive processes that are central to mathematical thinking: 

\subsection{Operational considerations}

\paragraph{Mathematical tools} This concerns the choice of the kind of mathematics to apply, including notation, and symbolic and diagrammatic representations appropriate for the problem you are trying to address. 

\paragraph{Computational tools} Should you wish to use a computer to run your mathematical models, then you will also need to make many of the choices related to computational thinking\footnote{See Section??.}. Note that many modern programming languages and environments include a wide range of mathematical libraries which you can use directly in your code, so that you don't have to start your code from scratch, reducing substantially the time and effort required. Such libraries are also likely to have been tested extensively, hence their code should be error-free and highly reliable.

\paragraph{Relevant examples} Although you will need to be creative in applying mathematics to your own research problem, there may be relevant examples in the literature which can provide a good starting point. Working from simple examples to more complex ones may help you establish an appropriate mathematical approach.


\subsection{Other things to think about}
%\endinput

\paragraph{Foundational knowledge} Mathematical thinking is arrived at through creative thinking and deep study of mathematical tools and techniques. The sophistication of mathematics often means that, either:
%
\begin{itemize}
\item a particular area of research has already been taken past the abilities of a masters-research-level mathematician;
\item it is not amenable to (current) mathematical tools and techniques, and further creative\footnote{And, most likely, deep and advanced, out of the box, out of this world, and further.} mathematical thinking will be necessary to progress.
\end{itemize}
%
Although neither of these characteristics are insuperable, they make timely contributions to knowledge through the application of mathematical approaches difficult\footnote{What is often missing from the mathematical literature – or what isn't always visible to the new entrant – is the often vast timescales over which mathematical progress is made. Bertrand Russell and Alfred Whitehead spent over two decades of their professional lives in the creation of the three volume \emph{Principia Mathematica}. A fourth volume – on geometry – was begun but never completed. In another example, the proof of Fermat's Last Theorem took 358 years to complete.}. It's worth moderating your expectations of what can be achieved in mathematical research at masters level – discussion with your supervisor of what their expectations are would be very worthwhile.

%\begin{question}[subtitle={Activity: Understanding your supervisor's mathematical thinking expectations}] 
%	Schedule some time with your supervisor to discuss what they hope will be achieved through your research project.
%\end{question}


%Mathematics is a very tight community with very high publication standards. The language of mathematics is dense\footnote{A mathematical statement indicative of this complexity is: \enquote{Let q be $x^{5}-x-1$. Let $G$ be its Galois group, which acts faithfully on the set of complex roots of $q$. Numbering the roots lets one identify $G$ with a subgroup of the symmetric group $\mathcal{S}_{5}$. Since $q{\bmod {2}}$ factors as $(x^{2}+x+1)(x^{3}+x^{2}+1)$ in $\mathbb{F}_{2}[x]$...}.}.
%
%Because of this, many mathematical research projects at masters level are designed to provide a way into the mathematical literature. A supervisor will set a mathematical task that may already have been solved. The contribution a research student might make, then, is not a contribution to knowledge in the formal sense of extending mathematics, but the widening of the mathematical community to include another researcher whose skills have expanded to be able to make a novel restatement of a problem, for instance, and research further. 
%
%The study of the development of mathematical thinking, for instance, in schoolchildren is a very fruitful area with much still to be contributed.\todo{More here}
%

\paragraph{Limitations of mathematical abstraction} Mathematics abstracts from real-world complexity: in modelling traffic to improve flow through a complex junction, for instance, one would not necessarily consider the economy of individual cars, or the noise pollution created by a solution. This can reduce a real-world problem to a complexity that is approachable, but may also lead to non-solutions when applied back in the real world, for instance, leading to complaints from local home owners that noise pollution has risen through a solution. Therefore, you need to check you simplifying assumptions carefully against the real-world situation to avoid reaching invalid conclusions.

\subsection{Further reading}

\ResGenExtras{mathematical thinking}{{stacey1982thinking}}


\section{Statistical thinking}

Statistical thinking is problem solving with Statistics. It is used to identify patterns, trends and relationships in data from which inferences are possible through probabilistic reasoning, which acknowledges the data inherent variability and uncertainty. 

\ResGenTechnique{statistical thinking}

Statistical inferences are particularly valuable for prediction and forecasting -- for instance, to predict the spread of a virus in a population or how the average house price in a geographical area may change over a certain period of time, or to test hypotheses\footnote{We will introduce statistical tests in Section~\ref{sect:inferentialStatistics}}, for instance whether a medical treatment is effective. Statistical thinking is essential in quantitative analysis, which will cover in Section~\ref{sect:statisticalAnalysis}: in this section we only provide a brief introduction with a focus on modelling.

%
%Statistical thinking\todo{Source: \textcite{chance2024statistical}.} involves designing a study to collect data, analyse patterns in the data, and draw conclusions that go beyond the observed data. Sampling is key to being able to generalise results, while random assignment is key for cause-and-effect conclusions. Probability models help assess random variation and estimate margin of error.



\subsection{Procedural considerations}

\paragraph{Sampling} Statistical modelling requires relevant data, so that you have to consider how you will obtain such data. Sampling is a way to do so\footnote{You should refer back to Section~\ref{sect:DG:sampling}}: in such case, you need to worry about both sample size and the extent it is representative of the population of interest.

\paragraph{Data quality} Quality data are data with no missing, inconsistent or erroneous entries. Typically, you will need to pre-process your data to ensure this is the case before applying any statistical technique. 

\paragraph{Choice of techniques} You will need to decide which statistical techniques to apply in relation to the research problem you are trying to address. Like Mathematics, Statistics too includes a vast repertoire of techniques applicable to different problems. If you do not possess sufficient expertise to be able to choose by yourself, then you will need to take expert advice, as applying inappropriate techniques will lead to invalid or misleading results.

\paragraph{Statistical software} The use of computational tools is the norm to support statistical thinking and many bespoke statistical software applications are available. In addition, many programming languages and environments now come equipped with full libraries of statistical functions ready for use\footnote{R and Python are two of them.}. Such applications and environments allow you to perform most statistical modelling and testing alongside data manipulation and visualisation with graphs and charts.

\subsection{Other things to think about}

\paragraph{Foundational knowledge} Statistical techniques can be complex and require specialised knowledge and skills to apply them effectively, particularly for advanced modelling, but also to provide meaningful interpretation of outcomes. As for mathematical thinking, unless you have sufficient foundational knowledge, it is unlikely you will be able to develop knowledge and skills beyond the basics within the remit of a Masters project.

\paragraph{Data bias} Even when your data are of good quality, they can still be biased in that they may over- or under-represent certain characteristics of the population of interest, leading to invalid or unreliable generalisations. For instance, if all participants in a clinical trial for a new medicinal drug are male, then the effectiveness or otherwise of the drug for female patients cannot be inferred from the trial, so that any generalisation to the wider population may be unsound.

\paragraph{Confounding factors} Unfortunately, things can still go wrong even when you have good quality, unbiased data to start with. This may be due to \emph{confounding factors} you may not have considered in your study. For instance, say you are interested in the possible relationship between physical activity and heart health. If you only focus on (some measures for) those two variables, you are likely to miss possible effects of, say, age and gender on heart health in addition to physical activity, and may, once again, infer the wrong conclusions. 

\paragraph{Model assumptions} Statistical methods are usually based on specific assumptions made of data characteristics. For instance, many statistical tests assume that the data are normally distributed\footnote{We will cover these topics in Section~\ref{sect:inferentialStatistics}}. It is therefore essential for you to check that all required assumptions hold, otherwise your model, and any conclusions you derive from it, may be invalid.

\paragraph{Ethical considerations} As statistical thinking relies on data, then ethical and legal issues arise in relation to how the data are obtained and used in your research, particularly around privacy and data protection. In addition, ethical issues arise in relation to  social implications of applying statistical thinking in decision-making, particularly when decisions are increasingly taken by algorithms. This can lead to inequality and discrimination, as demonstrated by some shocking cases which have been reported widely, such as the COMPAS system, discriminating against black offenders, or the Amazon's recruitment algorithm, discriminating against women. 

\subsection{Further reading}

\ResGenExtras{statistical thinking}{{chance2024statistical}}

\section{System thinking}

Systems thinking is yet another problem solving approach which focuses on systems and their dynamics. By \emph{system} we mean a set of elements coming together in a complex whole and whose behaviour stems from the interaction of those elements. Any kind of system is in scope, whether natural, social or artificial, with system thinking focusing on understanding how the different elements influence each other and the system behaviour emerges from their interaction. 

\ResGenTechnique{system thinking}

System thinking takes a holistic approach to understanding a system, encouraging different stakeholders' perspectives and a participative approach to develop a shared understanding. This also means that the enquiry process is iterative, with insights being revisited, reviewed and refined as more knowledge is acquired through ongoing analysis and interaction with stakeholders.

Like mathematical and statistical thinking, system thinking may be used in combination with computational thinking, for instance, to develop a better understanding of a system of interest before creating a computational simulation of it, or as an aid to prototyping novel computational artefacts.

System thinking also relies on system models based on diagrammatic notations, of which there is a great variety. Among the most common are\footnote{This is by no means a complete list!}:

\begin{itemize}
	\item \textit{systems maps}, which allow you to sketch the structure of a system by identifying key components and sub-systems;
	\item \textit{influence diagrams}, which extend system maps to show how those elements influence each other;
	\item \textit{causal loop diagrams}, which are used to capture cause-and-effect relations, and particularly feedback loops in the system dynamics which affect behaviour over time;
	\item \textit{stock and flow diagrams}, which augment causal loop diagrams with quantitative information that can be exploited in computational simulations;
	\item \textit{UML (Unified Modeling Language) diagrams}, where UML is a standardised engineering modelling language specifically defined to capture and analyse various aspects of software systems\footnote{Although it is also used for other kind if design and engineering, beyond software.}, either in terms of their structure or behaviour.
\end{itemize}

\subsection{Procedural considerations}

\paragraph{Scope and boundaries} Before you start your investigation you need to define clearly the scope of your system of interest, its boundaries and the purpose of your analysis, to inform your data gathering and interaction with stakeholders. Your analysis should encompass different system dimensions, say social, cultural, economical or environmental. 

\paragraph{Stakeholders} You need to decide who you will involve in your research, focusing on stakeholders with an interest and understanding of the system, and ensuring that a plurality of views and perspectives are represented. If you aim for some form of intervention on an existing system, then you must also ensure you involve stakeholders who will champion or support it. In all cases, you should encourage collaboration and communication among stakeholders, including exchanging knowledge and ideas to foster shared understanding.

\paragraph{Data gathering} To gather your data about the system you can apply any relevant method from Section~\ref{??}. It is likely you will need both qualitative and quantitative data as you are aiming for a comprehensive characterisation and analysis of your system from a plurality of perspectives.

\paragraph{Modelling} You need to decide which notations to use to model key aspects of the system relevant to your research. You should also consider whether a computational simulation would be appropriate, in which case, you should review the operational considerations related to computational thinking. For both, you will need to develop a certain level of expertise to be able to apply them effectively in your enquiry. This will require time, and ideally some expert guidance, which you must ensure are available within the constraints of your Masters project.

\subsection{Other things to think about}

\paragraph{Complexity} Analysing complex systems can be challenging, and taking a system thinking approach is time consuming and resource intensive due to the need for large amount of data to gather and protracted interactions with many stakeholders. You need to ensure access to both data and people for your system thinking enquiry to be meaningful.

\paragraph{Subjectivity and bias} As a system thinker, you establish the system boundaries, the perspectives to take, who to involve and how to gather and interpret your data. This leaves your research open to your own bias. Reflexive practices, alongside triangulation, say by cross-validating with independent data, are therefore necessary to support the validity of your findings.

\paragraph{Model validity} As for all modelling, your system characterisation will be based on simplifications and assumptions, which will need careful checking with respect to the system being modelled. To validate both assumptions and  resulting models you could apply triangulation, including asking independent experts to review them or compare model behaviour with real-world observations.  


\subsection{Further reading}

\ResGenExtras{system thinking}{{??}}


%\endinput
%\section{Statistical thinking}
%
%%\subsection{Statistical thinking tools}
%
%Like mathematics, statistical thinking is a sophisticated discipline with much to offer the researcher. Statistics provides many tools of general applicability across the research process and some form of statistical thinking will apply to most quantitative research and in some qualitative research projects. To this end, we provide a separate section below on statistical modelling. 
%
%\ResGenTechnique{statistical thinking}
%
%\subsection{Workflow}
%
%\subsection{Other things to think about}
%
%\ResGenExtras{statistical thinking}{}

%\section{Reflexivity}
%
%Reflexivity\todo{Sources: \textcites{dodgson2019reflexivity, may2014reflexivity,patnaik2013reflexivity,palaganas2017reflexivity, darawsheh2014reflexivity,macbeth2001reflexivity}.} involves the researcher describing the relationships between themselves and research participants, and is crucial for increasing the credibility of findings and deepening understanding. Researchers should be explicit about their biases and experiences as a means of demonstrating trustworthiness to readers. In addition, however, reflexivity also helps a researcher to recognise and take responsibility for their situatedness within the research, i.e., how they influence data collection and interpretation. The reflexive researcher should focus on self-knowledge, sensitivity, and understanding the role of the self for their knowledge contribution. 
%
%Introducing a **reflexive practice** into qualitative research allows researchers to examine the grounds of claims about the social world and explore the strengths and limitations of knowledge forms. This helps correct an instrumental approach to knowledge that seeks to control rather than understand the social world.
%
%\textcquote{dodgson2019reflexivity}{- **Qualitative research is contextual and occurs between two or more people in a specific time and place.**
%- **Researchers must describe the intersecting relationships between participants and themselves (reflexivity) to increase credibility and deepen understanding of the work.**
%- **Reflexivity is essential in qualitative research as the researcher's identity influences the findings.**
%- **Readers need to understand the researcher's positionality beyond their name and affiliations.**
%- **Researchers should address unconscious biases and continually evaluate their positionality.**
%- **Participator process enhances non-exploitive processes and minimizes power differentials.**
%- **Reflexivity involves self-examination and understanding one's situatedness within the research.**
%- **Researchers must be aware of power differentials inherent in the researcher/participant relationship.**
%- **Describing contextual relationships between participants and researchers increases credibility and understanding of the work.**
%- **Researchers need to focus on self-knowledge, sensitivity, and understanding the role of the self in creating knowledge.**
%- **Researchers' position as an insider or outsider is crucial in considering similarities and differences with participants.**
%
%Reflexivity in qualitative research involves the researcher being conscious of their own biases, positionality, and impact on the research process. It requires continual self-reflection and transparency in addressing these factors throughout the research endeavor.
%
%- Reflexivity is a process that permeates the whole research endeavor.
%- Researchers need to address reflexivity in substantive ways to inform the reader about their processes.
%- The issues surrounding researchers' reflexivity are many and complex.
%- Power differentials between participants and researchers pose challenges related to reflexivity.
%- Researchers must be explicit about reflexivity and continually address trustworthiness criteria.
%- Reflexivity involves a continual internal dialogue and critical self-evaluation of the researcher's positionality.}
%
%\textcquote{may2014reflexivity}{
%- Reflexivity in qualitative research allows for examining the grounds of claims about the social world and exploring the strengths and limitations of knowledge.
%- **Reflexivity involves investigating the relationship between the knower and the known through inquiry itself.**
%- Calls for reflexive social inquiry challenge the separation between subject and object.
%- **Reflexivity enables researchers to correct an instrumental approach to knowledge that aims to control rather than understand the social world.**
%- The document discusses different social scientific approaches to reflexivity and their implications for research practices.
%- **Reflexive spaces are explored through various forms of qualitative work conducted over the years.**
%
%Workflow: - Reflexivity involves turning back on oneself in order that processes of knowledge production become the subject of investigation.
%- It is a way of thinking or critical ethos that aids interpretation, translation, and representation.
%- Reflexivity is not a method but a continuous characteristic of good research practice.
%- It includes endogenous and referential reflexivity, which focus on the actions and understandings of researchers and the meeting of points of view in the production and reception of accounts.
%
%Issues: - Reflexivity involves turning back on oneself in order that processes of knowledge production become the subject of investigation.
%- Endogenous reflexivity and referential reflexivity are two interrelated dimensions of reflexive practice.
%- A reflexive approach to analysis requires navigating between scientism and relativism, and deconstruction and reconstruction.
%- Reflexivity is not a method, but a critical ethos to aid interpretation, translation, and representation.}
%
%\textcquote{patnaik2013reflexivity}{
%
%- The paper explores **reflexivity** in social sciences for meaning making and knowledge claims.
%- **Reflexivity** is important for establishing credibility and richness in research.
%- **Introspective reflexivity** involves understanding how the researcher's experiences influence the research.
%- **Reflexivity** helps in monitoring assumptions, ethical considerations, and research rigour.
%- **Maintaining a reflective journal** helps in capturing the researcher's attitudes and biases.
%- **Bracketing** is used to prevent the researcher's biases from influencing the research process.
%
%Workflow: - Reflexivity is essential in qualitative research to address the subjective nature of data interpretation and researcher bias.
%- It involves introspective reflexivity to understand how the researcher's experiences influence the research process.
%- Epistemological reflexivity examines the knowledge claims being made and the researcher's role in shaping them.
%- Achieving reflexivity requires addressing personal history, values, and biases that may impact the research.
%- Operationalizing reflexivity involves asking questions about the researcher's influence on the topic, research process, and participant interactions.
%
%Issues: - The influence of the researcher's values and attitudes on the choice of topic
%- The exploration of epistemological foundations of knowledge claims
%- The role of the researcher in the process of knowledge construction
%- The presentation of reflexivity in research writing}
%
%\textcquote{palaganas2017reflexivity}{
%The document discusses reflexivity in qualitative research, highlighting the personal changes and influences experienced by researchers during fieldwork. It emphasizes how researchers are shaped by the research process and how their involvement impacts the final study. The authors reflect on their positionality and personal backgrounds, acknowledging the importance of self-awareness in research.
%
%- The document discusses **reflexivity in qualitative research** and how it impacts researchers.
%- The researchers share their **journeys of learning** and how the research process shaped them.
%- The paper focuses on understanding social phenomena like **poverty, development, gender, migration, and ill health** in the Philippines.
%- Reflexivity helps researchers become aware of their contribution to the construction of meanings and lived experiences.
%- **Fieldwork** is described as intensely personal, influenced by researchers' positionality and personal backgrounds.
%
%Workflow: - Reflexivity in research involves reflecting on how the researcher's values, beliefs, and perceptions shape the research process.
%- It is important in feminist research to identify with the research participants and be aware of the power differentials that exist.
%- Reflexivity can take on various forms such as epistemological reflexivity, personal reflexivity, critical reflexivity, and feminist reflexivity.
%- Researchers need to consider how their own background and assumptions affect their research practice.
%- Practicing reflexivity is a significant component of qualitative research.
%
%Issues: - Reflexivity can disrupt the process of discovery
%- Researchers need to suspend the belief that a more personal story reveals a more authentic story
%- Sharing of ideas and experiences can become emotionally driven, leading to ethical issues
%- Researchers need to be aware of personal biases and how they shape the research process
%- Objectivity in research focuses on method rather than content
%- Researchers must maintain academic distance to avoid being influenced by emotions
%- Reflexivity challenges the assumption of studying social reality objectively
%- Researchers need to be critical of power differentials in research
%- Feminist reflexivity emphasizes reciprocity in research}
%
%\textcquote{darawsheh2014reflexivity}{AI: Qualitative research is contextual and occurs between two or more people in a specific time and place. **Reflexivity** in research, which involves the researcher describing the relationships between themselves and the participants, is crucial for increasing the credibility of findings and deepening understanding. Researchers need to be explicit about their positionality, biases, and experiences to ensure trustworthiness. **Reflexivity** helps researchers recognize and take responsibility for their situatedness within the research, influencing data collection and interpretation. It is important for researchers to focus on self-knowledge, sensitivity, and understanding the role of the self in creating knowledge. The balance between personal experiences and universal knowledge must be maintained.
%
%- **Qualitative research is contextual and occurs between two or more people in a specific time and place.**
%- **Researchers must describe the intersecting relationships between participants and themselves (reflexivity) to increase credibility and deepen understanding of the work.**
%- **Reflexivity is essential in qualitative research as the researcher's identity influences the findings.**
%- **Readers need to understand the researcher's positionality beyond their name and affiliations.**
%- **Researchers should address unconscious biases and continually evaluate their positionality.**
%- **Participator process enhances non-exploitive processes and minimizes power differentials.**
%- **Reflexivity involves self-examination and understanding one's situatedness within the research.**
%- **Researchers must be aware of power differentials inherent in the researcher/participant relationship.**
%- **Describing contextual relationships between participants and researchers increases credibility and understanding of the work.**
%- **Researchers need to focus on self-knowledge, sensitivity, and understanding the role of the self in creating knowledge.**
%- **Researchers' position as an insider or outsider is crucial in considering similarities and differences with participants.**
%
%Reflexivity in qualitative research involves the researcher being conscious of their own biases, positionality, and impact on the research process. It requires continual self-reflection and transparency in addressing these factors throughout the research endeavor.
%
%- Reflexivity is a process that permeates the whole research endeavor.
%- Researchers need to address reflexivity in substantive ways to inform the reader about their processes.
%- The issues surrounding researchers' reflexivity are many and complex.
%- Power differentials between participants and researchers pose challenges related to reflexivity.
%- Researchers must be explicit about reflexivity and continually address trustworthiness criteria.
%- Reflexivity involves a continual internal dialogue and critical self-evaluation of the researcher's positionality.
%}
%
%\textcquote{macbeth2001reflexivity}{**Summary:**
%The document discusses the concept of reflexivity in qualitative research, focusing on two main inflections: positional reflexivity and textual reflexivity. It also reintroduces Garfinkel's ethnomethodological "constitutive reflexivity" as an alternative perspective. The text explores the diversity of reflexivity in the literature and its role in deconstructing the intersections of author, other, text, and world. The document includes references to various authors and their works on reflexivity and qualitative research.
%
%- Reflexivity in qualitative research is a significant topic, with two main inflections: positional reflexivity and textual reflexivity.
%- **Positional reflexivity** involves examining the influence of place, biography, self, and others on the analysis.
%- **Textual reflexivity** focuses on disrupting the exercise of textual representation.
%- The article discusses the concept of **constitutive reflexivity** in social science, particularly Garfinkel's ethnomethodological approach.
%- **Reflexivity** is seen as a deconstructive exercise to understand the connections between author, text, and world.
%- The literature on reflexivity is diverse, with various perspectives and interpretations.
%- An example of constitutive reflexivity is analyzed through a videotaped sequence from a fifth-grade classroom.
%- The rush of interest in qualitative research has led to a broad consensus on the importance of reflexivity.
%- **Postmodern attachments** may influence the understanding of reflexivity, but it is suggested that there are commonalities with Enlightenment certainties.
%- **Garfinkel's work** in ethnomethodology is referenced as an alternative perspective on reflexivity.
%
%workflow: Reflexivity in qualitative research involves two main programs: positional reflexivity and textual reflexivity. Positional reflexivity focuses on examining how place, biography, self, and others shape the analytic exercise. Textual reflexivity, on the other hand, involves examining and disrupting the exercise of textual representation. Both programs aim to deconstruct and understand the intersections of author, other, text, and world in the research process.
%
%issues: Reflexivity in qualitative research raises issues related to positional reflexivity and textual reflexivity, which focus on the impact of place, biography, self, and other on the analytic exercise, as well as the disruption of the exercise of textual representation. The discussion also introduces the concept of constitutive reflexivity, which dissolves binaries and representational language games into practical achievements of diverse settings and practices.}
%
%\ResGenTechnique{reflexivity}
%
%\subsection{Reflexivity tools}
%
%\subsection{Workflow}
%
%\subsection{Other things to think about}
%
%\ResGenExtras{reflexivity}{}


%\subsection{Sampling: what, who (and how) to choose}\label{sect:DG:sampling}
%
%A core prelude to many of the data generating techniques introduced above is to choose the data source. You've already had experience of doing this when you conducted your literature search as part of Stage~\ref{stage:?}\footnote{You might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. \todo{More here} 
%
%Unless you had infinite amounts of time – which you don't – and infinite patience – which you might have – you could never be 100\% certain that your literature search collected \emph{all} relevant papers  the search space is infeasibly large (and not indexed particularly well). But you were systematic and achieved a practically good\footnote{By \emph{practically good}, we mean you found the most of the most important papers, some other papers, and didn't have to read \emph{every single paper}. I.e., you found a \emph{representative sample}.} coverage because of that.\todo{More here?}
%
%Sampling is the process of selecting a subset\footnote{We could have said \enquote{sample} but that would have been circular.} of an infeasibly large population of interest, and is used in the research strategies\todo{Update given Stage 3.} that work by estimating or predicting the properties of that population. %, for instance, survey (who will fill in your questionnaire) or experimental (who will take part in your experiment) research. 
%
%Sampling can either be random or non-random. 
%
%In \emph{random sampling}\footnote{Random sampling is also called \emph{probability sampling}.} some unbiased way of choosing, before the fact, subset members from the population, while in \emph{non-random sampling}\footnote{Non-random sampling is also called \emph{non-probability sampling}.}, the choice is based on a researcher's judgement and discretion and can be added to as the research progresses. The lack of bias in the former means that results tend to generalise from the sample to the population. The potential for bias in the latter means that results may not generalise, but things of interest, of depth, and of richness can be followed as they are discovered. As a result, the former is used more in quantitative research, and the latter in qualitative research\todo{Reword to separate the two?}. %Also, in quantitative research the tendency is to choose the sample upfront, before any analysis commences, while in qualitative research, the process is iterative, with more and more sample data collected and analysed until no more collection is possible or \textit{saturation} is reached, that is collecting more data would not bring more relevant information.
%
%Random sampling techniques include:
%\begin{description}
%
%	\item [simple random sampling] where each member of the population has exactly the same chance to be selected. It is easy and efficient to implement, and given the complete randomness of the sample, generalisation is fairly reliable. However, if the population has large sub-groups, these may be over-represented in the sample, with minority groups being under-represented.\todo{Add strengths and weaknesses.}
%	
%	\item [stratified random sampling] where sub-groups of the population are identified based on common characteristics, the \textit{strata}, and sampling is random across those strata. The strata are not mutually exclusive: for instance, the population may have sub-groups defined by gender, ethnicity and level of education, which may overlap. This approach overcomes the over/under representation problem of simple random sampling.\todo{Add strengths and weaknesses.}
%	
%	\item [cluster sampling] where the population is divided up in naturally occurring separate clusters, and the sample is obtained by randomly selecting some clusters and then randomly selecting members of those clusters. It is more cost-efficient than the other two approaches, but can introduce bias if the selected clusters are not representative of the whole population, so that the over/under representation problem remains.\todo{Add strengths and weaknesses.}
%\end{description}
%
%%%Candidate for moving to chapter preload
%
%Non-random sampling techniques include:
%\begin{description}
%	\item [purposive sampling] in which participants are selected by the researcher based on particular characteristics, knowledge, or expertise they have. It is often used for small populations, especially rare populations which may otherwise be difficult to access\todo{Clarify}. Purposive sampling is particularly suited to studies which intend to be deep and narrow, and for which subsequent generalisation back to the parent population is not a concern. As the sample choice is made by the researcher, it is prone to bias.\todo{Add other strengths and weaknesses, or perhaps the weakness is with the class rathe than the instance?}
%
%	\item [convenience sampling] where participants are selected based on their availability or accessibility. This is quick and easy, but unlikely to produce a representative sample, so, once again, bias is an issue.\todo{Add other strengths and weaknesses.}
%	
%	\item [snowball sampling] which relies on referral from previous participants to recruit new ones. This is an effective approach when a population is difficult to access or when the topic is sensitive or tabu. This too is unlikely to generate a representative sample, and is prone to bias.\todo{Add other strengths and weaknesses.}
%\end{description}
%
%\begin{question}[subtitle={Activity: Deep reading on Non-Random Sampling}]
%Check back to your choice of research strategy. If you've chosen one that uses non-random sampling, then you should read the following sources for more details \cites{}	
%\end{question}
%
%In summary, when choosing a sample, you need to consider various factors, including the aim of your study, the kind of methods you are applying, and the level of access you may have. Trade-offs are likely involved and you may not be able to obtain an ideal sample. Nevertheless, your sample will still be useful to your research, as long as you clearly explain and justify how it was obtained and what its limitations are.
%
%\begin{question}[subtitle={Activity: Choosing your sampling approach}]
%Assuming your study requires you to perform some sampling, write down the approach you are going to take, with its justification in terms of what is needed to address your aim and objectives, and any trade-offs due to the practicality of accessing the sample. Record any possible weakness or limitation of your chosen approach.
%\begin{guidance}
%You can skip this activity if sampling is not indicated by your choice of research strategy.
%\end{guidance}
%\end{question}
%
%\todo{Add other core techniques here; which are there?}
%

\chapter{Data analysis methods}

%%%
\newcommand{\ResAnTechnique}[1]{\begin{question}[subtitle={Activity: Do I need to know about #1?}]
Check back to your chosen research strategy from Stage 3. Does it involve data analysis using #1? If so, read through the remainder of this section and complete the activities.
\end{question}}
%%%

Your choice of data analysis methods is part of your research design, and relates to the kind of data and evidence you have generated, and what you are trying to achieve, that is your aim and objectives.

Analysis methods fall into two main categories, quantitative and qualitative, based on the nature of the data to analyse. In this section, we provide an introduction to some of the most common. This is far from complete and does not go very deeply into the details of each method: entire books have been written on any of them! By studying this section, you won't become an expert in any of these methods, but you will have gained enough understanding to be able to make a judicious selection for your project. After that, you should review the related specialised literature to help you apply your chosen methods appropriately. You should also talk regularly to your supervisor for further guidance.

\section{Using tables to analyse data}

Tables can be used to summarise both quantitative and qualitative data, as a starting point for their analysis.

\ResAnTechnique{tables}

The following kinds of tables are used extensively in research and often found in dissertations.

\paragraph{Pivot tables}

Pivot tables can be used to summarise, sort, filter, re-organise or group data organised in rows and columns, and perform calculations on them, such as counting, generating totals or averages, and much more. Pivot tables are both powerful and versatile\footnote{In fact, they are so versatile that we'll only be able to provide few illustrative examples. Much, much more can be found online!}, and one of the most widespread tools for data analysis.

You can generate a pivot table from any data set organised in rows and columns, regardless of whether the values are quantitative or qualitative: all common spreadsheet applications\footnote{From MS Excel to Apple Numbers to Google Sheets.} include this function.

figure~\ref{fig:exampleDataSet} gives an example: these are the first few raws of a data set related to the US housing market\footnote{It was taken from one of Kaggle's free datasets, the housing price dataset. Kaggle is possibly the largest and best known online community for data science and machine learning.}. The dataset contains over 9,316 entries, each corresponding to a distinct property. Each property is characterised by a number of attributes: size in square feet, number of bedrooms and bathrooms, type of neighbourhood, the year it was built and its market price in US dollars. As you can see, this table includes both numerical and categorical variables.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/exampleDataSet.pdf}
\caption{first few rows of the example dataset}
\label{fig:exampleDataSet}
\end{figure}

Pivot tables can be used to summarise such data to answer certain questions. For instance, we may be interested in the average house price by neighbourhood and number of bedrooms, which would result in the pivot table in figure~\ref{fig:pivot1}, which gives the average price of each combination. The `grand totals' in the table are also averages, by row and by column.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/pivot1.pdf}
\caption{Pivot table of average property prices by neighbourhood and number of bedrooms}
\label{fig:pivot1}
\end{figure}

Alternatively, we may be interested in finding out how many properties of each kind have been built in each neighbourhood. In this case the pivot table would look like that in figure~\ref{fig:pivot2}. The grand totals in this case are counts. Note how we have added combinations of bedroom and bathroom numbers to characterise each type of property.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/pivot2.pdf}
\caption{Pivot table of property counts by neighbourhood and number of bedrooms/bathrooms}
\label{fig:pivot2}
\end{figure}

These are just but two examples of questions about the data you can address by using pivot tables, out of a vast range of the possibilities. If your data are organised in tables, then it is well worth spending some time becoming familiar with pivot tables.

\begin{question}[subtitle={Activity: Pivot tables in Excel}] Download the housing price data set from Kaggle and re-create the pivot tables in our example. Come up with other questions you could ask of the data and generate related pivot tables.	
\begin{guidance}
Feel free to use your preferred spreadsheet application for this activity, as long as it supports pivot tables -- most do.

You may have to register with Kaggle to gain access to the data set. 

The Excel Help facility and documentation provides all the info you need to create a pivot table. However, you could also browse some of the very many freely available online resources and tutorials on this topic.
\end{guidance}
\end{question}	


\paragraph{Frequency and contingency tables}
Frequency tables are used to summarise the frequency (or count) of values taken by a categorical variables in a data set. For instance, after studying a degree, a student's outcome may be classed as distinction, merit, pass or fail. A frequency table can then be used to summarise the frequency of each class of outcome for a particular students' cohort, as shown in Table~\ref{tab:frequencyTableExample}.
 
\begin{table}[htbp]
\caption{Example of frequency table\label{tab:frequencyTableExample}}
\small
\begin{tabulary}{\tablewidth}{@{}LLLLL@{}} 
\toprule
  & \textbf{Distinction} & \textbf{Merit} & \textbf{Pass} & \textbf{Fail} \\
\midrule
 \textbf{Outcome} & 12 & 26 & 42 & 5\\
\bottomrule
\end{tabulary}
\end{table}

Contingency tables\footnote{Also known as \textit{cross-tabulation} tables.} are a form of frequency tables used to tabulate the value frequencies of two categorical variables. For instance, following from our previous example, we may like to tabulate the outcome value frequencies in the cohort against gender, as shown in Table~\ref{tab:contingencyTableExample}. 

\begin{table}[htbp]
\caption{Example of contingency table\label{tab:contingencyTableExample}}
\small
\begin{tabulary}{\tablewidth}{@{}LLLLL@{}} 
\toprule
 \textbf{Outcome by Gender} & \textbf{Distinction} & \textbf{Merit} & \textbf{Pass} & \textbf{Fail} \\
\midrule
\textbf{Female} & 7 & 12 & 21 & 2\\
\textbf{Male} & 5 & 13 & 19 & 3\\
\textbf{Other} & 0 & 1 & 2 & 0\\
\midrule
\textbf{Totals} & 12 & 26 & 42 & 5\\
\bottomrule
\end{tabulary}
\end{table}

Contingency tables are frequently used to summarise and analyse data collected in survey research, and are a key tool in statistical analysis.

Both frequency and contingency tables can be generated as pivot tables in a spreadsheet. In fact, the table in figure~\ref{fig:pivot2} is a contingency table. 


\subsection{Further reading}

\ResGenExtras{using tables}{{??}}

\section{Statistical analysis}\label{sect:statisticalAnalysis}

Statistical analysis in an umbrella terms for a set of methods which can be applied to numerical and categorical data. More precisely, in statistics data types are classified as:

\begin{itemize}
	\item scalar, which includes all measurements and counts; with reference to the types in Section\ref{sect:evidenceAndData}, these are all numerical data, continuous, discrete, interval and ratio data.
	\item categorical, both ordinal and nominal.
	\end{itemize}

There are two broad categories of statistical methods:
\begin{itemize}
	\item descriptive statistics, whose aim is to describe data; and
	\item inferential statistics, whose aim is to make predictions from data.
\end{itemize}

We briefly consider each in what follows. 

\subsection{Descriptive statistics} \label{sect:descriptive}

Descriptive statistics are used to describe various attributes of a data set. 

\ResAnTechnique{descriptive statistics}

The basics are:
\begin{itemize}
	\item count, to establish how many entries there are in the data set
	\item centrality, to establish the `centre' of the data set. Three measures are commonly used: the \textit{mean}, which provides the average value of the data set; the \textit{median}, which provides its mid point\footnote{Remember that quantitative data can be ordered.}; and the \textit{mode}, which indicates the value that occurs most frequently, if any\footnote{There is no mode if no value is repeated in the data set.}. 
	\item dispersion, to establish the spread of the data in the data set. Range and standard deviation are two common measures. The \textit{range} is the difference between smallest (minimum) and largest (maximum) values. The \textit{standard deviation} is based on a mathematical formula which considers the distance of each value in the data set from the mean. It is not essential for you to know such formula, which is automatically computed by spreadsheets and statistical software\footnote{Of course, you can always look it up in the literature...}. The larger the standard deviation, the greater the dispersion.
	\item skewness, to establish how symmetrically distributed the values in the data set are in relation to the centre. In the case of perfect symmetry, skewness is equal to zero, and mean and median are equal. When asymmetric, mean and median are different and the distribution may be either right (mean smaller than median, and negative skewness) or left (mean greater than median, and positive skewness) skewed. A perfectly symmetric distribution is usually referred to as a \textit{normal distribution} or \textit{bell curve}, from the shape of the line that can be obtained by plotting the data on a chart\footnote{This oversimplifies the topic in order to give some intuition in case you have not come across these terms before. A lot more should be said about the normal distribution and its pivotal role in statistics!}.
\end{itemize}

Not all descriptive statistics apply to categorical data. In particular, the mode is used as the main measure of centrality for nominal data, while the median is used for ordinal data which are not numeric.

These are lots of definitions to digest, particularly if you haven't encountered these terms before! The following activity should help.

\begin{question}[subtitle={Activity: Descriptive statistics in Excel}] Assume you have measured the weight in grams of each apple in a basket, obtaining the following numbers: 105, 120, 122, 125, 127, 128, 129, 130, 132, 133, 135, 135, 138, 140, 128. Enter these data in an Excel sheet and use its built-in data analysis function to generate the related descriptive statistics.
\begin{guidance}
In the current version of Excel, you can access this function from the Data tab, by pressing the Data Analysis button. If you find it difficult to locate this function, you should refer to the documentation or to some of the many tutorials on this topic which are freely available online.
\end{guidance}
\begin{solution}

You should have obtained the following values:

\begin{tabulary}{\tablewidth}{@{}LL@{}} 
\textbf{Attribute} & \textbf{Value} \\
mean & 128.47 \\
median & 129 \\
mode & 128 \\
standard deviation & 8.55 \\
skewness & -1.4 \\
range & 35 \\
minimum & 105 \\
maximum & 140 \\
count & 15 \\
\end{tabulary}

There are 15 values in this data set, with range 35 (the difference between maximum and minimum values).
In terms of centrality, the mean (128.47) is slightly smaller than the median (129), and Excel reports a mode at 128. In reality, if you look at the data you will see that there are two modes in this data set\footnote{Statisticians call this \textit{bi-modal}.}, 128 and 135, but Excel only returns the first encountered!
In terms of dispersion, the standard deviation is telling us that most apple weights are within 8.55 grams of the mean (below or above), so the apple weights are similar in the apple baskets.
Note that the skewness is negative, which is consistent with the mean being smaller than median, so the data distribution is right skewed. 
\end{solution}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

In your dissertation, you can easily present such descriptive statistics as a table, possibly adapting that automatically generated by your spreadsheet.

In addition, charts can be used to visualise the data and examine their descriptive statistics. 

With scalar data, like in our example, you can use a \textit{histogram}. The one in figure~\ref{fig:histogramBin1} uses the apple weights from the previous activity: on the horizontal axis, we have the distinct weights, and on the vertical axis, their frequencies, that is how many times each weight appears in the data set. Given the values you have obtained for the data set descriptive statistics, you can easily locate on the chart min and max values, and mean, median and mode. In this case, the two `peaks' correspond to the two modes we mentioned in the activity. You can also check that most of the values are within 8.55 grams from the mean, either way: the only values left out are 105 (to the left) and 138 and 140 (to the right). Skewness is not obviously notable on this chart, so that we will use a different chart for that purpose.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/barchart.pdf}
\caption{Histogram for the apple weights (bin size = 1)}
\label{fig:histogramBin1}
\end{figure}

Before we do that, however, it is worth noticing that given our small data set of discrete values, we have used a histogram with `bin' size equal to one, which allows us to plot each individual apple weight. A \textit{bin} in a histogram is essentially a way to group a number of values, with bin size establishing the spread of each bin. Frequencies are then calculated by bin. Grouping values in bins is necessary with large data sets and/or with continuous data.  figure~\ref{fig:histogramBin5} illustrates a histogram for our example, in which the bin size is 5: that is, each bin spans a set of 5 possible values. 

\begin{figure}[htbp]
\centering
\includegraphics[width=12cm]{figures/histogramBin5.pdf}
\caption{Histogram for the apple weights (bin size = 5)}
\label{fig:histogramBin5}
\end{figure}

In order to visualise both spread and skewness, a useful chart is the boxplot, illustrated in figure~\ref{fig:boxplot} for our example. This is made of a `box' around the median of the data, and some `whiskers' on each side of the box\footnote{Which is why this chart is also called a \textit{box and whiskers} plot.}. It is obtained by dividing up the data into quartiles, each containing a quarter (or 25\%) of the data, with the median in the centre. The box includes the two quartiles on each side of the median, which, together, account for half of the values in the data set. The whiskers account for the two other quartiles, with a caveat: if there are very extreme values, these are treated as possible outliers and left out of the whiskers. This is, in fact, the case in our example where value 105 is treated as an outlier in the chart: it is a dot on its own, not included in the left whisker. The whisker length provides an indication of spread: the longer the whiskers, the more spread out the data. Instead, the position of the median in relation to the extreme of the box provides an indication of skweness: in our example the median is further away from to the right edge (just!), indicating that the data distribution is slightly right-skewed (consistent with the negative skewness value in the descriptive statistics).

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/boxplot.pdf}
\caption{Boxplot for the apple weights}
\label{fig:boxplot}
\end{figure}

To be more precise, the relation between a boxplot and its underlying statistical features is illustrated in figure~\ref{fig:boxplotFeatures}. The two quartiles around the median represent the interquartile range (IQR) of the data set. The whisker lengths, calculated based on the formulae in the figure,  allows the identification of lower and upper bounds beyond which values are seen as extreme and represented separately as outliers. An outlier, therefore, is just a value which is distant from most of the other values in the data set: it may point to an error, which should be corrected, or an anomaly, which may require further investigation, but that's not necessarily the case. However, it's good practice to investigate all outliers to understand why they have occurred. 

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/boxplotFeatures.pdf}
\caption{The features of a boxplot --- LR to redraw as taken from the web}
\label{fig:boxplotFeatures}
\end{figure}


\begin{question}[subtitle={Activity: Charts in Excel}] Go back to your Excel sheet from the previous activities and generate charts similar to those in the figures above.
\begin{guidance}
In the current version of Excel, you can generate these charts from the Insert tab, by choosing from the Statistical charts menu. If you find it difficult to locate this function, you should refer to the documentation or check some of the many tutorials on this topic which are freely available online.
\end{guidance}
\end{question}


Table~\ref{tab:charts} summarises useful charts that can be applied to visualise your data and their descriptive statistics: it includes charts we have not used in our examples, but which are very common, so that you can find plenty of study materials online should you wish to look them up and use them.

\begin{table}
	\caption{Common charts to visualise data sets and their descriptive statistics}
	\label{tab:charts}
\begin{tabulary}{\tablewidth}{@{}LLL@{}} 
\textbf{Chart} & \textbf{Variable(s)} & \textbf{Purpose} \\
bar chart & one categorical & to visualise counts/frequencies/proportions/percentages \\
staked bar chart & two categorical & to compare   counts/frequencies/proportions/percentages between two groups\\
histogram & one scalar & to visualise distribution, including centrality, dispersion and skewness \\
scatter diagram & two scalar & to visualise relationships and possible outliers \\
boxplot & one scale or one categorical & to visualise spread, skewness, median, IQR and possible outliers \\
line chart & one scalar by time & to visualise change over time \\
\end{tabulary}
\end{table}


Calculating descriptive statistics and visualising data in appropriate charts, should be the first step in your statistical data analysis, as these provide useful summaries and visualisations of key properties of your data set. And, as you have found out in the activities, you do not need to be a statistician to be able to generate them!

Descriptive statistics may also help you identify errors or anomalies in the data, and can inform possible follow-up analysis, including inferential statistical analysis. Depending on your research aim and objectives, they could also be all you need in your project. 

If you have collected scalar or categorical data, it is time for you to have a go at analysing them using descriptive statistics and charts.

\begin{question}[subtitle={Activity: Applying descriptive statistics to your data}] 
Calculate descriptive statistics for your data set, and generate appropriate charts.
\begin{guidance}
MS Excel is relatively straightforward to use for this purpose, but feel free to use other tools you may be already familiar with, including statistical or data analytics packages. Whichever tool you use, you should ensure it supports the functionalities we have discussed in this section.
\end{guidance}
\end{question}


\subsection{Inferential statistics}\label{sect:inferentialStatistics}

Inferential statistics relies on the concepts of population and sample: the \textit{population} is the entire group you are interested in studying -- say, all UK voters in a general election; while the \textit{sample} is the portion or subset of that group you have access to in your research. Then the aim of inferential statistics is to establish whether patterns or effects you have observed in the sample can be generalised to, i.e., inferred for, the whole population, or whether they are the result of chance. In inferential statistics this is achieved through statistical tests.

\ResAnTechnique{inferential statistics}


A statistical test tells you whether the proposition\footnote{You can think of a proposition as an educated guess you have made based on some observations, but that has yet to be supported by evidence.} you wish to test on your sample is likely to be true in the population under study. For this to work, your sample must be representative of the population\footnote{We discussed sampling in Section~\ref{sect:sampling}}.

A statistical test returns a measure of \textit{statistical significance}, which is used to provide evidence (or otherwise) that the pattern or effect you see in your sample is also likely to exist in the population, and is not just the effect of chance\footnote{Contrary to the common language meaning of `significance' as big or important, statistical significance only indicates that the effect is likely to exist in the population, where it may well be small or unimportant!}. As a corollary, if your sample is very large, almost all effects observed in the sample will be likely present in the population; vice-versa, if your sample is very small, most effects observed in the sample are unlikely to be present in the population, unless they are really very large. As a rule of thumb, most tests require a sample size of at least 30 observations, but more precise sample size estimates can be made based on population size and expected significance level\footnote{Formulae for the ideal sample size are easily found in the literature and online.}.


Each statistical test comprises the following elements.

\begin{itemize}
	\item \textbf{Hypotheses} There are two, \textit{null} and \textit{alternative} hypotheses. Inferential statistics assumes you can't prove something to be true, but you can disprove something by finding an exception. Here is a classic example: you can't prove that all swans are white, but you can disprove they are by finding a black swan! So, you must  set the null hypothesis to what you want to disprove about the population, with the alternative hypothesis being what you are really interested in finding out. So, the null hypothesis is usually a statement of no pattern/effect in the population.
	\item \textbf{Significance} This is the level of statistical significance for the test. It's known as the \textit{alpha} ($\alpha$) value from the Greek name of the mathematical variable used to express it. Most tests are run with $\alpha=0.05$, which gives a 5\% probability that we may infer that the null hypothesis is disproved while in actually it is correct\footnote{This is called a Type I error in Statistics.}.
	\item \textbf{Sample(s)} You need to have one or more (representative) samples of the population of interest  on which to perform the test. Multiple samples are used in some tests, typically to compare specific statistics in different groups within the population or changes within a group over time or after an intervention of interest, say treating patients with a new pharmacological drug.
	\item \textbf{p-value} This is the probability calculated for your test by your statistical package, and which is used to decide the outcome of the test.
	\item \textbf{Decision} This is based on the p-value in relation to the $\alpha$ value: if the p-value is less than the $\alpha$ value, then the null hypothesis is \textit{rejected}, i.e. disproved, which means your alternative hypothesis that there is an effect in the population is supported by statistical evidence.
\end{itemize}

There are very many statistical tests to choose from, depending on the kind of data you have and their distribution, the purpose of your analysis and the number of samples involved. 

Statistical tests are applicable to both scalar and categorical data and can be used to compare values of specific statistics or to establish statistical relationships between variables, specifically:
\begin{itemize}
	\item an \textit{association} between variables means that one variable can be used to provide some information about the other
	\item a \textit{correlation} is a particular type of association such that the two associated variables always change together, for instance they both increase or decrease at the same time, or when one increases the other always decreases. 
\end{itemize}
Statistical tests can be used to estimate the strength of an association (i.e., the extent changes in one correspond to changes in the other) and its direction (whether the variable changes are in the same or opposite way).

We will not detail all possible statistical tests in this introductory section --- once again, entire books have been written about them! Instead, we provide Tables~\ref{tab:testsForComparison} and \ref{tab:testsForAssociation} as summaries of the most common tests that you can then follow up in the literature, should you wish to apply any in your research.

\begin{table}
	\caption{Common statistical tests for comparison. \textit{Parametric} tests apply to normally distributed data (see Section\ref{sect:descriptive}), while \textit{non parametric} tests to skewed distributions.}
	\label{tab:testsForComparison}
\begin{tabulary}{\tablewidth}{@{}LLLLLL@{}} 
\textbf{Purpose} & \textbf{Variables} & \textbf{Example} & \textbf{Parametric} & \textbf{Non parametric} & \textbf{Notes}  \\
\toprule
to compare the sample mean against a specific value & one scalar & to investigate whether AA batteries of a particular brand have the claimed lifespan  & one sample t-test & n/a  & \\
\midrule
to compare the sample proportion against a specific value & one categorical & to investigate the proportion of people who voted for a particular party in a city against that for the whole country & one sample z-test & n/a  & \\
\midrule
to compare the means of two independent samples & scalar & to compare the mean scores (dependent) of students studying the same subject with two different teaching approaches (explanatory) & independent t-test & Mann-Whitney test/Wilcoxon rank sum  & two samples are \textit{independent} when there is no reason to believe that observations in one sample are influenced or determined by those in the other\\
\midrule
to compare the means of three or more independent samples & scalar dependent; nominal explanatory & to compare the mean scores (dependent variable) of students studying the same subject with three or more different teaching approaches (explanatory variable) & one-way ANOVA & Kruskal-Wallis test \\
\midrule
to compare the average difference between paired samples against a particular value & scalar dependent; time or condition as explanatory & to compare the blood pressure readings (dependent vraiable) of a group of people before and after exercising (explanatory variable) & paired t-test & Wilcoxon signed
rank test &  in paired samples each data point in one sample is uniquely matched to a data point in the other sample; this happens, for instance, when we measure a factor before and after an intervention, or take different readings for the same group of individuals. Because of this, paired samples are not independent.\\
\midrule
\end{tabulary}
\end{table}

\begin{table}
	\caption{Common statistical tests for association. \textit{Parametric} tests apply to normally distributed data, while \textit{non parametric} tests to skewed distributions.}
	\label{tab:testsForAssociation}
\begin{tabulary}{\tablewidth}{@{}LLLLLL@{}} 
\textbf{Purpose} & \textbf{Variables} & \textbf{Example} & \textbf{Parametric} & \textbf{Non parametric} & \textbf{Notes}  \\
\toprule
to investigate correlation between two continuous variables & scalar dependent and explanatory & to investigate the relation between blood pressure (dependent) and age (explanatory)  & Pearson’s Correlation Coefficient & Spearman’s Correlation Coefficient & \\
\midrule
to investigate association between two categorical variables & categorical dependent and explanatory & to find out if there are gender (categorical) differences in the choice of modes of transport (categorical) in a city & chi-squared & n/a  &  \\
\midrule
to investigate association between two categorical variables when the sample is small & categorical dependent and explanatory & to find out if there are gender (categorical) differences in the choice of modes of transport (categorical) in a city  & fisher's Exact test & n/a & the sample size $n$ should be less than 20 \\
\midrule
to predict the value of one variable from that of one or more other variables & scalar dependent and any kind of explanatory & to predict house prices (dependent) based on location (explanatory, categorical) and number of bedrooms (explanatory, scalar) & linear regression & n/a & linear regression relies on associations between dependent and explanatory variables\\
\midrule
to predict the value of a binary variable from that of two or more other variables & binary categorical dependent and any kind of explanatory & to predict whether a customer is likely or not to purchase a certain product (dependent) based on previous purchased products (explanatory, categorical) and average annual spent (explanatory, scalar) & logistic regression & n/a & a binary variable has only two possible values, so that logistic regression calculates the probability of each value based on the values of the explanatory variables. Because of this logistic regression can be used as a classification method \\
\midrule
\end{tabulary}
\end{table}

Even if these tests are only a sub-set of all statistical tests available, there is a lot to digest. The next activity should help you use these table to choose an appropriate test. 

\begin{question}[subtitle={Activity: Choosing an appropriate test}] 
Consider the following scenarios: for each, use the information in the tables to decide which test to apply and what the null hypothesis should be. For each, write down your reasoning, choice and null hypothesis.

\begin{itemize}
	\item \textit{Scenario 1} to investigate the amount of sugar contained in baby food of a particular brand against a recommended threshold, from a sample of 30 products of that brand.
	\item \textit{Scenario 2} to investigate the number of products per hour of two manufacturing machines in the same plant, by observing the two machines' output over 24 hours. 
	\item \textit{Scenario 3} to investigate the effect of temperature on the consumption of ice cream in a particular city over 12 months.
	\item \textit{Scenario 4} to investigate whether taste in chocolate types, say white vs milk vs dark, is related to gender in particular country.
	\end{itemize}
\begin{guidance}
To simplify things, always assume normal distributions.
\end{guidance}
\begin{solution}
Assuming normal distributions, for each scenario, we have considered:
\begin{itemize}
	\item the kind of data
	\item number of samples and their size
	\item purpose of the investigation
\end{itemize}
This is what we have concluded:
\begin{itemize}
	\item \textit{Scenario 1} scalar variable (amount of sugar); one sample of 30 products; to compare the sample mean against the recommended threshold. The test to use is a t-test with null hypothesis that the sample mean is above the threshold.
	\item \textit{Scenario 2}  scalar dependent (number of products per hour) and categorical explanatory (which machine); two samples (one per machine over the time span); to compare the means of products per hours for the two machines; there is no reason to think that the working of one machine may influence that of the other. The test to use is an independent t-test with null hypothesis that the two sample means are different.
	\item \textit{Scenario 3} scalar dependent (level of ice cream consumption) and scalar explanatory (temperature); one sample over the period; to investigate any relationship between the two variables. The test to apply is Pearson's correlation with null hypothesis that there is no association between the two variables.  If, in addition, we wanted to make predictions on ice cream consumption based on temperature, then we could also apply linear regression.
	\item \textit{Scenario 4} both dependent (chocolate taste) and explanatory (gender) are categorical; one sample from the country; to investigate association. The test to use is a Chi-squared with null hypothesis that gender has no association with chocolate taste.
\end{itemize}
\end{solution}
\end{question}


\subsection{Further reading}

\ResGenExtras{statistical analysis}{{??}}


%\endinput

%%% LR -- to decide whether to include!!!!

%use of generative AI to add to ethics section
%constraints on the use of generative AI in research:
%- university policies: check with your university!!!! generative AI and IP issues
%- technology capabilities: still developing; as a human researcher you need to check and double check anything that AI does
%
%
%Complementary to statistical methods, an increasing variety of Machine Learning algorithms can also be used for data analysis. Two broad application concern the recognition of patterns in data and making predictions based on historical data.
%
%
%tasks that you can fast track with AI
%- 
%**** more about this????
%
%
%issue -- black box nature

\section{Qualitative analysis}

Qualitative analysis is used to extract meaning and insights from non numerical data, be that text, images, audio or other.

The most common types of qualitative analysis are:
\paragraph{Thematic analysis} which aims to identify recurring themes, their definition and relationships. It is ap
plied particularly to text, e.g., transcriptions of interviews or answers to questionnaires or existing text documents, for instance to find out something about people's views, opinions, knowledge, etc.

\paragraph{Content analysis} which aims to identify patterns used for communication, whether in text, speech, images, videos, or other, for instance, focusing on the use of certain words, themes, or concepts within that content. It can be used for many purposes, from discovering and understanding patterns, to looking at intentions behind what is expressed, or to highlighting differences of use in different contexts. 

\paragraph{Discourse analysis} which focuses on the use of language in conversations in a real-world context, including how this is influenced by historic or cultural factors, or power dynamics.

\paragraph{Narrative analysis} which focuses on stories made and told by people to investigate their meaning and how people make sense of reality.

\ResAnTechnique{any of the above types of qualitative analysis}

While their goal may be different, all these frameworks apply \emph{coding} as a core method, which we discuss next.


\subsection{Coding qualitative data}

A \textit{code} is essential a label which describes an extract from qualitative data set, with \textit{coding} the process of creating and assigning codes to categorise those extracts. 

Coding is important and it helps you ensure that your analysis is systematic, and the codes will help you explore themes and patterns in the data. However, codes are not themes: they are just labels used to group similar types of data, developed to support your follow-up analysis. 

There are two main approaches to coding. In \textit{deductive coding}, the codes are decided upfront, before looking at the data, and may be based on your research problem phenomena, or  may have emerged from your literature review, including codes possibly used in previous studies. In \textit{inductive} coding, the codes emerge from the data and are not pre-defined. Deducting and inductive coding can also be combined by starting with a set of pre-defined codes then adding new codes as you review the data.

Whichever your approach, you should follow a multi-pass coding process. The first pass should consist of going through the whole data set in order to establish which codes to use. In the second pass, and any subsequent ones, you should apply the codes to the data bit by bit, say by line by line in a text, or frame by frame in a video, etc. In the second pass and subsequent passes, the initial codes are reviewed and may become more or less detailed.

There are various ways to choose codes. For instance, \textit{in vivo} coding uses the exact language which occurs in the data: this is used, in particular, for participants' speech, especially when different languages are used. On the other hand, \textit{descriptive}\footnote{This is a very common approach, although there are others which you can research in the literature.} coding uses words which encapsulate a general idea, such as `sport' or `running': this is particularly useful for non textual data, like images or videos. 

Whichever codes you end up with, you should ensure they are properly defined, so that their are unambiguous and can be applied consistently. You should use a \textit{codebook} for this purpose, which lists all the codes and their intended meaning, and that you can revisit and refine throughout the coding process.

The last step before detailed analysis is \textit{code categorisation}, which is the process of reviewing what you have coded and organise it into categories. For instance, from codes such as `football', `tennis' and `rugby' you may define a category `sports'. In this way, you both organise your data and establish connections between codes and coded information. 

Both coding and categorisation are iterative processes which carry on until you reach saturation, that is no more is gained from further coding or categorisation. At this point, you can proceed with your chosen analysis method, whether content, thematic, narrative, discourse analysis or other, in order to identify patterns and themes, and provide your own interpretation of the data.

Coding and categorising are time consuming tasks, particularly if you have a large amount of text to code. In most research, coding data by hand is impractical and you should at least make use of a word processor, perhaps using colours and comments to code fragments of your text. Better still, you could  make use of a bespoke qualitative data coding tool: many such tools are now available, some of which can also automate coding and categorisation to some extent\todo{Add URLs in the following question}.

\begin{question}[subtitle={Activity: Investigating tools for qualitative data coding}] 
Conduct a web search on tools which support qualitative data coding. List up to four which appear most commonly used. For each, indicate which coding features it offers and the extent it is freely available for students' research projects.
\begin{solution}
Qualitative analysis tools are growing and changing rapidly, particularly due to the integration and exploitation of AI capabilities. 

At the time of writing this book, the most used commercial products include NVivo, ATLAS.it and MAXQDE%\todo{Add urls.}. 
They all provide support for coding, with more or less extensive automation, alongside various other features such as data visualisation, statistical analysis, automatic transcripts generation from audio and video files, to name just a few. These commercial products are quite sophisticated with a steep learning curve and are usually quite expensive. They are also geared towards large research efforts, possibly by teams of researchers.

An increasing number of lighter, free products are also available. These include, for instance, Taguette, which supports manual coding and is both open source and free to use, or QDE Miner Lite, which is a free limited version of its full commercial release, and also supports manual coding. Such free products may be sufficient for Masters level research projects.

You may have found other similar tools.
\end{solution}
\end{question}

\subsection{Presenting qualitative data}

While quantitative data can be summarised and presented using tables and charts, the same does not necessarily apply to qualitative data, which, due to their heterogeneous nature, cannot be easily set out in a standard manner. 

Conveying the depth and richness of qualitative data in a succinct way is challenging, so that both selectivity and creativity are needed in presenting the data. 

For textual data, like interview transcripts, verbatim quotations are often used to illustrate specific themes or points, or support certain conclusions. However, an excessive use of quotations will result in overlong accounts of the work, which may be difficult to follow or even obscure the main findings. Therefore it is important to select quotations which are particularly representative or poignant, avoiding verbose details that can be succinctly presented in the narrative around those quotations.

Diagrams, schematics or drawings can also be used effectively and imaginatively to present qualitative data and their analysis. Data visualisation is, in fact, a discipline in its own right\footnote{Edward Tufte is one of the most influential figures in this field. His books provide compelling examples on how to use visualisation to present and analyse highly complex data.}, and some visualisation techniques can be applied to qualitative data.

\begin{question}[subtitle={Activity: Visualisation techniques for qualitative data}] 
Conduct a web search on techniques for visualising qualitative data. List the techniques you have found and what they are used for.
\begin{solution}
You may have encountered some or all of the following techniques:
\begin{itemize}
	\item diagrams and schematics, to convey complex processes or structures
	\item graphic timelines, to summarise key events and their order
	\item word clouds, to summarise emerging themes or concepts from text, and their relative frequencies
	\item mind maps, to visualise how different ideas relate or contribute to a central concept or topic
	\item heat maps, to highlight trends or differences in tabulated data
	\item icons, alongside brief descriptions, to represent and quickly identify specific concepts 
	\item bespoke drawings, for data which cannot be easily visualised using other standard techniques
	\item pie charts and bar charts, to summarise proportions and counts – which are actually quantitative, but may be the result of qualitative data analysis – of categorical data.
\end{itemize}
\end{solution}
\end{question}

\subsection{Further reading}

\ResGenExtras{qualitative analysis}{{??}}

\chapter{Writing up your analysis}

\todo{to review in light of whole draft}

In writing up your data analysis in your stage report or dissertation, you will need to decide:

\begin{itemize}
	\item how to summarise your data and evidence. This will depend on their nature, and you will need to ensure that your summaries are appropriate to convey the essence of the evidence you have generated. In the previous sections, you have considered ways in which quantitative and qualitative data can be summarised using tables and visualisations. It may also be necessary for you to include sample raw data in an appendix.
	\item how to report findings. Your findings are your conclusions from your data analysis and should be reported as academic arguments which rely on the evidence you have generated. 
	\item how to structure your narrative. Depending on your chosen research strategies and methods, different structures are possible. For instance, you may choose to start with a section which summarises all your evidence followed by one in which you analyse it, which may work well, for instance, for survey research. Alternatively, you could have separate sections each including a summary and analysis of a sub-set of your evidence: this may be appropriate for mixed methods research, with each section dealing with a different kind of data, or for design science research, with each section addressing a different design cycle. Whatever you choose, it is important that your report is effective in presenting your evidence and findings in a clear, rigorous and logical manner.
\end{itemize} 


\begin{question}[subtitle={Activity: Writing up your analysis}] 
Consider the data you have collected and analysed so far. Note down how you are going to address each of the points above in your report. Write an outline of your analysis section.
\begin{guidance}
A good starting point is to consider how other researchers report their data analysis and findings. To this end, go back to some of the articles you have reviewed and consider their data analysis section and any related discussion. Ensure you select articles that apply similar collection and analysis methods to those in your research design, or deal with similar types of data.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}


%%%LR -- I don't think we need this, which is a T802 thing
%\subsection{The extended abstract} 
%
%An {extended abstract} is a summary of academic research intended for a more general audience, so that it should be easily read and understood by someone with only a superficial knowledge of the topic. As with the abstract, it should be a stand-alone item without any reference to your full dissertation. However, it is a lengthier piece of academic writing, structured with headings and sub-headings, including citations and references, and possibly tables, figures and diagrams to help you present and summarise your work.
%
%\begin{question}[subtitle={Activity: Drafting your extended abstract}] Write a draft extended abstract for your project, which should reflect your research progress to date.
%
%\begin{guidance}Your extended abstract should be 4 to 6 pages in length (once complete) and a common structure is as follows:
%
%\begin{itemize}
%\item Title --- the same as your dissertation
%
%\item Introduction and background --- an outline of your research problem in its context, its significance, and the knowledge gap addressed by your research
%
%\item Aim and objectives --- from your dissertation
%
%\item Research design --- an outline of your research design
%
%\item Results --- a summary of the evidence collected and analysed, and your key findings
%
%\item Discussion --- how significant your findings are in relation to research problem and knowledge gap
%
%\item Conclusion and future work --- your overall conclusions and possible follow-up research
%
%\item References --- selected references cited in the body of your extended abstract
%
%\end{itemize}
%
%Your course may have different guidelines which you should check and follow to produce your extended abstract.
%
%\end{guidance}\end{question}
%%%Hack to correct tcbox behaviour
%\color{black}

\chapter{Managing risk in Stage 4}

More here

\chapter{Reflecting and reporting in Stage 4}

It's time to write your Stage 4 report. As in the previous stages, before you do, it is worth reflecting on your work and learning in this stage.

\begin{question}[subtitle={Activity: Reflecting on your learning and practice}]
As you did at the end of the previous stages, in this activity you are asked to stand back and reflect deeply on what you have leant and done, the wider context of your work and your own attitude to it. Specifically, you are asked to think deeply about each of the following:

\begin{itemize}
	\item your study this far
	\item the way you work
	\item the context of your research
	\item your feelings about your project
\end{itemize}

You should also think of any significant changes with respect to your reflection in the previous stages
\begin{guidance}
You should be accomplished at reflection by now. However, should you need to, you can refer back to the guidance to this activity in Stage 1, Section~\ref{sect:stage1Reflection}.
\end{guidance}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

Your end-of-Stage 4 report will help you consolidate your work so far, adding yet another increment toward your full dissertation. We recommend you follow the guidance in Table~\ref{tab:S4report} to write your report.

At the end of Stage 4, you should complete a report, extending that of Stage 3 and covering the work you have carried on in this stage. Its recommended structure and content are indicated in Table~\ref{tab:S4report}: much of the content should be carried forward from the previous stage.

\begin{table}[htbp]
\caption{Report structure and guidance \label{tab:S4report}}
\centering
\begin{tabulary}{\tablewidth}{@{}LL@{}} \toprule
 \textbf{Report template} & \textbf{Guidance} \\
\midrule

 Proposed title & Your title should continue to capture succinctly your research problem and aim. \textit{It is likely this is the same as, or very similar to, that in Stage 3}\\
 Abstract & You should include your draft abstract providing a succinct account of your research to date \\
 Sect 1 - Introduction 1.1 Background to the research 1.2 Justification for the research 1.3 fitness of the research & This section should continue to provide an introduction to your research topic in its wider context (as background) and your justification of why the research is worth pursuing. Its purpose is to introduce and justify your intended research in overview, before entering the detailed work of the subsequent sections. It should be well argued and supported by appropriate citations. In this section, you should also argue how the research fits within the scope of your qualification, and meets any other personal, professional or organisational criteria. \textit{You may review this section from Stage 1 to reflect your growing understanding of the topic in context derived from your literature review.} \\
 Sect 2 - Literature review 2.1 Review of existing relevant knowledge 2.2 Critical summary, including knowledge gap to be addressed by the research & Your review should provide a critical account of your in-depth engagement with the academic (and other) relevant literature, including identifying key trends, ideas and possible knowledge gaps. Most of your citations should point to academic articles. Your critical summary should highlight key insights from your review and provide a strong justification for your proposed research. Both coverage and depth of your review matter. You should ensure that your review is well structured, with a logical narrative flow and your arguments are well supported by evidence \\
 Sect 3 - Research definition 3.1 Problem statement 3.2 Aim, objectives, tasks and deliverables 3.3 Knowledge contribution & You should ensure that your research problem is well articulated and appropriate for your course and your personal and professional circumstances, that your aim and objectives are consistent with research problem, that tasks and deliverables break down your objectives appropriately and are clearly related to your chosen research methods, and that the intended knowledge contribution of your research is clearly articulated \\
  Sect 4 - Research design 4.1 Evidence and data 4.2 Research strategy and methods 4.3 Research procedures 4.4 Ethical, legal and EDI considerations & This section should demonstrate your critical engagement with all elements of research design, including a detailed account of the data and evidence needed in your research, the research methods and research strategies chosen, with justification, and applied within your project. Your account should be supported by a clear rationale and insights from the related literature, and appropriately justified in relation to your research problem, aim and objectives. It should also demonstrate your careful consideration of ethical and legal matters, and that your research complies with your course and university requirements \\
  Sect 5 - Analysis and interpretation 5.1 Summary and analysis of evidence 5.2 Summary of key findings 5.3 Interpretation in relation to aim and objectives & This section should demonstrate substantial progress towards generating and analysing your data and evidence, and interpreting them in relation to aim and objectives. It should demonstrate a competent execution of your research design, present appropriate summaries of evidence and data, supported by raw data in an appendix if needed. Key findings should be clearly identified and logically connected to evidence, with good critical reflection on their implications for aim and objectives. \\
  Sect 6 - Work planning and risk assessment 6.1 Statement of progress 6.2 Key priorities in follow-up stage 6.3 Risk assessment & In this section you should reflect on the progress you have made in Stage 4 and establish your priorities for the next stage. You should also review your risk assessment as appropriate. \\
 References & You should keep your growing references in good order and ensure you apply the required bibliographical style consistently. \\
 Appendix - Raw evidence & If relevant, you should include a sample of your raw data as an appendix \\
 Appendix - Work schedule & You should include your revised work plan as an appendix \\
 Appendix - Risk assessment table & You should include your updated risk table as an appendix \\
\bottomrule
\end{tabulary}
\end{table}

\begin{question}[subtitle={Activity: Writing and assessing your report for Stage 4}] Using your word processor of choice, revise and expand your Stage 3 report by applying the structure and guidance in Table~\ref{tab:S4report}. 

Assess your report by applying the criteria in Table~\ref{tab:criteriaForStage4report}. Revise and iterate until you are ready to move on. 
\begin{guidance}
In completing your report, you should make good use of notes and summaries your wrote as part of the activities in this chapter.
In evaluating your report, for each criteria, you should consider the related prompts, write down any further work needed for your next stage, and update your work plan and risk assessment table accordingly.
\end{guidance}\end{question}
%%Hack to correct tcbox behaviour
\color{black}
%\endinput

\begin{table}
	\caption{Criteria for reviewing your research proposal \label{tab:criteriaForStage4report}}
\begin{tabulary}{\tablewidth}{@{}LL@{}} \toprule
 \textbf{Criteria} & \textbf{Prompts} \\
\midrule
 \textbf{Completeness} & Are all sections included and their content complete? What is missing?\\
 \textbf{Academic writing} & Have you applied good academic writing practices throughout? Which main issues do you still have to address? \\
 \textbf{Logical structure and flow} & Have you structured your writing appropriately to ensure a logical flow of arguments? Which restructuring may be needed?\\
 \textbf{Supporting evidence} & Are your key arguments supported by appropriate references or other evidence? Which further evidence is needed?\\
 \textbf{Citation and reference style} & Do all your citations and references comply with the required bibliographical style? \\
 \textbf{Avoiding plagiarism} & Have you acknowledged the work of others and distinguished it from your own appropriately? \\
 \textbf{Grammar and spelling} & Have you proof-read your report carefully to remove all typos and grammatical errors? \\
\bottomrule
\end{tabulary}
\end{table}
%\endinput

\chapter{Takeaways}
\begin{itemize}
\item Sampling is the process of selecting a sample from the population of interest, and is required in many research strategies. Many different approaches to sampling exist, depending on the nature and aim of your research.
\item Questionnaires are common tools for data generations. Good questionnaire design relies on a wide range of considerations (see Section~\ref{sect:questionnaireDesign}).
\item When a large amount of raw data is collected, it is important to devise appropriate ways to store and organise them, paying particular attention to backing them up and protecting personal data.
\item Tables are common ways to organise and present data, and a good starting point for data analysis. Pivot, frequency and contingency tables are commonly used in research.
\item Descriptive statistics is used to describe data, with various attributes of data sets defined and calculated, such as centrality, dispersion or skewness. Charts are often used to visualise such attributes.
\item Inferential statistics is used to make predictions from data, specifically to establish whether patterns or effects observed on sample data can be inferred for the whole population from which the sample was taken.
\item Statistical tests are used to establish the statistical significance of observations on a sample in relation to the whole population. They are used both for comparing data to set values and to establish relationships between variables. Many statistical tests exist.
\item Coding is the first step in qualitative analysis, and is the process of assigning labels to extracts from a qualitative data set to allow a systematic follow-up analysis. Different approaches to coding exist.
\item  Qualitative data are heterogeneous in nature, so that they cannot be easily set out in a standard manner. Many different, often bespoke, approaches to present and visualise qualitative data have been proposed in the literature.
\item In writing up your data analysis you must decide how to summarise your data, how to report your findings and how to structure your narrative. 
\item Interpreting your findings means to indicate what you can conclude from the data, how that relate to your aim and objectives, and which new knowledge it contributes.
\item An abstract is a short summary of your whole dissertation, written for a specialist audience as a stand-alone piece, that is understandable without reference to any other part of your dissertation.
\item The template provided can help you structure your Stage 4 report.
\end{itemize}


