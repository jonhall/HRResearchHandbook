%%Why?
\renewcommand*{\mkccitation}[1]{~(#1)}

\chapter*{Stage 4: Gathering and analysing data}

You've now reached Stage 4, which means the end of your project is now in sight. In this stage you will be in the midst of your data gathering and analysis, which is possibly the most exciting, yet demanding, part of your research: this is where you get an opportunity to make your original contribution to knowledge.

This stage assumes that you have worked out most of your research design details and are now in a position to begin your data generation and analysis\footnote{If that's not the case, then, you should go back to Stage 3. You should also discuss your progress with your supervisor, revisiting your project timescale and risk.}.
With reference to our 5-stage framework, the activities which are in focus in Stage 4 are summarised in Table~\ref{tab:stage4}, which also provides some guidance for your interaction with your supervisor during this stage.

\begin{table}[htbp]
\caption{Research activities addressed in Stage 4 (20\% of project length)\label{tab:stage4}}
\small
\begin{tabulary}{\tablewidth}{@{}LLLLL@{}} 
\toprule
 \textbf{Research process activities} & \textbf{Deliverables} & \textbf{Learning Outcomes: by the end of this stage you will:} & \textbf{Effort} & \textbf{Suggested focus of your interaction with your supervisor} \\
\midrule

 \textbf{Identifying the research problem} & Research problem statement, refined as needed & be able to assess and improve your research problem statement & 1\% & \\
 \textbf{Reviewing the literature} & Substantial draft of your literature review, refined as needed & be able to assess and improve your current draft & 1\% &  \\
 \textbf{Setting your aim and objectives} & Aim and objectives, refined as needed & be able to assess and improve your aim, objectives and related tasks & 2\% & \\
 \textbf{Developing the research design} & Research design description, refined as needed &  be able to describe data generation and analysis procedures in detail  & 2\% & Suitability of methods and procedures \\
\textbf{Gathering and analysing evidence} & Raw data appropriately organised and stored; data summaries and outcomes of data analysis & know the difference between various sampling approaches; be able to organise and store your raw data; be able to apply appropriate data analysis methods; be able to present your data and evidence in a concise and effective way & 50\% & Appropriateness of data analysis and presentation\\
\textbf{Interpreting and evaluating findings} & Draft summary of findings from data/evidenced gathered & be able to derive findings from your data analysis and critically assess them in relation to research aim and objectives & 15\% & Critical and logical thinking\\
 \textbf{Reflecting and reporting} & Stage 4 report; draft abstract for your project & know the purpose and content of an abstract; be able to assess your research progress and write up a substantial report, including an abstract for your project & 25\% & Any further improvements required, particularly in relation to critical thinking and academic writing \\
 \textbf{Planning work and managing risk} & Updated risk and work plan & be able to assess risk and draw a work plan & 5\% & Any major adjustment required to address deficiencies or manage risk \\
\bottomrule
\end{tabulary}
\end{table}

\begin{question}[subtitle={Activity: Understanding the effort needed in this stage}] Consider Table~\ref{tab:stage4} carefully, paying particular attention to the entries in the `Effort' column. Make a note of the activities which are most prominent in this stage and what their deliverables and learning outcomes are.

\begin{solution}
Gathering and analysing evidence will constitute by far your major effort in this stage (50\% of study time): in particular, the framework assumes that you will have worked out the details of your research design in Stage 3, so you can focus on applying your data generation and analysis methods. You will also start to interpret you findings, an activity your will complete in Stage 5. 
\end{solution}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

Note that your data analysis and interpretation may also prompt you to generate more data, including, perhaps, reviewing more academic literature or even re-thinking or adjusting your  aim an objectives better to reflect your improving understanding. Therefore, so you should expect some iteration back to activities you have carried out in previous stages, and revision of things you have written.

By the end of Stage 4 your data generation, analysis and interpretation should be on a solid ground, and consistent with your aim and objectives. Your research design description should also be close to its final form. Given the criticality of this stage, it is essential that you work very closely with your supervisor throughout.

\section{Generating raw research data}

Your \textit{raw data} represent any data\footnote{Some authors may also describe data as \emph{evidence}.} you generate as part of your research. 

Which data you generate and how it is determined by the choices you have made in your research design, informed by your research aim and objectives. In this section, we look at key topics in generating data. This section provides 
%
\begin{itemize}
\item design tips and techniques for each technique;
\item a basic workflow to get your data generation going;
\item weaknesses exposed through the data generating technique;
\item further sources to consult for more detail.
\end{itemize}
%

%\subsection{Data generation}

When we say \enquote{data generation}, we don't necessarily mean that you will create a new-to-the-world \enquote{data}\footnote{Although this might indeed be the outcome of your data generation.}. We simply mean new-to-your-masters-project data. 

New-to-your-masters-project covers a multitude of sins, including:
%
\begin{itemize}
\item the creation of a brand new data set from a newly instrumented organisational process, for instance; this might be the first time that the process has had data collected of it, and so the data you collect has been generated for your research project; It may also be data collected through a questionnaire or focus group, through  selecting passages from documents, etc.
\item the extension of a previously collected data set with new elements, derived from those that already exist; this might mean adding the mean value of a collection of numerical data to en existing data set, or grouping together specific phenomena into new categories that you have created;
\item the collection of previous data for reinterpretation; no new data is created which might be the case if you are rerunning a previous research project, or dong a meta-analysis of the literature in a particular area.
\end{itemize}
%
Our use of the term \emph{data generation} includes each of these. 

Of course, in making a contribution to knowledge, you're going to have to do it independently of the data generation method and so the data you generate or collect as part of your research must allow you to conclude something new.

\subsection{Modern standards}

Modern standards of research often require that data be made available to other researchers so that your research can be rerun. In areas such as machine learning, in which new knowledge can be the improvement of a fraction of a percent in the ability of a artificial intelligence's \enquote{ability} to diagnose a medical condition from images, not being able to satisfy this condition can negate your knowledge contribution. Elsewhere, you should consider whether your data will need to appear as part of an appendix to your dissertation, as might be the case should you use Interviews, for instance. 

The need to anonymise data\footnote{There may be a route to your degree in which your thesis is not published. Should you have any concerns about the release of data, please do find time to discuss this with your supervisor, balancing the needs for total anonymity with those than can be achieved through data anoymisation.} without losing its research value for your project and the need to release commercial in confidence or otherwise sensitive data as part of your dissertation, should be part of your decision process within your data generation process. 

In the following, we step through the most used data generation methods – those that were mentioned as part of Stage~\ref{stage3}, i.e., Interviews, Journalling, Observations, Questionnaires, Documents, Focus groups, Field work, Computational thinking, Mathematical thinking, Statistical thinking, and Reflexivity.

\subsection{Sampling: what, who (and how) to choose}\label{sect:DG:sampling}

A core element of many of the data generating techniques described below is the choice of data source\footnote{Of course, you've already had experience of choosing data sources when you conducted your literature search as part of Stage~\ref{stage:?}; you might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. \todo{More here} 

Unless you had infinite amounts of time – which you didn't – and infinite patience – which you might have – you could never be 100\% certain that your literature search collected \emph{all} relevant papers  the search space is infeasibly large (and not indexed particularly well). But you were systematic and achieved a practically good\footnote{By \emph{practically good}, we mean you found the most of the most important papers, some other papers, and didn't have to read \emph{every single paper}. I.e., you found a \emph{representative sample}.} coverage because of that.\todo{More here?}

Sampling is the process of selecting a subset\footnote{We could have said \enquote{sample} but that would have been circular.} of an infeasibly large population of interest, and is used in the research strategies\todo{Update given Stage 3.} that work by estimating or predicting the properties of that population. %, for instance, survey (who will fill in your questionnaire) or experimental (who will take part in your experiment) research. 

Sampling can either be random or non-random. 

In \emph{random sampling}\footnote{Random sampling is also called \emph{probability sampling}.} some unbiased way of choosing, before the fact, subset members from the population, while in \emph{non-random sampling}\footnote{Non-random sampling is also called \emph{non-probability sampling}.}, the choice is based on a researcher's judgement and discretion and can be added to as the research progresses. The lack of bias in the former means that results tend to generalise from the sample to the population. The potential for bias in the latter means that results may not generalise, but things of interest, of depth, and of richness can be followed as they are discovered. As a result, the former is used more in quantitative research, and the latter in qualitative research\todo{Reword to separate the two?}. %Also, in quantitative research the tendency is to choose the sample upfront, before any analysis commences, while in qualitative research, the process is iterative, with more and more sample data collected and analysed until no more collection is possible or \textit{saturation} is reached, that is collecting more data would not bring more relevant information.

Random sampling techniques include:
\begin{description}

	\item [simple random sampling] where each member of the population has exactly the same chance to be selected. It is easy and efficient to implement, and given the complete randomness of the sample, generalisation is fairly reliable. However, if the population has large sub-groups, these may be over-represented in the sample, with minority groups being under-represented.\todo{Add strengths and weaknesses.}
	
	\item [stratified random sampling] where sub-groups of the population are identified based on common characteristics, the \textit{strata}, and sampling is random across those strata. The strata are not mutually exclusive: for instance, the population may have sub-groups defined by gender, ethnicity and level of education, which may overlap. This approach overcomes the over/under representation problem of simple random sampling.\todo{Add strengths and weaknesses.}
	
	\item [cluster sampling] where the population is divided up in naturally occurring separate clusters, and the sample is obtained by randomly selecting some clusters and then randomly selecting members of those clusters. It is more cost-efficient than the other two approaches, but can introduce bias if the selected clusters are not representative of the whole population, so that the over/under representation problem remains.\todo{Add strengths and weaknesses.}
\end{description}

%%Candidate for moving to chapter preload

Non-random sampling techniques include:
\begin{description}
	\item [purposive sampling] in which participants are selected by the researcher based on particular characteristics, knowledge, or expertise they have. It is often used for small populations, especially rare populations which may otherwise be difficult to access\todo{Clarify}. Purposive sampling is particularly suited to studies which intend to be deep and narrow, and for which subsequent generalisation back to the parent population is not a concern. As the sample choice is made by the researcher, it is prone to bias.\todo{Add other strengths and weaknesses, or perhaps the weakness is with the class rathe than the instance?}

	\item [convenience sampling] where participants are selected based on their availability or accessibility. This is quick and easy, but unlikely to produce a representative sample, so, once again, bias is an issue.\todo{Add other strengths and weaknesses.}
	
	\item [snowball sampling] which relies on referral from previous participants to recruit new ones. This is an effective approach when a population is difficult to access or when the topic is sensitive or tabu. This too is unlikely to generate a representative sample, and is prone to bias.\todo{Add other strengths and weaknesses.}
\end{description}

\begin{question}[subtitle={Activity: Deep reading on Non-Random Sampling}]
Check back to your choice of research strategy. If you've chosen one that uses non-random sampling, then you should read the following sources for more details \cites{}	
\end{question}

In summary, when choosing a sample, you need to consider various factors, including the aim of your study, the kind of methods you are applying, and the level of access you may have. Trade-offs are likely involved and you may not be able to obtain an ideal sample. Nevertheless, your sample will still be useful to your research, as long as you clearly explain and justify how it was obtained and what its limitations are.

\begin{question}[subtitle={Activity: Choosing your sampling approach}]
Assuming your study requires you to perform some sampling, write down the approach you are going to take, with its justification in terms of what is needed to address your aim and objectives, and any trade-offs due to the practicality of accessing the sample. Record any possible weakness or limitation of your chosen approach.
\begin{guidance}
You can skip this activity if sampling is not indicated by your choice of research strategy.
\end{guidance}
\end{question}

\todo{Add other core techniques here; which are there?}

\newcommand{\ResGenTechnique}[1]{\begin{question}[subtitle={Activity: Do I need to know about #1}]
Check back to your list of candidate research strategies that you complete in Section~\ref{sec:??}. Does it include a research strategy involving data generation using #1? 

If so, read the next section and complete the activities.
\end{question}}

\newcommand{\ResGenExtras}[2]{\begin{question}[subtitle={Activity: Deep dive into #1}]
To find out more about #1, take a look at these resources:

\cites#2

\end{question}}

\section{Data gathering tools and techniques}

\subsection{Observations}\label{sect:DG:observations}

\ResGenTechnique{Observations}

Empirical data is the benchmark against which theories and advances in knowledge are made, and observation is the way in which empirical data are generated. In effect, \textcquote{marvasti2014analysing}{Observation is the foundation of science.}\todo{Ensure that\footcite{driscoll2011introduction} \emph{Voluntary participation}, \emph{Confidentiality and anonymity}, and \emph{Researcher bias} are covered elsewhere, if not here.}

\subsubsection{Observation tools}

\blockcquote{daston2011introduction}{Observation[s...] instruments include not only the naked senses, but also tools such as the telescope and the microscope, the questionnaire, the photographic plate, the glassed-in beehive, the Geiger counter, and a myriad of other ingenious inventions designed to make the invisible visible, the evanescent permanent, and the abstract concrete. Where is society? How blue is the sky? Which ways do X-rays scatter? Over the course of centuries, scientific observers have devised ways to answer these and many other riddles.}

That the techniques of observation have grown alongside its domains of applications means that there are a  vast collection and many, many deep specialisations of them in specific circumstances. Whole books have been written on them\footnote{See below for definitive sources you can use here.}; we can give but a very shallow introduction to them. We will, however, note that what can be observed is core to the characteristics of a phenomenon, and so it is the phenomena that you have identified as part of your research problem that you will be observing, whether they are interactions between atoms, between school children, or even your own actions, thoughts, and – perhaps even – biases.

This means that all research strategies will, to some extend, test your ability to observe.

It may be that, in the course of your research, you will observe related or proxy phenomena, as needs must. Part of your observation skills will be to identify those related to and proxies for. Part of your observations will be your ability to record those observations and to iterate those records into structures that capture the characteristics that are necessary to do the research on their back. 

\paragraph{Observation types: natural, artificial, social}

Observations are versatile tools for almost any research domain, and the domain you are observing will determine what sort of observations you will make. Observations range across \emph{natural phenomena} – such as the different proportions of plant species that populate a train station wilderness garden – through the \emph{artificial phenomena} – the way that buses drop off and pick up their passengers at a train station – to observations of \emph{social phenomena} – the different ways in which a train station is used by commuters in the morning and the evening – as well as more complex combinations of each. Each will use different observations techniques and tools, and each with different constraints. 

\paragraph{More on social observations} As an observer of people, you can act as a \emph{participant observer} – a researcher that interacts as a member of a community, in effect \enquote{living} alongside those you observe – you might be a commuter that uses the train station and so observe others in their use. Alternatively, you may be an \emph{unobtrusive observer}, a researcher that works outside of the \enquote{frame of reference}\todo{What does this mean? Does it need to be defined?} for the observations you will make, perhaps standing at the entrance/exit to the train station counting how many commuters pass.

As an unobtrusive observer, one must weigh up the need for privacy for those observed – if the judgement is that the phenomena observed do require privacy – perhaps you wish to observe commuters' use of restrooms in the train station – then you must explicitly ask for permission – or change your research problem! Otherwise, in a public space, there may be no overriding expectation of privacy and observation can be done without explicit consent. This issue is context dependent – although observation within a train station might not need explicit consent, observation within a betting shop, for instance, probably will.

\subsubsection{Workflow}

Observations\todo{Paragraph adapted from AI} can be conducted on nearly any subject matter, and the kinds of observations you will do depend on your research question. Depending on the nature of the phenomena you are observing, you will prepare, run, and analyse your observations\footnote{Data analysis was/is dealt with where?}. When conducting observations, it is important to record only the events that are directly observable and to separate observations from interpretations to eliminate bias in your notes\footnote{The right way to do this follows in a short while.}. 

\paragraph{Preparing to observe} To be able to observe you will need to:
%
\begin{itemize}
\item choose which phenomena: whether natural, artificial, or social
\item if social: then choose which mode – either participant or unobtrusive.
\end{itemize}
%
In the case of participant observer, where you are located in time and space will be determined by your participation. If you are a participant observer of train station usage, then you will make your observations whenever you use the train station. It may be that you exaggerate your use of the train station to condense many months of participant observation into weeks or days – after all, your research project is time bounded – perhaps visiting  ten times per day rather than just two. Keeping use to those of a participant is the key. 

In the case of the other observations, you must determine the time and place at which those observations will be made. 

\paragraph{Unassisted observations} if you are able to observe using only your sense – sight, smell, taste, touch, or feel – then you must be colocated in time and space with the phenomena you wish to observe. 

\paragraph{Assisted observations} many phenomena do not permit observation through the senses unassisted – for instance, the search for exoplanets\footnote{Find example.} requires complex and delicate instruments which will be located on mountain tops, for instance. In this case, the availability of the equipment you will use will determine when and how you make your observations. In this case, you must plan to have and gain access to that equipment, and your other research tasks may have to fit around that access.

Records – created with the aid of technology, for instance, video recording of phenomena – may allow you to time-shift your observations to more convenient time. In addition, there may already be records made of the phenomena you wish to observe that are available to you\footnote{In which case, \url{youtube} might be your friend.}. 

\paragraph{Semi-assisted observations} although some phenomena do not permit direct sense observations, increasingly the sense-prostheses needed to make observations is sufficiently portable to make colocated observations possible. Indeed, it may be that a smartphone is all you need to make excellent observations.

In any case, if you need equipment, you must ensure that you have access to it at a time and in a location that fits your plan\footnote{Remember, plans never survive first contact with reality, so also plan to have a backup plan that you can use should your first plan to make your observations fail!}.

\subsubsection{Other things to think about}

Although you might see observation as being and seeing, observation is, by no means an easy way of generating research data. There are many issues that can arise, including:
%
\begin{itemize}
\item Observations can be influenced by the observer-observed relationship, overfamiliarity can, for instance, lead to observer bias such as in making of natural but undue inferences – see below
\item likewise, maintaining analytic detachment is important in observational research to avoid bias.
\item Different analysts, or different stages of analysis as your research progresses, may focus on different aspects of the same data. This can be a good thing should you analysis deepen due to understanding more about your observations, but may also lead to analysis drift or even \enquote{paralysis through analysis} in which no progress is made due to too much depth. To avoid this, keep a clear eye on the prize: your research goal, and set regular times at which you can reflect on progress.
\item The analysis of observations depends on the researcher's chosen focus and philosophical and analytical framework. This is a natural dependency and can give great richness to observations, even those that are taken from the record. However, they can also lead to overthinking and, like the previous item, paralysis, as well as to prose that is obtuse and disengaging for the reader\footnote{And examiner! Consider, also, that the examiner might not share your focus and that this difference might be sufficient for them to discount your work as without value. Not likely, but care is needed.}.
\end{itemize}

\paragraph{More on observer bias}

Bias in general is treated in Section~\ref{sec:bias}. Here we add something to that general description about observer bias that gives a tool for avoiding it, or at least being aware of it: the \enquote{double-entry notebook}\footnote{See \textcite{driscoll2011introduction}; example on page 162.}.

\paragraph{Notebooks: avoiding observer bias}

The double entry notebook separates pure observation from judgemental observation, in which value judgements are made. 
%
\begin{itemize}
\item pure observation: what can be determined from the observation alone, i.e., what can be determined without insight into the mindset of the person observed;
\item judgemental observation\todo{Might need better term, to contrast with pure observation.}: any additional data that is an inference by the observer – observing someone \enquote{waiting impatiently for the train door to open} is ascribing feelings to the person observe which, by their nature, are hidden from the observer. 
\end{itemize}

You may, of course, say that impatience is observable – and, indeed, it might be a valid inference from a statement such as \enquote{Finally, the train has arrived!}. The double–entry notebook allows such inferences into the mindset of the person observed – as well as other value judgements on their demeanour – so that another researcher reading your notes on observation can clearly differentiate direct observations from such inferences. You do not lose the ability to infer with a double-entry notebook.\todo{Source \cite[p.~161]{driscoll2011introduction}.} 



\ResGenExtras{observations}{daston2011introduction,marvasti2014analysing,simpson2003using,driscoll2011introduction,angrosino2003observations,sapsford1996data}

\subsection{Interviews}\label{sect:DG:sampling}

\ResGenTechnique{interviews}


Interviews\todo{[This section ADAPTED from \url{https://blog.scrintal.com/the-complete-guide-to-conducting-research-interviews-7a0027d02e0a}]
} are a versatile tool for generating data from participants by asking questions and recording detailed answers. Factors to consider in Interviewing including ensuring that you have chosen appropriately those that will take part, the questions you will ask and their structure, the tools that you need to take full value from the data generation, and how you will followup. 

The personal approach that is a characteristics of interviews means that they are a great way of accessing a (group of) individuals' feelings, thoughts, ideas, and/or experiences, data that can be difficult to generate in other ways. They can also provide direction for new research by giving expert indications of where problems lie in a particular domain. As such, interviews can often be used as a way into a discipline, filling in useful background through personal experiences, and having access to otherwise difficult to access information. 

Interviews do not need to be co-located – a video or audio link is all that is needed – but they do need to be in real-time, so that you must 

\subsubsection{Interview Tools}

There are three main kinds of research interviews.

\paragraph{The structured interview} The structure of a structured interview serves as a repeatable framework by which each participant can be asked the same questions in the same way. There is no scope for deviation from the structure, so that auxiliary questions and follow-ups are not used.

Structured interviews are the closest to being time bounded and predictable; if you only have 8 hours to conduct 24 interviews for instance, a structured interview would be the best way to achieve this. 

Your skills as an interviewer will be tested by structured interviews: it is often difficult not to stray outside of the structure when an interesting answer is given, and you may have to cut a participant short if their answers overrun or diverge from the structure\footnote{In our experience, this is a perennial problem, so don't underestimate the difficulties you will face as an interviewer.}.

\paragraph{The semi-structured interview} The structure of s semi-structured interview serves to identify areas of interest to the researcher, with interesting responses being welcomed and followed up if appropriate. Interviewing a domain expert on your chosen topic would be well-served by the semi-structured interview as their expert knowledge could be probed with follow up questions.

The semi-structured interview does not naturally time-bound the interaction, and so – if you don't have unbounded amounts of time – you will have to balance the breadth of questions with the depth of responses.


\paragraph{The unstructured interview} Although the interview may begin with the same question each time, there is no structure to constrain the route through the data that the participant wishes to take. The unstructured interview requires the least domain knowledge of the interviewer as the direction can wholly be given by the participant, but retaining forward motion and focus can be a challenge.

\subsubsection{Workflow}

Your characteristics will determine whether you choose structure, semi-structured, or the unstructured form. Essentially, if you:
%
\begin{itemize}
\item already have a good level of domain knowledge then you can use on the less structured interview models, as you will be able to follow your participants' answers more easily and direct their comments towards your research areas\footnote{Of course, you can always use structured interviews even if you do have domain knowledge – there's nothing to stop you.}. If you don't already have a good level of domain knowledge, then you will be putting more effort into the design of the interview, so that you can simply capture your participants' responses to your – well-designed – questions. 
\item need deep insight then, again, you should use the less structured interview forms as these can allow you to probe your participants responses\footnote{The less structured interview form you choose, the more domain knowledge you'll need. See the previous item.}.
\item more here...
\end{itemize}
%

Your next step is to identify whom to interview – see the section on sampling above for guidance.

\paragraph{Additional guidance} the number of participants in your interviews can not usually be predetermined: in the perfect case, you should interview until the responses you are receiving are \enquote{guessable}\footnote{I.e., you no longer get novel answers to your questions, indicating that the topic has been covered.}. Of course, you will most likely have:
%
\begin{enumerate*}[label={\roman*)}]
\item limited time to complete your data gathering;
\item a small population, so that you can interview everyone of interest;
\item other constraints???
\end{enumerate*}
%

Having decided on the participants, you should contact them. Your university may have strict guidelines on how to approach and work with interviews which you should investigate as a matter of urgency\footnote{It's a surefire way of failing a research module, not following university requirements.}. They're certain to contain issues around GDPR, informed consent, ethical guidelines, and the like.

\begin{question}[subtitle={Activity: Regs}]

\begin{guidance}
TBD
\end{guidance}
\end{question}

%\todo{From \url{https://blog.scrintal.com/the-complete-guide-to-conducting-research-interviews-7a0027d02e0a}.}
%\begin{itemize}
%\item Who you are
%\item The aim of your research
%\item What your research is about
%\item Why you are doing interviews
%\item How the interview data will be stored
%\item How the data and information collected will be used
%\end{itemize}
%


\paragraph{Before your interviews}

Prepare a draft of the questions you intend to ask. Find a friendly test subject for your questions and do a dummy run of your interview. Use their feedback to improve your list of questions:
%
\begin{itemize}
\item did you put the participant at ease during the questionnaire: if not their nervousness might influence their ability to contribute;
\item which questions worked well: i.e., they led to useful responses;
\item which questions were confusing or led to unhelpful answers: in which case do you need only to reword them – perhaps with the help of your participant\footnote{\enquote{I would have asked it this way}...}, by having alternative versions of the questions, or by removing or replacing the question.
\item (if time constrained) which questions overran: can you rephrased the question to be less \enquote{open}?
\item (if structured) were you able to keep to your \enquote{script}: how will you resist the temptation to problem more deeply? Or do you need to consider moving to a semi-structured or unstructured form?
\item did you remember to record the answers in a useful form? Were you writing notes – if so did you capture everything of interest?\footnote{Longhand notes can be taken at 35 words per minute; spoken text is often as fast as 120 words per minute.} Did you audio-record the interview? Did the recording equipment work well? Is there another way of getting a transcript?
\item are the questions in a logical order? Were they grouped by topic? Did they build responses in the most productive way?
\item are there other questions you should have asked?
\item other?
\end{itemize}
%

Repeat this with as many willing participants as you can until you're happy with the interview format\footnote{Or until you run out of willing participants, or time! Make sure that you do not dip into your target population for these preliminaries.}. Then run this form past your supervisor – they will be sure to have comments, perhaps from a more researcher perspective.

\subsubsection{Other things to think about}

\paragraph{Where will you hold the interview} you will need to ensure that you have an appropriately comfortable venue for your interview which, if to be colocated with your participant, access to comfort facilities. Public spaces – where you could share a coffee, for instance – may create a more immediate feeling of intimacy, and so deeper responses, but background noise might interfere with your record keeping., so make sure to check the venue out at the appropriate time of day to ensure a recording device can handle any difficulties.

\paragraph{Protecting your data} What would happen if your audio recording device went wrong? Would you have a backup or the interview? What if you forgot to turn it on?\footnote{Which has been known to happen?} Write a checklist of instructions for yourself to follow before and after each interview, so that you can be sure not to miss anything important. This checklist should include any permission issues, such as permission to record the interview. 

\paragraph{Being a good interviewer} Try, to the extent possible, given the format,  to allow your participant to govern the speed and direction of the interview. Allow them to talk in complete sentences without interruption, or have a good reason to interrupt. If you need to interrupt, apologise for doing so and tell them the reason why you have done so\footnote{\enquote{I'm sorry to have to interrupt, but we only have 5 minutes left and ...}.}. Be polite and encouraging, as your participant might be nervous.

\paragraph{At the end of the interview} Say what will happen next. Perhaps share a sheet which describes the research you are doing\footnote{Or do this at the beginning, if you are willing to give the participant time to read it as part of the interview.}


\ResGenExtras{interviews}{[C13]{oates2008researching}[p43]{johannesson2014research}[p194]{secor2010social}[p250]{hays2003case}{mcclure2002common}[p52]{peoples2020write}[6397]{jorgensen2001grounded}[]{hycner1985some,englander2012interview,ramsook2018methodological}{robertson2002automated}[C4]{kielmann2012introduction}}


\subsection{Journalling}\label{sect:DG:journalling}\todo{This section currently adapted from \cite{hayman2012journaling}.}

\ResGenTechnique{Journalling}

Journalling asks research participants to record and reflect on research-focussed experiences as \textcquote{hayman2012journaling}{a way of thinking, understanding, and learning.} One popular use of journalling is as a learning strategy for research participants, as so is often located in ethnographic research, or in data generation for grounded theory. The researcher is interested in the ability of journalling to expose elements and processes involved in deep learning, problem solving, critical thinking development, and reasoning.

%%
%\begin{itemize}
%
%\item by the researcher, as a way of recording and reflecting on the practice of research, \emph{as the research progresses}, and so may also feed into subsequent episodes of reflexivity\footnote{See below.}.
%\end{itemize}
%%

\subsubsection{Journalling tools}

\todo{Add something here}

\subsubsection{Workflow}

%The two uses of journaling lead to two related but different workflows.
%
%\paragraph{For research participants}
%
Journaling\todo{Adapted from~\textcite{giguere2012self-reflective}.} or \emph{self-reflective writing} can help research participants to reconstruct their thoughts from an activity or situation, indicating how they develop over time.

The structure of a self-reflective portfolio should include 
%
\begin{itemize}
\item goals of the reflection: established once at the beginning of the journaling exercise
\item journaling entries contributed by participants: the use of these is to help the participant reconstruct their thoughts and development from the research exercise. To ensure that the researcher goal of the journal is approached, the researcher should develop journaling prompts. They can be broader or narrower in scope, and guide the focus of the participant onto journal entries that will be useful for the research goals.

There are three identified challenges for journalling \parencite{hayman2012journaling}:
%
\begin{enumerate}%[start=0,label={(\bfseries R\arabic*):}]
\item poor participation: as a researcher, you want to collect as rich a journal from each participant as possible. To assist in this goal, any guidance provided should be sincere, nonjudgmental, and conversational.
\item feeling exposed: a participant may feel vulnerable or anxious documenting \enquote{sometimes intimate details of their lives} or by a perceived lack of writing skills. 

One method of allaying fears associated with journaling is to provide clear instructions, identify specific objectives, and provide ongoing support and guidance~\cite{taylor2006research}.
\item staying on track: Journaling \enquote{momentum} of the participant should be monitored, if possible, during the research process. A participant that becomes distracted or demotivated might be helped to refocus their efforts through restatement of the research goal, with prompts repeated as necessary.
\end{enumerate}
\end{itemize}

\subsubsection{Other things to think about}

\newcommand{\ed}[0]{Ed}

\ResGenExtras{journalling}{[\ed]{kadarisman2017classroom}[]{burns2009action}[p55]{peoples2020write}[]{feinblum2016journaling}[]{hayman2012journaling}{mcgrath202115}[\ed]{ovens2020weaving}}

\subsection{Questionnaires}\label{sect:questionnaireDesign}

\ResGenTechnique{questionnaires}

Questionnaires\footnote{Questionnaires are just one in a rich collection of \emph{survey tools}, others of which are described below.} are versatile tools for generating data from participants by asking questions\footnote{There's a hint in the name – \emph{question}naire – although why two \enquote{n}s; does no millionaire, billionaire, or debonaire use them?}. Questionnaires allow a researcher to characterise a population\todo{Why population here?} of interest by collecting participants' answers about their attitudes, preferences, opinions, behaviours, etc. You might use a questionnaire as a way of collecting statistically significant responses from a population sample, but there are other uses as well.%the basis of a large survey\todo{Should survey have been introduced at this point?}.

%, or to conduct some interviews or focus groups. %Whatever their use, you need to put some thought into your questionnaire design.

If you do use a questionnaire, its thoughtful design is of critical importance. Otherwise, you might be asking your (willing) sample to spend a considerable amount of their valuable time answering questions the content of which are not helpful for your research. As they might not be so willing to help a second time, getting the questions right\footnote{Often called \emph{questionnaire design}, although this conjures up glossy format and whizzy web-pages which is of secondary importance. Unless, your questionnaire is about the design of questionnaires, of course.} the first time is important. 

Administering questionnaires are nowhere near as difficult as they used to be as the number of online resources for doing so increases. And, probably because of this, there are plenty of resources in the literature and online to help you design your questions.%\footnote{Check out the following resources: \cites{}.} 
Their descriptions can be a little technical, however, so the following glossary and other tough points might help you engage with them better.

\paragraph{Essential questions} %You should identify 
the smallest possible set of questions you absolutely need to ask to address your research aim and objectives. While using several questions will give you richer data sets, long questionnaires tend to put people off, so that fewer people may be willing to participate. 

\paragraph{Profiling questions} %These are 
questions tat ensure your respondents match specific characteristics you are interested in: say, you are studying the usability of a new product, then you will need to know the extent your respondents have engaged with that product. This is particularly the case if you are running a large survey and don't know who is going to respond.  

\paragraph{Demographic questions} %These are 
often used so that you can then compare answers across different sub-groups, say, based on gender, age or ethnicity, etc.

\paragraph{Language} questions should be clear and plain, and you should avoid jargon and idioms, to ensure your participants understand what you are asking, particularly if not native speakers. Your questions should also be objectives, that is you should avoid any judgemental term or tone, which may lead participants to answer in a particular way, or make assumptions about your respondents' habits or behaviours: for instance, asking participants what they eat for breakfast, assumes they all take breakfast, which may not be the case.

\paragraph{Double-barrelled questions} also termed \enquote{compound}, these are questions that ask more than one thing, while only allowing one answer. These should be avoided as it would be difficult, if not impossible, to establish in your analysis which part of the question each participant has answered. Instead, you should split the question into separate questions each addressing a specific thing.

\paragraph{Response options} questions are broadly divided into \emph{closed} and \emph{open}-ended. Close questions restrict the possible responses to a set of given choices, while open questions allow respondents to use their own words freely to answer the question. If you use closed questions you should ensure that the possible answers cover all possible options\footnote{Or, at least those you're interested in.} and exclusive, in the sense they don't overlap. Open questions can lead to richer answers, but you must ensure they are sufficiently constrained so that the answers don't end up being without value by being, for instance, vague or off topic. 

\paragraph{Scales} if your questions require participants to estimate or measure something, you need to worry about both validity and reliability when setting up the scales for possible answers. Validity means that the chosen scale should allow respondents to measure something accurately; while reliability means that, under the same conditions, respondents will be able to measure something consistently.\todo{This might need rephrasing, as questionnaire weakness?}

\paragraph{Question grouping, ordering and flow} related questions\footnote{For instance, those intended to establish a demographic of respondents.} should be grouped together, and the flow between groups of questions should be logical. Question order in each group also matters: as a rule of thumb, simpler questions should precede more complex ones.

\subsubsection{Tools for creating (maintaining, and analysing) questionnaires} 

While you can design your questionnaires from scratch using your word processor, there are plenty of specialised digital tools, many of which are free, that can make it a lot easier\footnote{Examples include: {\color{red}add list here and URLs.}}. They usually come with: templates and pre-defined question types that you can customise for your study; statistical analysis and data visualisation features that you can apply to the data you have collected; export functions that allow you to save the data to a spreadsheet for further analysis. Overall, if you need to develop questionnaires for your research, they can really help you speed up the process, so that it's well-worth the investment of time in climbing their learning curve. 

\subsubsection{A simple questionnaire design workflow}\todo{More here?}

Following the guidelines above, for the order and content of questions, it's very easy to complete a first draft of a questionnaire. Unless you have many years of experience in questionnaire design, your first draft will be far from suitable. Indeed, releasing your first draft without further thought may lead to you not only gathering no useful data from it, but also p-ing off your audience sufficiently that they are not willing even to look at your second version.

So, once you have a first draft of your questionnaire, you should test it and refine it. 

%This will help you identify issues in relation to any of the points we have just discussed, and avoid wasting time and resources by employing a poorly designed questionnaire in your study. 

Early testing can be done by asking a friend, a family member\footnote{Probably, but not always a friend:)}, or a colleague to work through the questions, provide their answers and any other feedback they might have. This will give you early indications of problems with your questionnaire\footnote{Although it's sometimes difficult, you'll make more progress and quicker if you think of the questionnaire as imperfect, rather than you. You can then apply comments – even if they are negative – to the questionnaire rather than having a personal emotional reaction to them. For each comment, make sure you understand how it can be addressed in your questionnaire. This last tip also means that you can welcome (but ignore) comments that can't be addressed.}. Later in the process of designing it, however, you should take expert advice including, of course, that of your supervisor, to get to the final agreed form. 

In addition, you could pilot your questionnaire on a small number of respondents first, then revise it as necessary before using it more widely. 

In all cases, you are looking for evidence that there are issues, including confusion – which may point to a lack of clarity in the questions – or hesitation\todo{How can you check this with a non-colocated sample? Does this not need to go earlier?} – which may point to a poor choice of response options or to inappropriate scales – or disengagement – which may point to too many questions being asked – may have occurred. 

Be sure to loop back to those that have helped you to check that you have addressed their comments. 

\todo{ADD Extra reading}

\begin{question}[subtitle={Activity: Improving your questionnaire design}]
Assuming your study requires you to use a questionnaire to collect data, consider each of the points above in relation to your draft questionnaire, making improvements whenever required.
\begin{guidance}
You can skip this activity if questionnaires are not relevant to your project. Reflecting on each of the points will help you avoid common mistakes and improve your questionnaire design. 
\end{guidance}
\end{question}

\ResGenExtras{questionnaires}{[\nopp C14]{oates2008researching}[p250]{hays2003case}{burns2009action,mcclure2002common}{najafi2016observation}{robertson2002automated}[C6]{kielmann2012introduction}}

\subsection{Documents}

\ResGenTechnique{documents}

As a researcher, documents – in the form of academic articles – will already occupy a large proportion of your time/brain/computer. Your collection of academic papers could currently be as many as 50 or more. You will, therefore, already have good experience of interacting with documents and those interactions may well have been productive. 

Other documents can also be used as primary research vehicles when used a part of a research strategy. In this sense, documents%Adapted \todo{AI summary}
\footnote{Main sources: \cites[freely available as part of SAGE handbook]{coffey2014analysing}[electronically available through library]{finnegan2006using}.} are written records or figures produced as a by-product of the operation of an organisation, or part thereof. They will typically consist of literary, textual, or visual devices that enable organisational information to be shared and stories to be presented. They are social artefacts created for a particular purpose, crafted according to social conventions that apply at the time and place of writing, and can be used directly for their factual content or indirectly to uncover what they reveal about the writer or as examples of a specific form of presentation. 

Documents can be in various forms such as words/text, pictures, or audio, and are stored on physical carriers like paper, stone, or microfiche. They have narrative structure, imposed by the writer, have cultural ways of telling, in a particular style, structure, and language. They also employ visual signs, literary devices, and symbols to present and display meaning. Documents are rarely produced and read in isolation and are often related to other texts, allowing for exploration of relationships and meanings within a text and in relation to other documents.

\subsubsection{Document tools}

The way in which you interact with documents will lead you more or less quickly to success of your document review at the end of which you should have a good feeling of the relationship between documents, their formal properties, and rhetorical features.

Researchers use documentary sources to collect and analyse data. To do this, a researcher will interact with them either \emph{directly} or \emph{indirectly}:
%
\begin{description}
\item[direct] in which a document is analysed for its factual content: the data it describes;
\item [indirect] in which a document is analysed for the data it contains
\end{description}

The difference between these two modes may not be clear. An example might help. This is a copy of a passage from \textcite{fynes1873the-miners}:
%
\blockquote{Miner :– I believe you have something like 150 collieries to inspect?

Mr.~Dunn :– Yes.

Miner :– Twenty-eight in Cumberland?

Mr.~Dunn :– Yes.

Miner :– Do you think you are able to inspect all these? 

Mr.~Dunn :– Well, the Government thinks I am able, you know.

Another Miner :– Were you satisfied with the one shaft at this colliery, if so there is an end to the matter; if not, what steps did you take to remedy the defect? Did you apply to the Secretary of State, showing him that it was defective?

Mr.~Dunn :– At this very moment there are three of the largest collieries in Northumberland – Seaton Delaval, North Seaton, and Newsham – managed by the most talented men in Northumberland, all with single shafts. Now, what would you have me to do? Do you think it is my duty to call in question the management of these pits?

Miner :– Am I to understand this is an answer to my question?

Mr.~Dunn :– Well, I am not so well satisfied as if they had two, but I have not the power to alter it.}

Here, a direct reading could be to identify collieries in which a single shaft existed at that time. An indirect reading could be to explore social relationships in the 18th century.
%

In more detail, indirect and direct reading use the following techniques to classify and conceptualise documents for qualitative research:
\begin{itemize}
\item Studying the form, content, and function of documents
\item Analysing the ways in which documents justify decisions, display hierarchies, and exercise agency
\item Distinguishing between primary sources (documents providing raw data) and secondary sources (documents providing information about primary sources)
\end{itemize}

\subsubsection{Workflow}

As we have already mentioned, direct interaction with documents is already something with which you are\footnote{Or, should be!} familiar. However, according to \textcite[p.~370]{coffey2014analysing}\footnote{Freely available from \citeurl{coffey2014analysing}.}, a good place to start in analysing documents is with the realisation that documents are \enquote{socially defined, produced, and consumed} so that, alongside the content, the processes by which a document is produced and is intended to be consumed, i.e., by which it becomes an \enquote{accomplishment} for some individual or organisation, often contain useful data.

In this case, there are many approaches possible from the simplest – counting instances, for instance, of words, phrases, or other elements\footnote{\textcite{mckenzie1959shakespearian}, for instance, counts commas – as well as other punctuation – in Shakespear's \emph{First Folio} to help identify which compositors were responsible for which parts of it.} – and indexing and coding document elements to identify thematic content and identify patterns, ala \textcite{schreier2014qualitative}. 

\citeauthor{schreier2014qualitative}'s approach, a type of the more formal \emph{qualitative content analysis}, involves the selection of material from a wide range of source with adequate coverage for the topic of interest. As such it can result ing large amounts of material to analyse and so an element of formal in the process is mandated. An important step in this is the building of a \emph{coding frame}, i.e., a structure consisting of \emph{main category} and two \emph{sub-categories}~\parencite{schreier2014qualitative}:
%
\begin{itemize}
\item a main category\footnote{Coding frames with more than 40 main categories are known to be difficult for one person to handle at one time.} being those aspects of the material that interest the researcher, 
\item a subcategory being what is said in the material with respect to a main categories.
\end{itemize}

\paragraph{Material selection} It is important to choose material that covers all types of data and data sources in the proposed study. The material should be selected in a way that allows the majority of categories in the coding frame to be applied during the analysis. Once material has been selected, \textcite{schreier2014qualitative} recommends breaking down the material into smaller \enquote{chunks} and build the coding frame for one \emph{chunk} at a time\todo{The process described by Schreier is circular and will need linearising to make better sense}.

\paragraph{Pilot phase} is where the current draft of the coding frames categories and subcategories are tested and refined. After selecting and preparing an appropriate subset of the selected texts\footnote{This being one that will populate all categories and allow exploration of the subcategories.}, trials of the encoding.

\paragraph{Coding for keeps} once you're convinced that your coding frame is stable, you then apply it to \emph{all} documents. This will involve:
%
\begin{itemize}
\item  paying attention to how documents are constructed as distinctive artefacts, their structure, vocabulary, level of formality, etc. \parencite[p.~5]{coffey2014analysing}
\item analysing their form and content, considering how they were produced and how they were – and how they were intended to be – consumed
\item considering the relationships \emph{between} documents, highlighting dimensions of similarity, comparison, contrast, and difference by tracing how texts refer to other texts, sharing conventional formats, and constructing a uniform style\footnote{This scaled \emph{Intertextuality} in the literature~\parencite[p.~8]{coffey2014analysing}; it's akin to how you went about analysing the academic literature as part of your literature survey.}
\item exploring the ways in which they function and are used in everyday life and social context
\item examine their formal properties, including their linguistic registers, and rhetorical features.
\end{itemize}

\paragraph{Presenting your findings} can be as simple as delivering the statistics that you have collected as the basis for further analysis. Alternatively, a completed coding frame  with an accompanying narrative and example quotes as needed could be the output. Like other data, your coding frame can also be the starting point of further data generation and analysis, \textcquote{schreier2014qualitative}{examining the results [...] for patterns and co-occurrences of selected categories.}

\subsubsection{Other things to think about}

When\todo{AI} analysing documents, it is important to consider the form and function of the documents themselves. Instead of focusing on whether a document is 'true' or 'valid' evidence, one should examine the formal properties and rhetorical features of texts. Documents should be analysed in relation to their production and consumption, as well as their intertextuality and relationships with other documents. It is also crucial to understand how documents function in everyday life and social contexts.


\ResGenExtras{documents}{coffey2014analysing,schreier2014qualitative}

\subsection{Focus groups}

\ResGenTechnique{focus groups}

\subsubsection{Focus group tools}

\subsubsection{Workflow}

\subsubsection{Other things to think about}


\ResGenExtras{focus groups}{}

\subsection{Field work}

\ResGenTechnique{field work}

\subsubsection{Field work tools}

\subsubsection{Workflow}

\subsubsection{Other things to think about}



\ResGenExtras{field work}{}

\subsection{Computational thinking}

\citeauthor{wing2006computational}\footnote{\citeauthor{wing2006computational} is American, and so uses American spelling – -i\textit{z}i-, art\textit{i}fact, etc.}, in her introduction to Computational Thinking, said this about computational thinking:

\noindent\emph{Computational thinking} [...] has the following characteristics:
%
\begin{description}
\item [Conceptualizing, not programming.] Computer science is not computer programming. Thinking like a computer scientist means more than being able to program a computer. It requires thinking at multiple levels of abstraction; 
%
\item[Fundamental, not rote skill.] A fundamental skill is something every human being must know to function in modern society. Rote means a mechanical routine. Ironically, not until computer science solves the AI Grand Challenge of making computers think like humans will thinking be rote; 
%
\item [A way that humans, not computers, think.] Computational thinking is a way humans solve problems; it is not trying to get humans to think like computers. Computers are dull and boring; humans are clever and imaginative. We humans make computers exciting. Equipped with computing devices, we use our cleverness to tackle problems we would not dare take on before the age of computing and build systems with functionality limited only by our imaginations; 
%
\item [Complements and combines mathematical and engineering thinking.] Computer science inherently draws on mathematical thinking, given that, like all sciences, its formal foundations rest on mathematics. Computer science inherently draws on engineering thinking, given that we build systems that interact with the real world. The constraints of the underlying computing device force computer scientists to think computationally, not just mathematically. Being free to build virtual worlds enables us to engineer systems beyond the physical world; 
%
\item [Ideas, not artifacts.] It's not just the software and hardware artifacts we produce that will be physically present everywhere and touch our lives all the time, it will be the computational concepts we use to approach and solve problems, manage our daily lives, and communicate and interact with other people; and 
%
\item [For everyone, everywhere.] Computational thinking will be a reality when it is so integral to human endeavors it disappears as an explicit philosophy.
\end{description}

\ResGenTechnique{computation thinking}

The techniques generally associated with computational thinking are:
%
\begin{itemize}
\item Decomposition: breaking a problem into parts that are easier to solve;
\item Pattern recognition \& Generalisation: seeking significance from repeated structures within data
\item Abstraction: building higher level representations of things
\item Algorithms: associating behaviours with computational structure
\item Evaluation: called testing for software, but also has wider applicability when an algorithm is socialised.
\end{itemize}

\subsubsection{Computational thinking tools}

Given the explosive growth in the use of computers over the past half century, you may not be surprised to hear that there are thousands of useful\footnote{As well as some that are less than useful!} computer tools to support computational thinking. Fortunately, for the vast majority of these, they support one or more computational models, which are the bases of computational thinking. Those computational models fit into the following categories

%
\begin{itemize}
\item computational mode: sequential, concurrent, agent based. Example tools: flowcharts, UML, Petri Nets,\footnote{Computational modes tend to be packaged for use, so – although the basis of a computational mode might be concurrent, you would not have to deal with the intricacies of modelling in, say, Petri nets. Unless, of course, your intention was to investigate their properties.}
\item computational paradigm: imperative, declarative. Examples: procedural, object oriented; logical, functional, reactive; etc. 
\item language: machine, low-level, high level, interpreted: machine code, C, Swift, Python.
%\item structural model: UML, \todo{reconsider?}
\item developmental process: lying on a continuum between plan-driven and micro-iterative
\item requirements form: functional, non-functional, structural,
\item data structure: database, spreadsheet, json, etc.
\item delivery platform: web, package, snippet, \todo{more here}
%\item delivery mechanism: 
\item maintenance mechanism: GitHub, 
\item language libraries: React, Ruby on Rails, etc.\footnote{Language libraries tend to come into and go out of date regularly as new paradigms of delivery are created and superseded.}
\end{itemize}

\subsubsection{Workflow}

The main idea behind computational thinking is to link a wished-for behaviour to a computational structure. Here, we're thinking of the wished for behaviours of a client in context being translated to an algorithm, data model, or other computational element. 

The ways in which the wished-for behaviour of a client in context are understood is through the discipline of requirements analysis. Although naive requirements analysis is possible for simple projects – asking a client what functional behaviours they need – it is more often driven by the explicit or implicit management or developmental risk, the risks being those of 
%
\begin{itemize}
\item misunderstanding the context of deployment – where the final system will be installed
\item misunderstanding the problem that is to be solved – what functional and non-functional behaviour is wished-for
\item misunderstanding the solution space – what technologies can be employed within the context and how they should integrate with human elements of the system
\item misunderstanding of the change path by which any current system will become the new system
\item misunderstanding the process needs for developing and delivering the system
\item {} [more here]
\end{itemize}
%
\subsubsection{Other things to think about}

If you don't have experience with programming languages, then you can learn, but the learning curve can be very steep\footnote{This video will give you some idea of what will be required: https://www.youtube.com/watch?v=fLMZAHyrpyo. Stephen Wolfram is a particularly interesting, if restless, speaker, and a leader in this area.}\todo{But this isn't a great video, nor is any other that I've looked at, as they're created by computer scientists... They're also heavily advertise-ful.}. Engaging with clients as stakeholders in a development can also be challenging, in that it makes great demands on both parties time – there can be a great deal of iteration needed to get to a form where the client needs can be satisfied.

\ResGenExtras{computation thinking}{}

\subsection{Mathematical thinking}

\ResGenTechnique{mathematical thinking}

\todo{[More here]}

\subsubsection{Mathematical thinking tools}

\subsubsection{Workflow}

\subsubsection{Other things to think about}

\ResGenExtras{mathematical thinking}{}

\subsection{Statistical thinking}

\subsubsection{Statistical thinking tools}

\ResGenTechnique{statistical thinking}

\subsubsection{Workflow}

\subsubsection{Other things to think about}

\ResGenExtras{statistical thinking}{}

\subsection{Reflexivity}

\ResGenTechnique{reflexivity}

\subsubsection{Reflexivity tools}

\subsubsection{Workflow}

\subsubsection{Other things to think about}

\ResGenExtras{reflexivity}{}

\section{Sampling: what, who (and how) to choose}\label{sect:DG:sampling}

A core prelude to many of the data generating techniques introduced above is to choose the data source. You've already had experience of doing this when you conducted your literature search as part of Stage~\ref{stage:?}\footnote{You might remember the relatively complex procedures for recording search terms, discovered papers, their relationships, and your growing collection of notes on them.}. \todo{More here} 

Unless you had infinite amounts of time – which you didn't – and infinite patience – which you might have – you could never be 100\% certain that your literature search collected \emph{all} relevant papers  the search space is infeasibly large (and not indexed particularly well). But you were systematic and achieved a practically good\footnote{By \emph{practically good}, we mean you found the most of the most important papers, some other papers, and didn't have to read \emph{every single paper}. I.e., you found a \emph{representative sample}.} coverage because of that.\todo{More here?}

Sampling is the process of selecting a subset\footnote{We could have said \enquote{sample} but that would have been circular.} of an infeasibly large population of interest, and is used in the research strategies\todo{Update given Stage 3.} that work by estimating or predicting the properties of that population. %, for instance, survey (who will fill in your questionnaire) or experimental (who will take part in your experiment) research. 

Sampling can either be random or non-random. 

In \emph{random sampling}\footnote{Random sampling is also called \emph{probability sampling}.} some unbiased way of choosing, before the fact, subset members from the population, while in \emph{non-random sampling}\footnote{Non-random sampling is also called \emph{non-probability sampling}.}, the choice is based on a researcher's judgement and discretion and can be added to as the research progresses. The lack of bias in the former means that results tend to generalise from the sample to the population. The potential for bias in the latter means that results may not generalise, but things of interest, of depth, and of richness can be followed as they are discovered. As a result, the former is used more in quantitative research, and the latter in qualitative research\todo{Reword to separate the two?}. %Also, in quantitative research the tendency is to choose the sample upfront, before any analysis commences, while in qualitative research, the process is iterative, with more and more sample data collected and analysed until no more collection is possible or \textit{saturation} is reached, that is collecting more data would not bring more relevant information.

Random sampling techniques include:
\begin{description}

	\item [simple random sampling] where each member of the population has exactly the same chance to be selected. It is easy and efficient to implement, and given the complete randomness of the sample, generalisation is fairly reliable. However, if the population has large sub-groups, these may be over-represented in the sample, with minority groups being under-represented.\todo{Add strengths and weaknesses.}
	
	\item [stratified random sampling] where sub-groups of the population are identified based on common characteristics, the \textit{strata}, and sampling is random across those strata. The strata are not mutually exclusive: for instance, the population may have sub-groups defined by gender, ethnicity and level of education, which may overlap. This approach overcomes the over/under representation problem of simple random sampling.\todo{Add strengths and weaknesses.}
	
	\item [cluster sampling] where the population is divided up in naturally occurring separate clusters, and the sample is obtained by randomly selecting some clusters and then randomly selecting members of those clusters. It is more cost-efficient than the other two approaches, but can introduce bias if the selected clusters are not representative of the whole population, so that the over/under representation problem remains.\todo{Add strengths and weaknesses.}
\end{description}

%%Candidate for moving to chapter preload

Non-random sampling techniques include:
\begin{description}
	\item [purposive sampling] in which participants are selected by the researcher based on particular characteristics, knowledge, or expertise they have. It is often used for small populations, especially rare populations which may otherwise be difficult to access\todo{Clarify}. Purposive sampling is particularly suited to studies which intend to be deep and narrow, and for which subsequent generalisation back to the parent population is not a concern. As the sample choice is made by the researcher, it is prone to bias.\todo{Add other strengths and weaknesses, or perhaps the weakness is with the class rathe than the instance?}

	\item [convenience sampling] where participants are selected based on their availability or accessibility. This is quick and easy, but unlikely to produce a representative sample, so, once again, bias is an issue.\todo{Add other strengths and weaknesses.}
	
	\item [snowball sampling] which relies on referral from previous participants to recruit new ones. This is an effective approach when a population is difficult to access or when the topic is sensitive or tabu. This too is unlikely to generate a representative sample, and is prone to bias.\todo{Add other strengths and weaknesses.}
\end{description}

\begin{question}[subtitle={Activity: Deep reading on Non-Random Sampling}]
Check back to your choice of research strategy. If you've chosen one that uses non-random sampling, then you should read the following sources for more details \cites{}	
\end{question}

In summary, when choosing a sample, you need to consider various factors, including the aim of your study, the kind of methods you are applying, and the level of access you may have. Trade-offs are likely involved and you may not be able to obtain an ideal sample. Nevertheless, your sample will still be useful to your research, as long as you clearly explain and justify how it was obtained and what its limitations are.

\begin{question}[subtitle={Activity: Choosing your sampling approach}]
Assuming your study requires you to perform some sampling, write down the approach you are going to take, with its justification in terms of what is needed to address your aim and objectives, and any trade-offs due to the practicality of accessing the sample. Record any possible weakness or limitation of your chosen approach.
\begin{guidance}
You can skip this activity if sampling is not indicated by your choice of research strategy.
\end{guidance}
\end{question}

\todo{Add other core techniques here; which are there?}

\section{Managing your raw data}

Your chosen research strategy may require you to generate data of many kinds and from many sources. The amount of data you collect could be a few ideas or a mound of documents, from a few to terabytes of data\footnote{One project we know of collected ???}. 

%If, for instance, you conduct experimental research, you will have data about your subjects, perhaps collected through questionnaires, and variables of interest, with their measurements. If you use interviews or focus groups, you may have audio or video recordings and their transcripts, or notes you have taken. For survey research, you will have a large number of responses to the set questions. If you use existing secondary evidence, for instance as part of case study research, then you will have all sort of documents, from reports to images, diagrams, etc.: from such documents, you will need to extract relevant raw data for your analysis.

Before proceeding with your data analysis, you must ensure your data are properly organised and stored, so that you don't loose track of important information, and you can easily locate and refer back to appropriate data during your analysis and when writing up your research – you might need to include a representative sample of your raw data in an appendix of your dissertation as evidence of your data generation, for instance, identifying which sample can take some time if done afterward while it can be immediate if done while.  

Although techniques for doing so are outside of the scope of this book, your data storage should be secured against data loss either due to technical issues, such as computer failure, or due to a data breach, such as through hackers, at least to the standards required by law, any additional requirements made by your organisation, those of any participants, their organisations, and any other stakeholders\footnote{Once upon a time, in a galaxy far, far away, data generation and storage used to be a \emph{laissez-faire} thing. Today, your organisation can be fined vast amounts of money for any data misuse, so they tend to take it more seriously. If data loss were to happen, amongst other things, it'd probably means you'll fail your degree.}.

\todo{Can we point to needed safeguards rather than trying to be complete (and culpable) here? If so, revise below.}

%is regularly backed up, not to risk loosing it, and, if you collect any personal information, your data, whether physical or digital, must be stored securely to comply with data protection\footnote{See Section~\ref{sect:personalData}.} regulations.
%
It is also important that you put your raw data in a form which is useable for analysis. Spreadsheets are particularly useful for this purpose, especially if your data is quantitative, so that this is a common way to organise and store raw data. In fact, most publicly available data sets used in research and beyond are stored as spreadsheet files: if you are going to use one such data set, then your raw data are likely already organised for you!  

Spreadsheets organise data in rows and columns, so that you can easily enter your raw data using rows for your observations/measurements and columns for your variables. As we will see later on, spreadsheets come a wide range of functionalities for data manipulation and for some level of data analysis. They are also easily extensible, so that you can grow your data sets incrementally.

\begin{question}[subtitle={Activity: Organising and storing your raw data}]
Consider the data and evidence you have collected or are planning to collect. List the actions you have taken/will need to take in relation to:
\begin{itemize}
	\item organising your raw data
	\item storing and backing up your data
	\item protecting personal data
\end{itemize}
Make sure you complete those actions before moving on to your data analysis.
\end{question}

With your raw data properly organised and stored, you can now proceed to your data analysis\todo{End of \enquote{revise below}}.

****


\section{Common analysis methods}

Your choice of data analysis methods is part of your research design, and relates to the kind of data and evidence you have gathered, and what you are trying to achieve, that is your aim and objectives.

This section provides an introduction to some common analysis methods. It is far from complete and does not go very deeply into the details of each method: entire books have been written on any of them! By studying this section, you won't become an expert in any of these methods, but you will have gained enough understanding to be able to make a judicious selection for your project. After that, you should review the related specialised literature to help you apply your chosen methods appropriately. You should also talk regularly to your supervisor for further guidance.

\subsection{Using tables to analyse data}
The following kinds of tables are used extensively in research and often found in dissertations.

\paragraph{Pivot tables}

Pivot tables can be used to summarise, sort, filter, re-organise or group data organised in rows and columns, and perform calculations on them, such as counting, generating totals or averages, and much more. Pivot tables are both powerful and versatile\footnote{In fact, they are so versatile that we'll only be able to provide few illustrative examples. Much, much more can be found online!}, and one of the most widespread tools for data analysis.

You can generate a pivot table from any data set organised in rows and columns, regardless of whether the values are quantitative or qualitative: all common spreadsheet applications\footnote{From MS Excel to Apple Numbers to Google Sheets.} include this function.

Figure~\ref{fig:exampleDataSet} gives an example: these are the first few raws of a data set related to the US housing market\footnote{It was taken from one of Kaggle's free datasets, the housing price dataset. Kaggle is possibly the largest and best known online community for data science and machine learning.}. The dataset contains over 9,316 entries, each corresponding to a distinct property. Each property is characterised by a number of attributes: size in square feet, number of bedrooms and bathrooms, type of neighbourhood, the year it was built and its market price in US dollars. As you can see, this table includes both numerical and categorical variables.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{Figures/exampleDataSet.pdf}
\caption{First few rows of the example dataset}
\label{fig:exampleDataSet}
\end{figure}

Pivot tables can be used to summarise such data to answer certain questions. For instance, we may be interested in the average house price by neighbourhood and number of bedrooms, which would result in the pivot table in Figure~\ref{fig:pivot1}, which gives the average price of each combination. The `grand totals' in the table are also averages, by row and by column.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{Figures/pivot1.pdf}
\caption{Pivot table of average property prices by neighbourhood and number of bedrooms}
\label{fig:pivot1}
\end{figure}

Alternatively, we may be interested in finding out how many properties of each kind have been built in each neighbourhood. In this case the pivot table would look like that in Figure~\ref{fig:pivot2}. The grand totals in this case are counts. Note how we have added combinations of bedroom and bathroom numbers to characterise each type of property.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{Figures/pivot2.pdf}
\caption{Pivot table of property counts by neighbourhood and number of bedrooms/bathrooms}
\label{fig:pivot2}
\end{figure}

These are just but two examples of questions about the data you can address by using pivot tables, out of a vast range of the possibilities. If your data are organised in tables, then it is well worth spending some time becoming familiar with pivot tables.

\begin{question}[subtitle={Activity: Pivot tables in Excel}] Download the housing price data set from Kaggle and re-create the pivot tables in our example. Come up with other questions you could ask of the data and generate related pivot tables.	
\begin{guidance}
Feel free to use your preferred spreadsheet application for this activity, as long as it supports pivot tables -- most do.

You may have to register with Kaggle to gain access to the data set. 

The Excel Help facility and documentation provides all the info you need to create a pivot table. However, you could also browse some of the very many freely available online resources and tutorials on this topic.
\end{guidance}
\end{question}	


\paragraph{Frequency and contingency tables}
Frequency tables are used to summarise the frequency (or count) of values taken by a categorical variables in a data set. For instance, after studying a degree, a student's outcome may be classed as distinction, merit, pass or fail. A frequency table can then be used to summarise the frequency of each class of outcome for a particular students' cohort, as shown in Table~\ref{tab:frequencyTableExample}.
 
\begin{table}[htbp]
\caption{Example of frequency table\label{tab:frequencyTableExample}}
\small
\begin{tabulary}{\tablewidth}{@{}LLLLL@{}} 
\toprule
  & \textbf{Distinction} & \textbf{Merit} & \textbf{Pass} & \textbf{Fail} \\
\midrule
 \textbf{Outcome} & 12 & 26 & 42 & 5\\
\bottomrule
\end{tabulary}
\end{table}

Contingency tables\footnote{Also known as \textit{cross-tabulation} tables.} are a form of frequency tables used to tabulate the value frequencies of two categorical variables. For instance, following from our previous example, we may like to tabulate the outcome value frequencies in the cohort against gender, as shown in Table~\ref{tab:contingencyTableExample}. 

\begin{table}[htbp]
\caption{Example of contingency table\label{tab:contingencyTableExample}}
\small
\begin{tabulary}{\tablewidth}{@{}LLLLL@{}} 
\toprule
 \textbf{Outcome by Gender} & \textbf{Distinction} & \textbf{Merit} & \textbf{Pass} & \textbf{Fail} \\
\midrule
\textbf{Female} & 7 & 12 & 21 & 2\\
\textbf{Male} & 5 & 13 & 19 & 3\\
\textbf{Other} & 0 & 1 & 2 & 0\\
\midrule
\textbf{Totals} & 12 & 26 & 42 & 5\\
\bottomrule
\end{tabulary}
\end{table}

Contingency tables are frequently used to summarise and analyse data collected in survey research, and are a key tool in statistical analysis.

Both frequency and contingency tables can be generated as pivot tables in a spreadsheet. In fact, the table in Figure~\ref{fig:pivot2} is a contingency table. 

\subsection{Statistical analysis}

Statistical analysis in an umbrella terms for a set of methods which can be applied to numerical and categorical data. More precisely, in statistics data types are classified as:

\begin{itemize}
	\item scalar, which includes all measurements and counts; with reference to the types in Section\ref{sect:evidenceAndData}, these are all numerical data, continuous, discrete, interval and ratio data.
	\item categorical, both ordinal and nominal.
	\end{itemize}

There are two broad categories of statistical methods:
\begin{itemize}
	\item descriptive statistics, whose aim is to describe data; and
	\item inferential statistics, whose aim is to make predictions from data.
\end{itemize}

We briefly consider each in what follows. 

\subsubsection{Descriptive statistics} \label{sect:descriptive}
These are used to describe various attributes of a data set. The basics are:
\begin{itemize}
	\item count, to establish how many entries there are in the data set
	\item centrality, to establish the `centre' of the data set. Three measures are commonly used: the \textit{mean}, which provides the average value of the data set; the \textit{median}, which provides its mid point\footnote{Remember that quantitative data can be ordered.}; and the \textit{mode}, which indicates the value that occurs most frequently, if any\footnote{There is no mode if no value is repeated in the data set.}. 
	\item dispersion, to establish the spread of the data in the data set. Range and standard deviation are two common measures. The \textit{range} is the difference between smallest (minimum) and largest (maximum) values. The \textit{standard deviation} is based on a mathematical formula which considers the distance of each value in the data set from the mean. It is not essential for you to know such formula, which is automatically computed by spreadsheets and statistical software\footnote{Of course, you can always look it up in the literature...}. The larger the standard deviation, the greater the dispersion.
	\item skewness, to establish how symmetrically distributed the values in the data set are in relation to the centre. In the case of perfect symmetry, skewness is equal to zero, and mean and median are equal. When asymmetric, mean and median are different and the distribution may be either right (mean smaller than median, and negative skewness) or left (mean greater than median, and positive skewness) skewed. A perfectly symmetric distribution is usually referred to as a \textit{normal distribution} or \textit{bell curve}, from the shape of the line that can be obtained by plotting the data on a chart\footnote{This oversimplifies the topic in order to give some intuition in case you have not come across these terms before. A lot more should be said about the normal distribution and its pivotal role in statistics!}.
\end{itemize}

Not all descriptive statistics apply to categorical data. In particular, the mode is used as the main measure of centrality for nominal data, while the median is used for ordinal data which are not numeric.

These are lots of definitions to digest, particularly if you haven't encountered these terms before! The following activity should help.

\begin{question}[subtitle={Activity: Descriptive statistics in Excel}] Assume you have measured the weight in grams of each apple in a basket, obtaining the following numbers: 105, 120, 122, 125, 127, 128, 129, 130, 132, 133, 135, 135, 138, 140, 128. Enter these data in an Excel sheet and use its built-in data analysis function to generate the related descriptive statistics.
\begin{guidance}
In the current version of Excel, you can access this function from the Data tab, by pressing the Data Analysis button. If you find it difficult to locate this function, you should refer to the documentation or to some of the many tutorials on this topic which are freely available online.
\end{guidance}
\begin{solution}

You should have obtained the following values:

\begin{tabulary}{\tablewidth}{@{}LL@{}} 
\textbf{Attribute} & \textbf{Value} \\
mean & 128.47 \\
median & 129 \\
mode & 128 \\
standard deviation & 8.55 \\
skewness & -1.4 \\
range & 35 \\
minimum & 105 \\
maximum & 140 \\
count & 15 \\
\end{tabulary}

There are 15 values in this data set, with range 35 (the difference between maximum and minimum values).
In terms of centrality, the mean (128.47) is slightly smaller than the median (129), and Excel reports a mode at 128. In reality, if you look at the data you will see that there are two modes in this data set\footnote{Statisticians call this \textit{bi-modal}.}, 128 and 135, but Excel only returns the first encountered!
In terms of dispersion, the standard deviation is telling us that most apple weights are within 8.55 grams of the mean (below or above), so the apple weights are similar in the apple baskets.
Note that the skewness is negative, which is consistent with the mean being smaller than median, so the data distribution is right skewed. 
\end{solution}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

In your dissertation, you can easily present such descriptive statistics as a table, possibly adapting that automatically generated by your spreadsheet.

In addition, charts can be used to visualise the data and examine their descriptive statistics. 

With scalar data, like in our example, you can use a \textit{histogram}. The one in Figure~\ref{fig:histogramBin1} uses the apple weights from the previous activity: on the horizontal axis, we have the distinct weights, and on the vertical axis, their frequencies, that is how many times each weight appears in the data set. Given the values you have obtained for the data set descriptive statistics, you can easily locate on the chart min and max values, and mean, median and mode. In this case, the two `peaks' correspond to the two modes we mentioned in the activity. You can also check that most of the values are within 8.55 grams from the mean, either way: the only values left out are 105 (to the left) and 138 and 140 (to the right). Skewness is not obviously notable on this chart, so that we will use a different chart for that purpose.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{Figures/barchart.pdf}
\caption{Histogram for the apple weights (bin size = 1)}
\label{fig:histogramBin1}
\end{figure}

Before we do that, however, it is worth noticing that given our small data set of discrete values, we have used a histogram with `bin' size equal to one, which allows us to plot each individual apple weight. A \textit{bin} in a histogram is essentially a way to group a number of values, with bin size establishing the spread of each bin. Frequencies are then calculated by bin. Grouping values in bins is necessary with large data sets and/or with continuous data.  Figure~\ref{fig:histogramBin5} illustrates a histogram for our example, in which the bin size is 5: that is, each bin spans a set of 5 possible values. 

\begin{figure}[htbp]
\centering
\includegraphics[width=12cm]{Figures/histogramBin5.pdf}
\caption{Histogram for the apple weights (bin size = 5)}
\label{fig:histogramBin5}
\end{figure}

In order to visualise both spread and skewness, a useful chart is the boxplot, illustrated in Figure~\ref{fig:boxplot} for our example. This is made of a `box' around the median of the data, and some `whiskers' on each side of the box\footnote{Which is why this chart is also called a \textit{box and whiskers} plot.}. It is obtained by dividing up the data into quartiles, each containing a quarter (or 25\%) of the data, with the median in the centre. The box includes the two quartiles on each side of the median, which, together, account for half of the values in the data set. The whiskers account for the two other quartiles, with a caveat: if there are very extreme values, these are treated as possible outliers and left out of the whiskers. This is, in fact, the case in our example where value 105 is treated as an outlier in the chart: it is a dot on its own, not included in the left whisker. The whisker length provides an indication of spread: the longer the whiskers, the more spread out the data. Instead, the position of the median in relation to the extreme of the box provides an indication of skweness: in our example the median is further away from to the right edge (just!), indicating that the data distribution is slightly right-skewed (consistent with the negative skewness value in the descriptive statistics).

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{Figures/boxplot.pdf}
\caption{Boxplot for the apple weights}
\label{fig:boxplot}
\end{figure}

To be more precise, the relation between a boxplot and its underlying statistical features is illustrated in Figure~\ref{fig:boxplotFeatures}. The two quartiles around the median represent the interquartile range (IQR) of the data set. The whisker lengths, calculated based on the formulae in the figure,  allows the identification of lower and upper bounds beyond which values are seen as extreme and represented separately as outliers. An outlier, therefore, is just a value which is distant from most of the other values in the data set: it may point to an error, which should be corrected, or an anomaly, which may require further investigation, but that's not necessarily the case. However, it's good practice to investigate all outliers to understand why they have occurred. 

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{Figures/boxplotFeatures.pdf}
\caption{The features of a boxplot --- LR to redraw as taken from the web}
\label{fig:boxplotFeatures}
\end{figure}


\begin{question}[subtitle={Activity: Charts in Excel}] Go back to your Excel sheet from the previous activities and generate charts similar to those in the figures above.
\begin{guidance}
In the current version of Excel, you can generate these charts from the Insert tab, by choosing from the Statistical charts menu. If you find it difficult to locate this function, you should refer to the documentation or check some of the many tutorials on this topic which are freely available online.
\end{guidance}
\end{question}


Table~\ref{tab:charts} summarises useful charts that can be applied to visualise your data and their descriptive statistics: it includes charts we have not used in our examples, but which are very common, so that you can find plenty of study materials online should you wish to look them up and use them.

\begin{table}
	\caption{Common charts to visualise data sets and their descriptive statistics}
	\label{tab:charts}
\begin{tabulary}{\tablewidth}{@{}LLL@{}} 
\textbf{Chart} & \textbf{Variable(s)} & \textbf{Purpose} \\
bar chart & one categorical & to visualise counts/frequencies/proportions/percentages \\
staked bar chart & two categorical & to compare   counts/frequencies/proportions/percentages between two groups\\
histogram & one scalar & to visualise distribution, including centrality, dispersion and skewness \\
scatter diagram & two scalar & to visualise relationships and possible outliers \\
boxplot & one scale or one categorical & to visualise spread, skewness, median, IQR and possible outliers \\
line chart & one scalar by time & to visualise change over time \\
\end{tabulary}
\end{table}


Calculating descriptive statistics and visualising data in appropriate charts, should be the first step in your statistical data analysis, as these provide useful summaries and visualisations of key properties of your data set. And, as you have found out in the activities, you do not need to be a statistician to be able to generate them!

Descriptive statistics may also help you identify errors or anomalies in the data, and can inform possible follow-up analysis, including inferential statistical analysis. Depending on your research aim and objectives, they could also be all you need in your project. 

If you have collected scalar or categorical data, it is time for you to have a go at analysing them using descriptive statistics and charts.

\begin{question}[subtitle={Activity: Applying descriptive statistics to your data}] 
Calculate descriptive statistics for your data set, and generate appropriate charts.
\begin{guidance}
MS Excel is relatively straightforward to use for this purpose, but feel free to use other tools you may be already familiar with, including statistical or data analytics packages. Whichever tool you use, you should ensure it supports the functionalities we have discussed in this section.
\end{guidance}
\end{question}


\subsubsection{Inferential statistics}\label{sect:inferentialStatistics}
Inferential statistics relies on the concepts of population and sample: the \textit{population} is the entire group you are interested in studying -- say, all UK voters in a general election; while the \textit{sample} is the portion or subset of that group you have access to in your research. Then the aim of inferential statistics is to establish whether patterns or effects you have observed in the sample can be generalised to, i.e., inferred for, the whole population, or whether they are the result of chance. In inferential statistics this is achieved through statistical tests.

A statistical test tells you whether the proposition\footnote{You can think of a proposition as an educated guess you have made based on some observations, but that has yet to be supported by evidence.} you wish to test on your sample is likely to be true in the population under study. For this to work, your sample must be representative of the population\footnote{We discussed sampling in Section~\ref{sect:sampling}}.

A statistical test returns a measure of \textit{statistical significance}, which is used to provide evidence (or otherwise) that the pattern or effect you see in your sample is also likely to exist in the population, and is not just the effect of chance\footnote{Contrary to the common language meaning of `significance' as big or important, statistical significance only indicates that the effect is likely to exist in the population, where it may well be small or unimportant!}. As a corollary, if your sample is very large, almost all effects observed in the sample will be likely present in the population; vice-versa, if your sample is very small, most effects observed in the sample are unlikely to be present in the population, unless they are really very large. As a rule of thumb, most tests require a sample size of at least 30 observations, but more precise sample size estimates can be made based on population size and expected significance level\footnote{Formulae for the ideal sample size are easily found in the literature and online.}.


Each statistical test comprises the following elements.

\begin{itemize}
	\item \textbf{Hypotheses} There are two, \textit{null} and \textit{alternative} hypotheses. Inferential statistics assumes you can't prove something to be true, but you can disprove something by finding an exception. Here is a classic example: you can't prove that all swans are white, but you can disprove they are by finding a black swan! So, you must  set the null hypothesis to what you want to disprove about the population, with the alternative hypothesis being what you are really interested in finding out. So, the null hypothesis is usually a statement of no pattern/effect in the population.
	\item \textbf{Significance} This is the level of statistical significance for the test. It's known as the \textit{alpha} ($\alpha$) value from the Greek name of the mathematical variable used to express it. Most tests are run with $\alpha=0.05$, which gives a 5\% probability that we may infer that the null hypothesis is disproved while in actually it is correct\footnote{This is called a Type I error in Statistics.}.
	\item \textbf{Sample(s)} You need to have one or more (representative) samples of the population of interest  on which to perform the test. Multiple samples are used in some tests, typically to compare specific statistics in different groups within the population or changes within a group over time or after an intervention of interest, say treating patients with a new pharmacological drug.
	\item \textbf{p-value} This is the probability calculated for your test by your statistical package, and which is used to decide the outcome of the test.
	\item \textbf{Decision} This is based on the p-value in relation to the $\alpha$ value: if the p-value is less than the $\alpha$ value, then the null hypothesis is \textit{rejected}, i.e. disproved, which means your alternative hypothesis that there is an effect in the population is supported by statistical evidence.
\end{itemize}

There are very many statistical tests to choose from, depending on the kind of data you have and their distribution, the purpose of your analysis and the number of samples involved. 

Statistical tests are applicable to both scalar and categorical data and can be used to compare values of specific statistics or to establish statistical relationships between variables, specifically:
\begin{itemize}
	\item an \textit{association} between variables means that one variable can be used to provide some information about the other
	\item a \textit{correlation} is a particular type of association such that the two associated variables always change together, for instance they both increase or decrease at the same time, or when one increases the other always decreases. 
\end{itemize}
Statistical tests can be used to estimate the strength of an association (i.e., the extent changes in one correspond to changes in the other) and its direction (whether the variable changes are in the same or opposite way).

We will not detail all possible statistical tests in this introductory section --- once again, entire books have been written about them! Instead, we provide Tables~\ref{tab:testsForComparison} and \ref{tab:testsForAssociation} as summaries of the most common tests that you can then follow up in the literature, should you wish to apply any in your research.

\begin{table}
	\caption{Common statistical tests for comparison. \textit{Parametric} tests apply to normally distributed data (see Section\ref{sect:descriptive}), while \textit{non parametric} tests to skewed distributions.}
	\label{tab:testsForComparison}
\begin{tabulary}{\tablewidth}{@{}LLLLLL@{}} 
\textbf{Purpose} & \textbf{Variables} & \textbf{Example} & \textbf{Parametric} & \textbf{Non parametric} & \textbf{Notes}  \\
\toprule
to compare the sample mean against a specific value & one scalar & to investigate whether AA batteries of a particular brand have the claimed lifespan  & one sample t-test & n/a  & \\
\midrule
to compare the sample proportion against a specific value & one categorical & to investigate the proportion of people who voted for a particular party in a city against that for the whole country & one sample z-test & n/a  & \\
\midrule
to compare the means of two independent samples & scalar & to compare the mean scores (dependent) of students studying the same subject with two different teaching approaches (explanatory) & independent t-test & Mann-Whitney test/Wilcoxon rank sum  & two samples are \textit{independent} when there is no reason to believe that observations in one sample are influenced or determined by those in the other\\
\midrule
to compare the means of three or more independent samples & scalar dependent; nominal explanatory & to compare the mean scores (dependent variable) of students studying the same subject with three or more different teaching approaches (explanatory variable) & one-way ANOVA & Kruskal-Wallis test \\
\midrule
to compare the average difference between paired samples against a particular value & scalar dependent; time or condition as explanatory & to compare the blood pressure readings (dependent vraiable) of a group of people before and after exercising (explanatory variable) & paired t-test & Wilcoxon signed
rank test &  in paired samples each data point in one sample is uniquely matched to a data point in the other sample; this happens, for instance, when we measure a factor before and after an intervention, or take different readings for the same group of individuals. Because of this, paired samples are not independent.\\
\midrule
\end{tabulary}
\end{table}

\begin{table}
	\caption{Common statistical tests for association. \textit{Parametric} tests apply to normally distributed data, while \textit{non parametric} tests to skewed distributions.}
	\label{tab:testsForAssociation}
\begin{tabulary}{\tablewidth}{@{}LLLLLL@{}} 
\textbf{Purpose} & \textbf{Variables} & \textbf{Example} & \textbf{Parametric} & \textbf{Non parametric} & \textbf{Notes}  \\
\toprule
to investigate correlation between two continuous variables & scalar dependent and explanatory & to investigate the relation between blood pressure (dependent) and age (explanatory)  & Pearson’s Correlation Coefficient & Spearman’s Correlation Coefficient & \\
\midrule
to investigate association between two categorical variables & categorical dependent and explanatory & to find out if there are gender (categorical) differences in the choice of modes of transport (categorical) in a city & chi-squared & n/a  &  \\
\midrule
to investigate association between two categorical variables when the sample is small & categorical dependent and explanatory & to find out if there are gender (categorical) differences in the choice of modes of transport (categorical) in a city  & Fisher's Exact test & n/a & the sample size $n$ should be less than 20 \\
\midrule
to predict the value of one variable from that of one or more other variables & scalar dependent and any kind of explanatory & to predict house prices (dependent) based on location (explanatory, categorical) and number of bedrooms (explanatory, scalar) & linear regression & n/a & linear regression relies on associations between dependent and explanatory variables\\
\midrule
to predict the value of a binary variable from that of two or more other variables & binary categorical dependent and any kind of explanatory & to predict whether a customer is likely or not to purchase a certain product (dependent) based on previous purchased products (explanatory, categorical) and average annual spent (explanatory, scalar) & logistic regression & n/a & a binary variable has only two possible values, so that logistic regression calculates the probability of each value based on the values of the explanatory variables. Because of this logistic regression can be used as a classification method \\
\midrule
\end{tabulary}
\end{table}

Even if these tests are only a sub-set of all statistical tests available, there is a lot to digest. The next activity should help you use these table to choose an appropriate test. 

\begin{question}[subtitle={Activity: Choosing an appropriate test}] 
Consider the following scenarios: for each, use the information in the tables to decide which test to apply and what the null hypothesis should be. For each, write down your reasoning, choice and null hypothesis.

\begin{itemize}
	\item \textit{Scenario 1} to investigate the amount of sugar contained in baby food of a particular brand against a recommended threshold, from a sample of 30 products of that brand.
	\item \textit{Scenario 2} to investigate the number of products per hour of two manufacturing machines in the same plant, by observing the two machines' output over 24 hours. 
	\item \textit{Scenario 3} to investigate the effect of temperature on the consumption of ice cream in a particular city over 12 months.
	\item \textit{Scenario 4} to investigate whether taste in chocolate types, say white vs milk vs dark, is related to gender in particular country.
	\end{itemize}
\begin{guidance}
To simplify things, always assume normal distributions.
\end{guidance}
\begin{solution}
Assuming normal distributions, for each scenario, we have considered:
\begin{itemize}
	\item the kind of data
	\item number of samples and their size
	\item purpose of the investigation
\end{itemize}
This is what we have concluded:
\begin{itemize}
	\item \textit{Scenario 1} scalar variable (amount of sugar); one sample of 30 products; to compare the sample mean against the recommended threshold. The test to use is a t-test with null hypothesis that the sample mean is above the threshold.
	\item \textit{Scenario 2}  scalar dependent (number of products per hour) and categorical explanatory (which machine); two samples (one per machine over the time span); to compare the means of products per hours for the two machines; there is no reason to think that the working of one machine may influence that of the other. The test to use is an independent t-test with null hypothesis that the two sample means are different.
	\item \textit{Scenario 3} scalar dependent (level of ice cream consumption) and scalar explanatory (temperature); one sample over the period; to investigate any relationship between the two variables. The test to apply is Pearson's correlation with null hypothesis that there is no association between the two variables.  If, in addition, we wanted to make predictions on ice cream consumption based on temperature, then we could also apply linear regression.
	\item \textit{Scenario 4} both dependent (chocolate taste) and explanatory (gender) are categorical; one sample from the country; to investigate association. The test to use is a Chi-squared with null hypothesis that gender has no association with chocolate taste.
\end{itemize}
\end{solution}
\end{question}

\subsection{Quantitative analysis resources}

\todo{Add here}

%%% LR -- to decide whether to include!!!!

%use of generative AI to add to ethics section
%constraints on the use of generative AI in research:
%- university policies: check with your university!!!! generative AI and IP issues
%- technology capabilities: still developing; as a human researcher you need to check and double check anything that AI does
%
%
%Complementary to statistical methods, an increasing variety of Machine Learning algorithms can also be used for data analysis. Two broad application concern the recognition of patterns in data and making predictions based on historical data.
%
%
%tasks that you can fast track with AI
%- 
%**** more about this????
%
%
%issue -- black box nature

\subsection{Qualitative analysis}

As indicated in Section~\ref{sect:dataAnalysisMethods}, common methods for qualitative data analysis include content, thematic, narrative or discourse analysis. While their goal may be different, they all apply the initial step of \emph{coding}, which we discuss next.

\subsubsection{Coding qualitative data}

A \textit{code} is essential a label which describes an extract from qualitative data set, with \textit{coding} the process of creating and assigning codes to categorise those extracts. 

Coding is important and it helps you ensure that your analysis is systematic, and the codes will help you explore themes and patterns in the data. However, codes are not themes: they are just labels used to group similar types of data, developed to support your follow-up analysis. 

There are two main approaches to coding. In \textit{deductive coding}, the codes are decided upfront, before looking at the data, and may be based on your research problem phenomena, or  may have emerged from your literature review, including codes possibly used in previous studies. In \textit{inductive} coding, the codes emerge from the data and are not pre-defined. Deducting and inductive coding can also be combined by starting with a set of pre-defined codes then adding new codes as you review the data.

Whichever your approach, you should follow a multi-pass coding process. The first pass should consist of going through the whole data set in order to establish which codes to use. In the second pass, and any subsequent ones, you should apply the codes to the data bit by bit, say by line by line in a text, or frame by frame in a video, etc. In the second pass and subsequent passes, the initial codes are reviewed and may become more or less detailed.

There are various ways to choose codes. For instance, \textit{in vivo} coding uses the exact language which occurs in the data: this is used, in particular, for participants' speech, especially when different languages are used. On the other hand, \textit{descriptive}\footnote{This is a very common approach, although there are others which you can research in the literature.} coding uses words which encapsulate a general idea, such as `sport' or `running': this is particularly useful for non textual data, like images or videos. 

Whichever codes you end up with, you should ensure they are properly defined, so that their are unambiguous and can be applied consistently. You should use a \textit{codebook} for this purpose, which lists all the codes and their intended meaning, and that you can revisit and refine throughout the coding process.

The last step before detailed analysis is \textit{code categorisation}, which is the process of reviewing what you have coded and organise it into categories. For instance, from codes such as `football', `tennis' and `rugby' you may define a category `sports'. In this way, you both organise your data and establish connections between codes and coded information. 

Both coding and categorisation are iterative processes which carry on until you reach saturation, that is no more is gained from further coding or categorisation. At this point, you can proceed with your chosen analysis method, whether content, thematic, narrative, discourse analysis or other, in order to identify patterns and themes, and provide your own interpretation of the data.

Coding and categorising are time consuming tasks, particularly if you have a large amount of text to code. In most research, coding data by hand is impractical and you should at least make use of a word processor, perhaps using colours and comments to code fragments of your text. Better still, you could  make use of a bespoke qualitative data coding tool: many such tools are now available, some of which can also automate coding and categorisation to some extent.

\begin{question}[subtitle={Activity: Investigating tools for qualitative data coding}] 
Conduct a web search on tools which support qualitative data coding. List up to four which appear most commonly used. For each, indicate which coding features it offers and the extent it is freely available for students' research projects.
\begin{solution}
Qualitative analysis tools are growing and changing rapidly, particularly due to the integration and exploitation of AI capabilities. 

At the time of writing this book, the most used commercial products include NVivo, ATLAS.it and MAXQDE. They all provide support for coding, with more or less extensive automation, alongside various other features such as data visualisation, statistical analysis, automatic transcripts generation from audio and video files, to name just a few. These commercial products are quite sophisticated with a steep learning curve and are usually quite expensive. They are also geared towards large research efforts, possibly by teams of researchers.

An increasing number of lighter, free products are also available. These include, for instance, Taguette, which supports manual coding and is both open source and free to use, or QDE Miner Lite, which is a free limited version of its full commercial release, and also supports manual coding. Such free products may be sufficient for Masters level research projects.

You may have found other similar tools.
\end{solution}
\end{question}

\subsubsection{Presenting qualitative data}

While quantitative data can be summarised and presented using tables and charts, the same does not necessarily apply to qualitative data, which, due to their heterogeneous nature, cannot be easily set out in a standard manner. 

Conveying the depth and richness of qualitative data in a succinct way is challenging, so that both selectivity and creativity are needed in presenting the data. 

For textual data, like interview transcripts, verbatim quotations are often used to illustrate specific themes or points, or support certain conclusions. However, an excessive use of quotations will result in overlong accounts of the work, which may be difficult to follow or even obscure the main findings. Therefore it is important to select quotations which are particularly representative or poignant, avoiding verbose details that can be succinctly presented in the narrative around those quotations.

Diagrams, schematics or drawings can also be used effectively and imaginatively to present qualitative data and their analysis. Data visualisation is, in fact, a discipline in its own right\footnote{Edward Tufte is one of the most influential figures in this field. His books provide compelling examples on how to use visualisation to present and analyse highly complex data.}, and some visualisation techniques can be applied to qualitative data.

\begin{question}[subtitle={Activity: Visualisation techniques for qualitative data}] 
Conduct a web search on techniques for visualising qualitative data. List the techniques you have found and what they are used for.
\begin{solution}
You may have encountered some or all of the following techniques:
\begin{itemize}
	\item diagrams and schematics, to convey complex processes or structures
	\item graphic timelines, to summarise key events and their order
	\item word clouds, to summarise emerging themes or concepts from text, and their relative frequencies
	\item mind maps, to visualise how different ideas relate or contribute to a central concept or topic
	\item heat maps, to highlight trends or differences in tabulated data
	\item icons, alongside brief descriptions, to represent and quickly identify specific concepts 
	\item bespoke drawings, for data which cannot be easily visualised using other standard techniques
	\item pie charts and bar charts, to summarise proportions and counts\footnote{Which are actually quantitative, but may be the result of qualitative data analysis.} of categorical data.
\end{itemize}
\end{solution}
\end{question}


\section{Writing up your analysis}

In writing up your data analysis in your stage report or dissertion, you will need to decide:

\begin{itemize}
	\item how to summarise your data and evidence. This will depend on their nature, and you will need to ensure that your summaries are appropriate to convey the essence of the evidence you have generated. In the previous sections, you have considered ways in which quantitative and qualitative data can be summarised using tables and visualisations. It may also be necessary for you to include sample raw data in an appendix.
	\item how to report findings. Your findings are your conclusions from your data analysis and should be reported as academic arguments which rely on the evidence you have gathered. 
	\item how to structure your narrative. Depending on your chosen research strategies and methods, different structures are possible. For instance, you may choose to start with a section which summarises all your evidence followed by one in which you analyse it, which may work well, for instance, for survey research. Alternatively, you could have separate sections each including a summary and analysis of a sub-set of your evidence: this may be appropriate for mixed methods research, with each section dealing with a different kind of data, or for design science research, with each section addressing a different design cycle. Whatever you choose, it is important that your report is effective in presenting your evidence and findings in a clear, rigorous and logical manner.
\end{itemize} 


\begin{question}[subtitle={Activity: Writing up your analysis}] 
Consider the data you have collected and analysed so far. Note down how you are going to address each of the points above in your report. Write an outline of your analysis section.
\begin{guidance}
A good starting point is to consider how other researchers report their data analysis and findings. To this end, go back to some of the articles you have reviewed and consider their data analysis section and any related discussion. Ensure you select articles that apply similar collection and analysis methods to those in your research design, or deal with similar types of data.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\section{Interpreting and evaluating data}

Having gathered and analysed a certain amount of data and evidence, it is time for you to start interpreting your findings in relation to your aim and objectives, and generally evaluate them in terms of their contribution to knowledge and possible limitations. This is a process you will repeat and complete in Stage 5, the concluding stage of your project, ending with your dissertation submission.

Interpreting your findings signifies addressing the following questions:

\begin{itemize}
\item What conclusions have you drawn from your data analysis?

\item How do they relate to your aim and objectives?

\item How do they relate to what you know from the literature? 

\item How do they relate to professional practice? (if applicable)

\item Which new knowledge do they contribute?

\item What do they fail to achieve?

\end{itemize}

\begin{question}[subtitle={Activity: Interpreting and evaluating your  findings}] 
Consider your data analysis and based on it, address each of the above questions. Write down your responses, ensuring your arguments are well-formed, with explicit reference to evidence.
\begin{guidance}
Your interpretation and evaluation of findings will be, of course, limited by the data\slash evidence you have gathered and analysed up to this point. You will revisit and expand this work in Stage 5 in order to complete your project.
\end{guidance}
\end{question}

\section{Drafting an abstract for your project}

An abstract is a common way to summarise academic research. Abstracts are an integral parts of all published academic articles -- you will have encountered many abstracts while reviewing the literature. They are also very common in academic dissertations, therefore it is highly likely you will be required to include one at the beginning of yours.

An {abstract} provides a short summary of the whole research written for a specialist audience, that is you can assume that the reader has good knowledge of the topic and field of study. It should be a stand-alone item, so that it can be understood without reference to any other part of your dissertation.

Its content should convey succinctly the research problem, how and where it arises and its significance, the research aim and research design, key results obtained by the research, their evaluation and their implications for further research or professional practice. 

Writing an abstract for your research is a good exercise, even if one is not needed for your dissertation, as it gives you an opportunity to write a logical argument that connects all key elements of your research. This can help you check that all the pieces fit together in a coherent manner. It is also something you can share with your supervisor and critical friends to communicate succinctly the essence of what you have done and achieved.  

\begin{question}[subtitle={Activity: Drafting your abstract}]
Write a draft abstract for your project, which should reflect your research progress to date. 
\begin{guidance}
You should go back to some of the articles you have reviewed to consider the content and structure of their abstract. Choose a structure which may fit your project and write up your draft abstract accordingly.

As your research is yet to be completed, you will not be able to write up the full abstract, but you should end up with a draft that you can easily complete by the end of your project.
\end{guidance}
\end{question}
%%Hack to correct tcbox behaviour
\color{black}


%%%LR -- I don't think we need this, which is a T802 thing
%\subsection{The extended abstract} 
%
%An {extended abstract} is a summary of academic research intended for a more general audience, so that it should be easily read and understood by someone with only a superficial knowledge of the topic. As with the abstract, it should be a stand-alone item without any reference to your full dissertation. However, it is a lengthier piece of academic writing, structured with headings and sub-headings, including citations and references, and possibly tables, figures and diagrams to help you present and summarise your work.
%
%\begin{question}[subtitle={Activity: Drafting your extended abstract}] Write a draft extended abstract for your project, which should reflect your research progress to date.
%
%\begin{guidance}Your extended abstract should be 4 to 6 pages in length (once complete) and a common structure is as follows:
%
%\begin{itemize}
%\item Title --- the same as your dissertation
%
%\item Introduction and background --- an outline of your research problem in its context, its significance, and the knowledge gap addressed by your research
%
%\item Aim and objectives --- from your dissertation
%
%\item Research design --- an outline of your research design
%
%\item Results --- a summary of the evidence collected and analysed, and your key findings
%
%\item Discussion --- how significant your findings are in relation to research problem and knowledge gap
%
%\item Conclusion and future work --- your overall conclusions and possible follow-up research
%
%\item References --- selected references cited in the body of your extended abstract
%
%\end{itemize}
%
%Your course may have different guidelines which you should check and follow to produce your extended abstract.
%
%\end{guidance}\end{question}
%%%Hack to correct tcbox behaviour
%\color{black}

\section{Reflecting and reporting in Stage 4}

It's time to write your Stage 4 report. As in the previous stages, before you do, it is worth reflecting on your work and learning in this stage.

\begin{question}[subtitle={Activity: Reflecting on your learning and practice}]
As you did at the end of the previous stages, in this activity you are asked to stand back and reflect deeply on what you have leant and done, the wider context of your work and your own attitude to it. Specifically, you are asked to think deeply about each of the following:

\begin{itemize}
	\item your study this far
	\item the way you work
	\item the context of your research
	\item your feelings about your project
\end{itemize}

You should also think of any significant changes with respect to your reflection in the previous stages
\begin{guidance}
You should be accomplished at reflection by now. However, should you need to, you can refer back to the guidance to this activity in Stage 1, Section~\ref{sect:stage1Reflection}.
\end{guidance}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

Your end-of-Stage 4 report will help you consolidate your work so far, adding yet another increment toward your full dissertation. We recommend you follow the guidance in Table~\ref{tab:S4report} to write your report.

At the end of Stage 4, you should complete a report, extending that of Stage 3 and covering the work you have carried on in this stage. Its recommended structure and content are indicated in Table~\ref{tab:S4report}: much of the content should be carried forward from the previous stage.

\begin{table}[htbp]
\caption{Report structure and guidance \label{tab:S4report}}
\centering
\begin{tabulary}{\tablewidth}{@{}LL@{}} \toprule
 \textbf{Report template} & \textbf{Guidance} \\
\midrule

 Proposed title & Your title should continue to capture succinctly your research problem and aim. \textit{It is likely this is the same as, or very similar to, that in Stage 3}\\
 Abstract & You should include your draft abstract providing a succint account of your research to date \\
 Sect 1 - Introduction 1.1 Background to the research 1.2 Justification for the research 1.3 Fitness of the research & This section should continue to provide an introduction to your research topic in its wider context (as background) and your justification of why the research is worth pursuing. Its purpose is to introduce and justify your intended research in overview, before entering the detailed work of the subsequent sections. It should be well argued and supported by appropriate citations. In this section, you should also argue how the research fits within the scope of your qualification, and meets any other personal, professional or organisational criteria. \textit{You may review this section from Stage 1 to reflect your growing understanding of the topic in context derived from your literature review.} \\
 Sect 2 - Literature review 2.1 Review of existing relevant knowledge 2.2 Critical summary, including knowledge gap to be addressed by the research & Your review should provide a critical account of your in-depth engagement with the academic (and other) relevant literature, including identifying key trends, ideas and possible knowledge gaps. Most of your citations should point to academic articles. Your critical summary should highlight key insights from your review and provide a strong justification for your proposed research. Both coverage and depth of your review matter. You should ensure that your review is well structured, with a logical narrative flow and your arguments are well supported by evidence \\
 Sect 3 - Research definition 3.1 Problem statement 3.2 Aim, objectives, tasks and deliverables 3.3 Knowledge contribution & You should ensure that your research problem is well articulated and appropriate for your course and your personal and professional circumstances, that your aim and objectives are consistent with research problem, that tasks and deliverables break down your objectives appropriately and are clearly related to your chosen research methods, and that the intended knowledge contribution of your research is clearly articulated \\
  Sect 4 - Research design 4.1 Evidence and data 4.2 Research strategy and methods 4.3 Research procedures 4.4 Ethical, legal and EDI considerations & This section should demonstrated your critical engagement with all elements of research design, including a detailed account of the data and evidence needed in your research, the research methods and research strategies chosen, with justification, and applied within your project. Your account should be supported by a clear rationale and insights from the related literature, and appropriately justified in relation to your research problem, aim and objectives. It should also demonstrate your careful consideration of ethical and legal matters, and that your research complies with your course and university requirements \\
  Sect 5 - Analysis and interpretation 5.1 Summary and analysis of evidence 5.2 Summary of key findings 5.3 Interpretation in relation to aim and objectives & This section should demonstrate substantial progress towards gathering and analysing your data and evidence, and interpreting them in relation to aim and objectives. It should demonstrate a competent execution of your research design, present appropriate summaries of evidence and data, supported by raw data in an appendix if needed. Key findings should be clearly identified and logically connected to evidence, with good critical reflection on their implications for aim and objectives. \\
  Sect 6 - Work planning and risk assessment 6.1 Statement of progress 6.2 Key priorities in follow-up stage 6.3 Risk assessment & In this section you should reflect on the progress you have made in Stage 4 and establish your priorities for the next stage. You should also review your risk assessment as appropriate. \\
 References & You should keep your growing references in good order and ensure you apply the required bibliographical style consistently. \\
 Appendix - Raw evidence & If relevant, you should include a sample of your raw data as an appendix \\
 Appendix - Work schedule & You should include your revised work plan as an appendix \\
 Appendix - Risk assessment table & You should include your updated risk table as an appendix \\
\bottomrule
\end{tabulary}
\end{table}

\begin{question}[subtitle={Activity: Writing and assessing your report for Stage 4}] Using your word processor of choice, revise and expand your Stage 3 report by applying the structure and guidance in Table~\ref{tab:S4report}. 

Assess your report by applying the criteria in Table~\ref{tab:criteriaForStage4report}. Revise and iterate until you are ready to move on. 
\begin{guidance}
In completing your report, you should make good use of notes and summaries your wrote as part of the activities in this chapter.
In evaluating your report, for each criteria, you should consider the related prompts, write down any further work needed for your next stage, and update your work plan and risk assessment table accordingly.
\end{guidance}\end{question}
%%Hack to correct tcbox behaviour
\color{black}

\begin{table}
	\caption{Criteria for reviewing your research proposal \label{tab:criteriaForStage4report}}
\begin{tabulary}{\tablewidth}{@{}LL@{}} \toprule
 \textbf{Criteria} & \textbf{Prompts} \\
\midrule
 \textbf{Completeness} & Are all sections included and their content complete? What is missing?\\
 \textbf{Academic writing} & Have you applied good academic writing practices throughout? Which main issues do you still have to address? \\
 \textbf{Logical structure and flow} & Have you structured your writing appropriately to ensure a logical flow of arguments? Which restructuring may be needed?\\
 \textbf{Supporting evidence} & Are your key arguments supported by appropriate references or other evidence? Which further evidence is needed?\\
 \textbf{Citation and reference style} & Do all your citations and references comply with the required bibliographical style? \\
 \textbf{Avoiding plagiarism} & Have you acknowledged the work of others and distinguished it from your own appropriately? \\
 \textbf{Grammar and spelling} & Have you proof-read your report carefully to remove all typos and grammatical errors? \\
\bottomrule
\end{tabulary}
\end{table}

\section{Takeaways}
\begin{itemize}
\item Sampling is the process of selecting a sample from the population of interest, and is required in many research strategies. Many different approaches to sampling exist, depending on the nature and aim of your research.
\item Questionnaires are common tools for data generations. Good questionnaire design relies on a wide range of considerations (see Section~\ref{sect:questionnaireDesign}).
\item When a large amount of raw data is collected, it is important to devise appropriate ways to store and organise them, paying particular attention to backing them up and protecting personal data.
\item Tables are common ways to organise and present data, and a good starting point for data analysis. Pivot, frequency and contingency tables are commonly used in research.
\item Descriptive statistics is used to describe data, with various attributes of data sets defined and calculated, such as centrality, dispersion or skewness. Charts are often used to visualise such attributes.
\item Inferential statistics is used to make predictions from data, specifically to establish whether patterns or effects observed on sample data can be inferred for the whole population from which the sample was taken.
\item Statistical tests are used to establish the statistical significance of observations on a sample in relation to the whole population. They are used both for comparing data to set values and to establish relationships between variables. Many statistical tests exist.
\item Coding is the first step in qualitative analysis, and is the process of assigning labels to extracts from a qualitative data set to allow a systematic follow-up analysis. Different approaches to coding exist.
\item  Qualitative data are heterogeneous in nature, so that they cannot be easily set out in a standard manner. Many different, often bespoke, approaches to present and visualise qualitative data have been proposed in the literature.
\item In writing up your data analysis you must decide how to summarise your data, how to report your findings and how to structure your narrative. 
\item Interpreting your findings means to indicate what you can conclude from the data, how that relate to your aim and objectives, and which new knowledge it contributes.
\item An abstract is a short summary of your whole dissertation, written for a specialist audience as a stand-alone piece, that is understandable without reference to any other part of your dissertation.
\item The template provided can help you structure your Stage 4 report.
\end{itemize}


